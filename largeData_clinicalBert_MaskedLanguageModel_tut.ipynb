{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cf6cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,BertForSequenceClassification, AutoTokenizer, AutoModel,AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9cb251",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7189bfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "new_tokens = [\"interstitial\", \"fibrosis\", \"tubular\", \"atrophy\",\"antibody\",\"T-cell\"]\n",
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85811197",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fbc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3557cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inter',\n",
       " '##st',\n",
       " '##iti',\n",
       " '##al',\n",
       " 'fi',\n",
       " '##bro',\n",
       " '##sis',\n",
       " 'and',\n",
       " 'tub',\n",
       " '##ular',\n",
       " 'at',\n",
       " '##rop',\n",
       " '##hy',\n",
       " '.',\n",
       " 't',\n",
       " '-',\n",
       " 'cell',\n",
       " 'mediated',\n",
       " 'rejection',\n",
       " '.',\n",
       " 'anti',\n",
       " '##body']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"interstitial fibrosis and tubular atrophy. T-cell mediated rejection. antibody \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f5a594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " '##rich',\n",
       " '##rome',\n",
       " 'stain',\n",
       " 'shows',\n",
       " 'focal',\n",
       " 'mild',\n",
       " 'inter',\n",
       " '##st',\n",
       " '##iti',\n",
       " '##al',\n",
       " 'fi',\n",
       " '##bro',\n",
       " '##sis',\n",
       " 'and',\n",
       " 'tub',\n",
       " '##ular',\n",
       " 'at',\n",
       " '##rop',\n",
       " '##hy',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "tokenizer.tokenize(\"Trichrome stain shows focal mild interstitial fibrosis and tubular atrophy. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be98f8d",
   "metadata": {},
   "source": [
    "# Fine-tune Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "238b9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03601a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d5ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data[\"Raw Case Text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe02954",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoding = tokenizer(inputs,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a3f2b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoding['labels'] = input_encoding.input_ids.detach().clone()\n",
    "input_encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3649a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ...,  True, False, False],\n",
       "        [False, False, False,  ...,  True, False, False],\n",
       "        [False, False,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(input_encoding.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (input_encoding.input_ids != 101) * \\\n",
    "           (input_encoding.input_ids != 102) * (input_encoding.input_ids != 0)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c449f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3429"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175eadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = [torch.flatten(mask_arr[i].nonzero()).tolist() for i in range(input_encoding.input_ids.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9fbd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_encoding.input_ids.shape[0]):\n",
    "    input_encoding.input_ids[i, mask_pos[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3496f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoding):\n",
    "        self.encoding = encoding\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encoding.input_ids)\n",
    "\n",
    "masked_dataset = MaskedDataset(input_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544a7bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3429\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1287\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1287' max='1287' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1287/1287 12:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-100\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-100/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-200\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-200/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-300\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-300/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-400\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-400/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-500\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-500/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-600\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-600/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-700\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-700/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-800\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-800/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-900\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-900/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-1000\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-1000/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-1100\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-1100/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "Saving model checkpoint to ./mlm_results_largeData/checkpoint-1200\n",
      "Configuration saved in ./mlm_results_largeData/checkpoint-1200/config.json\n",
      "Model weights saved in ./mlm_results_largeData/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./mlm_results_largeData',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=8,  \n",
    "    #per_device_eval_batch_size=64,   \n",
    "    #warmup_steps=50,                \n",
    "    #weight_decay=0.01,                          \n",
    "    logging_steps=100,\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    #eval_steps=100,\n",
    "    #load_best_model_at_end=True,\n",
    "    save_steps = 100,\n",
    "    save_total_limit = 10,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=masked_dataset,         \n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e1731",
   "metadata": {},
   "source": [
    "# Test Trained MLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdf3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_renal = AutoModelForMaskedLM.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3dde310",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sent = f\"Comment: The biopsy shows severe interstitial inflammation and tubulitis (i3/t3), \\\n",
    "which are diagnostic for acute T-cell-mediated rejection, type IB.\"\n",
    "\n",
    "masked_sent = f\"Comment: The {tokenizer.mask_token} shows {tokenizer.mask_token} interstitial {tokenizer.mask_token} and tubulitis (i3/t3), \\\n",
    "which are {tokenizer.mask_token} for {tokenizer.mask_token} T-cell-mediated {tokenizer.mask_token}, {tokenizer.mask_token} IB.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd802525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  6, 11, 26, 28, 34, 36])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent = tokenizer.encode(masked_sent, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(tokenized_sent == tokenizer.mask_token_id)[1]\n",
    "\n",
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17091236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: \n",
      " Comment: The biopsy shows severe interstitial inflammation and tubulitis (i3/t3), which are diagnostic for acute T-cell-mediated rejection, type IB. \n",
      "\n",
      "Comment: The 0*patient* shows 1*increased* interstitial 2*inflammation* and tubulitis (i3/t3), which are 3*concerning* for 4*a* T-cell-mediated 5*process*, 6*and* IB. \n",
      "\n",
      "Comment: The 0*CT* shows 1*bilateral* interstitial 2*disease* and tubulitis (i3/t3), which are 3*suspicious* for 4*chronic* T-cell-mediated 5*reaction*, 6*but* IB. \n",
      "\n",
      "Comment: The 0*exam* shows 1*new* interstitial 2*process* and tubulitis (i3/t3), which are 3*typical* for 4*possible* T-cell-mediated 5*infection*, 6*no* IB. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clinical model\n",
    "token_logits = model(tokenized_sent).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices.tolist()\n",
    "print(\"Original Sentence: \\n\", original_sent, \"\\n\")\n",
    "for words in zip(*top_3_tokens):\n",
    "    new_sent = masked_sent\n",
    "    for i,token in enumerate(words):\n",
    "        new_sent = new_sent.replace(tokenizer.mask_token,f'{i}*{tokenizer.decode([token])}*',1)\n",
    "    print(new_sent,\"\\n\")\n",
    "    \n",
    "# token_logits = model(tokenized_sent).logits\n",
    "# mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "# for token in top_5_tokens:\n",
    "#     print(masked_sent.replace(tokenizer.mask_token,tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bb5888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: \n",
      " Comment: The biopsy shows severe interstitial inflammation and tubulitis (i3/t3), which are diagnostic for acute T-cell-mediated rejection, type IB. \n",
      "\n",
      "Comment: The 0*patient* shows 1*moderate* interstitial 2*inflammation* and tubulitis (i3/t3), which are 3*insufficient* for 4*acute* T-cell-mediated 5*rejection*, 6*type* IB. \n",
      "\n",
      "Comment: The 0*specimen* shows 1*widespread* interstitial 2*congestion* and tubulitis (i3/t3), which are 3*suspicious* for 4*chronic* T-cell-mediated 5*reaction*, 6*and* IB. \n",
      "\n",
      "Comment: The 0*examination* shows 1*mild* interstitial 2*swelling* and tubulitis (i3/t3), which are 3*concerning* for 4*a* T-cell-mediated 5*disease*, 6*although* IB. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_renal\n",
    "token_logits = model_renal(tokenized_sent).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices.tolist()\n",
    "print(\"Original Sentence: \\n\", original_sent, \"\\n\")\n",
    "for words in zip(*top_3_tokens):\n",
    "    new_sent = masked_sent\n",
    "    for i,token in enumerate(words):\n",
    "        new_sent = new_sent.replace(tokenizer.mask_token,f'{i}*{tokenizer.decode([token])}*',1)\n",
    "    print(new_sent,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f0505",
   "metadata": {},
   "source": [
    "# Finetune New Model for isRejection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcffd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report\"].tolist()\n",
    "label1 = data[\"isRejection\"].tolist()\n",
    "\n",
    "label = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df697416",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb6384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808a061e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0527a1a019eb43bd97458300b553b973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.1 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData_extended_tokenizer/checkpoint-1100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6106e966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6860\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6860' max='6860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6860/6860 43:50, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.260800</td>\n",
       "      <td>0.215274</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.292564</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266700</td>\n",
       "      <td>0.255284</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>0.174267</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.238700</td>\n",
       "      <td>0.259257</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.249368</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.270994</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.139535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.212663</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.192900</td>\n",
       "      <td>0.205264</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.188147</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.326531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.236400</td>\n",
       "      <td>0.229334</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>0.263331</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.273100</td>\n",
       "      <td>0.223906</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.244934</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.226474</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.292344</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.234700</td>\n",
       "      <td>0.262144</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.252400</td>\n",
       "      <td>0.245674</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.247950</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.241517</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.246042</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.245238</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.256402</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.231968</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.259392</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.244733</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.272500</td>\n",
       "      <td>0.243507</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.260166</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.249290</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.221840</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.242900</td>\n",
       "      <td>0.236915</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.239466</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.252717</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.240935</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.269900</td>\n",
       "      <td>0.242377</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.238126</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.266101</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.254671</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.252589</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.179702</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.187895</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.225939</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.211258</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.191674</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.188067</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.190900</td>\n",
       "      <td>0.201458</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.247100</td>\n",
       "      <td>0.215892</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.185700</td>\n",
       "      <td>0.199741</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.203700</td>\n",
       "      <td>0.198697</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.204330</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.242927</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.209616</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.297872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.219969</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.225398</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>0.237628</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.222100</td>\n",
       "      <td>0.196308</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.459016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.158463</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>0.196381</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.190710</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>0.187221</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.240411</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>0.201093</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.206381</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.193493</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.180593</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>0.171064</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.182191</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.180680</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.483871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\n",
      "Configuration saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\\config.json\n",
      "Model weights saved in ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700] due to args.save_total_limit\n",
      "<ipython-input-7-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_bioBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700 (score: 0.15846268832683563).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_bioBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10aa05e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6860\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5254' max='6860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5254/6860 33:07 < 10:07, 2.64 it/s, Epoch 15.31/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.268791</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.282152</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>0.229670</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.180696</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.220326</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.255382</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.212400</td>\n",
       "      <td>0.129945</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>0.119921</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.170716</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.134492</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.124600</td>\n",
       "      <td>0.156411</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.110832</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.163200</td>\n",
       "      <td>0.116481</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.124900</td>\n",
       "      <td>0.118942</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.135513</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.141158</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.146353</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.128436</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.124927</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.707692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.149893</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>0.126564</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.129008</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.146145</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.148067</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.142480</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.205722</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.690476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.193918</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.275211</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.162206</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.169272</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.707692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.219326</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.224784</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.227271</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.232714</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.229268</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.222868</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.233728</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.231222</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.255689</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255953</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256955</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.246334</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280094</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247107</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255892</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256997</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256257</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.260828</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277982</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277661</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f6f8381ae52d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_exkidBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 3,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b6ec4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6860\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6860' max='6860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6860/6860 41:47, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.282160</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.247600</td>\n",
       "      <td>0.287136</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.256600</td>\n",
       "      <td>0.220962</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.250985</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>0.242396</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.259498</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.268282</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.276600</td>\n",
       "      <td>0.253254</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.234738</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.261035</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.268600</td>\n",
       "      <td>0.240037</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.268500</td>\n",
       "      <td>0.256802</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>0.231157</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.284252</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.231900</td>\n",
       "      <td>0.263113</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.248381</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.221600</td>\n",
       "      <td>0.254936</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.239740</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.247594</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.266200</td>\n",
       "      <td>0.248070</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.258835</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.236510</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.239509</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.250701</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.257071</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.252476</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.286600</td>\n",
       "      <td>0.231135</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.242734</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.242616</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.252125</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.247900</td>\n",
       "      <td>0.248385</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.246034</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.244912</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.255400</td>\n",
       "      <td>0.256989</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.255868</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.255215</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>0.247382</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.267400</td>\n",
       "      <td>0.231914</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.241257</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.247614</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>0.254052</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.252687</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.245916</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.291600</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.239700</td>\n",
       "      <td>0.242093</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.260600</td>\n",
       "      <td>0.245911</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.232700</td>\n",
       "      <td>0.252747</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.244609</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>0.233665</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.246096</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.271000</td>\n",
       "      <td>0.239033</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.246597</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.245206</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.240023</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.249904</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.245825</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.242100</td>\n",
       "      <td>0.249437</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.237900</td>\n",
       "      <td>0.246742</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.262300</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.237800</td>\n",
       "      <td>0.248212</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.243130</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.242830</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.244552</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.247082</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.207800</td>\n",
       "      <td>0.247532</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\n",
      "Configuration saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_vanBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400 (score: 0.22096247971057892).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_vanBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7788713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3430\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3430' max='3430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3430/3430 21:07, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.239454</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.274639</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.273100</td>\n",
       "      <td>0.256213</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.239065</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.250157</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.267500</td>\n",
       "      <td>0.240655</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.263899</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.261025</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>0.260134</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.247814</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.270100</td>\n",
       "      <td>0.245890</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.263327</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.247430</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.240420</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.287600</td>\n",
       "      <td>0.239827</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.266903</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.237000</td>\n",
       "      <td>0.265533</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.269300</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.259846</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.265200</td>\n",
       "      <td>0.245701</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.244654</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>0.250916</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.243800</td>\n",
       "      <td>0.254377</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.275100</td>\n",
       "      <td>0.246060</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.240100</td>\n",
       "      <td>0.253252</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.252100</td>\n",
       "      <td>0.250047</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.250112</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.206800</td>\n",
       "      <td>0.253471</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.253231</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.291100</td>\n",
       "      <td>0.249392</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.248242</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.247399</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.247527</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.248225</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_vanBERT_results_largeData_batch16_wd1e-5\\checkpoint-400 (score: 0.23906463384628296).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_vanBERT_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0a2e7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3430\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2501' max='3430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2501/3430 15:42 < 05:50, 2.65 it/s, Epoch 7.29/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.238400</td>\n",
       "      <td>0.232751</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.244300</td>\n",
       "      <td>0.272742</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.257704</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.236690</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.245700</td>\n",
       "      <td>0.250994</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>1.205118</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>0.055474</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.105118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.266922</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.271600</td>\n",
       "      <td>0.262928</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.260988</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.248935</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.245122</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.201000</td>\n",
       "      <td>0.263527</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.245977</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.287400</td>\n",
       "      <td>0.238839</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.269417</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.236900</td>\n",
       "      <td>0.266925</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.251811</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.260363</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.264700</td>\n",
       "      <td>0.241994</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>0.245919</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.251274</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.256292</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.245893</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.254559</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-2100\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-2200\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-2300\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-2400\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERT_results_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-4-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_vanBERT_results_largeData_batch16\\checkpoint-2500\n",
      "Configuration saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_vanBERT_results_largeData_batch16\\checkpoint-2500\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fine_vanBERT_results_largeData_batch16\\\\checkpoint-100' is not in list\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_vanBERT_results_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf08b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5145\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5145' max='5145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5145/5145 55:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.289286</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.238307</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.183509</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.253758</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.219565</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.244622</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.171581</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.206051</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.178887</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.183770</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.204366</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.140624</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.134099</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.183703</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.177299</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.110983</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.131392</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.141215</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.150811</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>0.122946</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.174137</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.230630</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.196919</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.188834</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.158101</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.193632</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.239759</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.195551</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.258645</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.176311</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.262231</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.247311</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.286966</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.226271</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.279489</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.280146</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.239190</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.294162</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.261130</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.258961</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260414</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.276281</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276224</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-4000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-5000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-5000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-4100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-5100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-5100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-5100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-4200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_largeData/checkpoint-1800 (score: 0.1109827309846878).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d56d816e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5145\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5145' max='5145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5145/5145 55:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.289286</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.261555</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.238307</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.183509</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>0.253758</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.219565</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>0.244622</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.226400</td>\n",
       "      <td>0.171581</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.184300</td>\n",
       "      <td>0.206051</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.178887</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.193400</td>\n",
       "      <td>0.183770</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.163000</td>\n",
       "      <td>0.204366</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.158000</td>\n",
       "      <td>0.140624</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.204800</td>\n",
       "      <td>0.134099</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.112984</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>0.183703</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.177299</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.110983</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.131392</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.141215</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.150811</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>0.122946</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.174137</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.130120</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.230630</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.196919</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.188834</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.158101</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.193632</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.239759</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.195551</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.260998</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.258645</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.284465</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.176311</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.262231</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.247311</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.286966</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.226271</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.279489</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.280146</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.239190</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.294162</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.261130</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.258961</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.260414</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.276281</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276224</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-1900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-1900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2100/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-1900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-2900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-2900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-2900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-2900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-3900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-3900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-3900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4200\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4300\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4400\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4500\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4600\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4700\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4800\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-3900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-4900\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-4900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-4900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-4000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-5000\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-5000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-4100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData/checkpoint-5100\n",
      "Configuration saved in ./fine_mlm_results_largeData/checkpoint-5100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData/checkpoint-5100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData/checkpoint-4200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_largeData/checkpoint-1800 (score: 0.1109827309846878).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_largeData',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e889fd86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1774' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1774/2580 35:15 < 16:02, 0.84 it/s, Epoch 10.31/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.216300</td>\n",
       "      <td>0.279459</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.178715</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.159300</td>\n",
       "      <td>0.144170</td>\n",
       "      <td>0.924088</td>\n",
       "      <td>0.407895</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.543860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.133488</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.509091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.136027</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>0.200309</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.122523</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>0.112497</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.115251</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.125687</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.157990</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.135297</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.584615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.120432</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.130979</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.192963</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.130915</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.111877</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>0.146889</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.171835</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.193612</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.168859</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.147850</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.149850</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.162486</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.177339</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.176709</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.160360</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.175655</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.746269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.214065</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.219572</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.685714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.222198</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.194055</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-50/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2150] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-150/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-150/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2250] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-250/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2350] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-350/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2450] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-450/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-450/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-2550] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-550/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-550/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-50] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-650/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-650/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-150] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-750/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-750/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-250] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-850/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-850/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-350] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-950/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-950/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-450] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1050/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-550] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1150/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1150/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-650] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1250/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1250/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-750] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1350/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1350/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-850] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-950] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1450/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1450/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1050] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1550/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1150] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1650/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1650/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1250] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_largeData_batch16/checkpoint-1750\n",
      "Configuration saved in ./fine_mlm_results_largeData_batch16/checkpoint-1750/config.json\n",
      "Model weights saved in ./fine_mlm_results_largeData_batch16/checkpoint-1750/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_largeData_batch16/checkpoint-1300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_largeData_batch16',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 10,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093a9496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_largeData_batch16/checkpoint-1450/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_largeData_batch16/checkpoint-1450\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_largeData_batch16/checkpoint-1450/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_largeData_batch16/checkpoint-1450.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file ./fine_cli_results_largeData/checkpoint-2500/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_cli_results_largeData/checkpoint-2500\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_cli_results_largeData/checkpoint-2500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_cli_results_largeData/checkpoint-2500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results/checkpoint-360\",num_labels=2)\n",
    "test_trainer = Trainer(fine_tuned_model) \n",
    "\n",
    "new_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_largeData_batch16/checkpoint-1450\",num_labels=2)\n",
    "new_test_trainer = Trainer(new_fine_tuned_model)\n",
    "\n",
    "cli_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_cli_results_largeData/checkpoint-2500\",num_labels=2)\n",
    "cli_test_trainer = Trainer(cli_fine_tuned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e8c12c",
   "metadata": {},
   "source": [
    "### Test dataset report on old model (old Kidney BERT+Fine-tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e655fa64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[612  35]\n",
      " [ 16  22]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       647\n",
      "           1       0.39      0.58      0.46        38\n",
      "\n",
      "    accuracy                           0.93       685\n",
      "   macro avg       0.68      0.76      0.71       685\n",
      "weighted avg       0.94      0.93      0.93       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_pred,_,_=test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093a838",
   "metadata": {},
   "source": [
    "### Test dataset report on clinical BERT model (Clinical BERT+Fine-tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d464b364",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[642   5]\n",
      " [ 13  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       647\n",
      "           1       0.83      0.66      0.74        38\n",
      "\n",
      "    accuracy                           0.97       685\n",
      "   macro avg       0.91      0.83      0.86       685\n",
      "weighted avg       0.97      0.97      0.97       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_pred,_,_=cli_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021698b4",
   "metadata": {},
   "source": [
    "### Test dataset report on new model (new Kidney BERT+Fine-tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4019402c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[643   4]\n",
      " [ 12  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       647\n",
      "           1       0.87      0.68      0.76        38\n",
      "\n",
      "    accuracy                           0.98       685\n",
      "   macro avg       0.92      0.84      0.88       685\n",
      "weighted avg       0.98      0.98      0.98       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_pred,_,_=new_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc9fcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_pred,_,_=new_test_trainer.predict(test_dataset) \n",
    "fpr, tpr, threshold = roc_curve(test_labels,raw_pred[:,1])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ef25b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.00309119, 0.00309119,\n",
       "        0.00463679, 0.00463679, 0.00618238, 0.00618238, 0.01081917,\n",
       "        0.01081917, 0.01700155, 0.01700155, 0.01854714, 0.01854714,\n",
       "        0.02009274, 0.02009274, 0.0309119 , 0.0309119 , 0.03554869,\n",
       "        0.03554869, 0.05564142, 0.05564142, 0.07418856, 0.07418856,\n",
       "        0.07573416, 0.07573416, 0.12210201, 0.12210201, 0.34775889,\n",
       "        0.34775889, 0.67697063, 0.68006182, 0.72488408, 0.72797527,\n",
       "        0.91962906, 0.92272025, 1.        ]),\n",
       " array([0.        , 0.02631579, 0.44736842, 0.44736842, 0.55263158,\n",
       "        0.55263158, 0.60526316, 0.60526316, 0.68421053, 0.68421053,\n",
       "        0.73684211, 0.73684211, 0.76315789, 0.76315789, 0.78947368,\n",
       "        0.78947368, 0.81578947, 0.81578947, 0.84210526, 0.84210526,\n",
       "        0.86842105, 0.86842105, 0.89473684, 0.89473684, 0.92105263,\n",
       "        0.92105263, 0.94736842, 0.94736842, 0.97368421, 0.97368421,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " array([ 5.6692133,  4.6692133,  4.161791 ,  4.150569 ,  3.7121654,\n",
       "         3.5833712,  3.3040643,  2.6677418,  1.3670143, -1.9970909,\n",
       "        -2.989468 , -4.265552 , -4.2671847, -4.3056335, -4.49092  ,\n",
       "        -4.577364 , -4.706436 , -4.9251847, -4.935466 , -4.977488 ,\n",
       "        -4.997598 , -5.1525493, -5.1812706, -5.2506924, -5.252448 ,\n",
       "        -5.257949 , -5.258188 , -5.330442 , -5.330841 , -5.407668 ,\n",
       "        -5.4077325, -5.451825 , -5.4518585, -5.4566107, -5.4568977,\n",
       "        -5.4769764, -5.4776087, -5.5128727], dtype=float32))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e578bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[568  79]\n",
      " [  2  36]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93       647\n",
      "           1       0.31      0.95      0.47        38\n",
      "\n",
      "    accuracy                           0.88       685\n",
      "   macro avg       0.65      0.91      0.70       685\n",
      "weighted avg       0.96      0.88      0.91       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels = [1 if x > -5.330841 else 0 for x in raw_pred[:,1]]\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586c06f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a080d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 44:46, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.247531</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.217700</td>\n",
       "      <td>0.176730</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.127405</td>\n",
       "      <td>0.945985</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.160500</td>\n",
       "      <td>0.145680</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.136721</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.116155</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>0.097637</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.087800</td>\n",
       "      <td>0.160207</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.095625</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.132961</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.738462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.115859</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.160635</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.169961</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.183469</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.195644</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.194873</td>\n",
       "      <td>0.976642</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.191821</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.226938</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.218847</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.218510</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.228260</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224097</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.224796</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225297</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-100\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-200\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-300\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-400\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-500\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-600\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-700\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-800\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-900\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1000\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1100\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1200\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-700] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1300\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1400\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1500\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1600\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1700\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1800\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1800/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-1900\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-1900/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-1900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-2000\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-2000/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-2100\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-2100/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-2100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-2200\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-2200/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-2200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-2300\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-2300/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-2300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-1900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-2400/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-2400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-2000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cli_results_largeData/checkpoint-2500\n",
      "Configuration saved in ./fine_cli_results_largeData/checkpoint-2500/config.json\n",
      "Model weights saved in ./fine_cli_results_largeData/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cli_results_largeData/checkpoint-2100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cli_results_largeData/checkpoint-900 (score: 0.09562461823225021).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2580, training_loss=0.062025848511324894, metrics={'train_runtime': 2688.5228, 'train_samples_per_second': 15.276, 'train_steps_per_second': 0.96, 'total_flos': 1.08059710436352e+16, 'train_loss': 0.062025848511324894, 'epoch': 15.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cli_results_largeData',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=100*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 100*16/batch_size,\n",
    "    save_total_limit = 5,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51519a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424710b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48dce0ba",
   "metadata": {},
   "source": [
    "### Training dataset report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7756a79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 193\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[143   0]\n",
      " [  0  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00       193\n",
      "   macro avg       1.00      1.00      1.00       193\n",
      "weighted avg       1.00      1.00      1.00       193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_pred,_,_=test_trainer.predict(train_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(train_labels,pred_labels))\n",
    "print(classification_report(train_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46125b48",
   "metadata": {},
   "source": [
    "### Inference on Diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1348063e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 242\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[179   0]\n",
      " [ 63   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       179\n",
      "           1       0.00      0.00      0.00        63\n",
      "\n",
      "    accuracy                           0.74       242\n",
      "   macro avg       0.37      0.50      0.43       242\n",
      "weighted avg       0.55      0.74      0.63       242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "label_diag = []\n",
    "inputs_diag = []\n",
    "with torch.no_grad():\n",
    "    for k,v in data.items():\n",
    "        label_diag.append(v[\"isRejection\"])\n",
    "        inputs_diag.append(\" \".join(v[\"diag\"]))\n",
    "        \n",
    "diag_encodings = tokenizer(inputs_diag,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "diag_dataset = RenalDataset(diag_encodings, label_diag)\n",
    "\n",
    "raw_pred_diag,_,_=test_trainer.predict(diag_dataset) \n",
    "\n",
    "pred_labels_diag = np.argmax(raw_pred_diag, axis=1)\n",
    "print(confusion_matrix(label_diag,pred_labels_diag))\n",
    "print(classification_report(label_diag,pred_labels_diag))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b49c6",
   "metadata": {},
   "source": [
    "# Finetune New Model for isPolyomavirus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff8aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report\"].tolist()\n",
    "label1 = data[\"poly_infection\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f66c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b480b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "800231dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d296a6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./mlm_results_largeData/checkpoint-1100/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./mlm_results_largeData/checkpoint-1100\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./mlm_results_largeData/checkpoint-1100/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ./mlm_results_largeData/checkpoint-1100 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./mlm_results_largeData/checkpoint-1100 and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'bert.pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f94811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 44:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>0.053335</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.049897</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.055769</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>0.046489</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.050088</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.050370</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.055700</td>\n",
       "      <td>0.050254</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.048542</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.048571</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.044015</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>0.051195</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.043662</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.053641</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.052766</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.053353</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.051214</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.053587</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.061835</td>\n",
       "      <td>0.991241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.069754</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.075026</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.077499</td>\n",
       "      <td>0.988321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.989781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-900/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-500] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-700] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1800/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1800/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-800] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1900/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-1900/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-900] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2000/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-1000] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-2100\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2100/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2100/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-1100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-2200\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2200/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2200/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-1200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-2300\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2300/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2300/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-1300] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-2400\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2400/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2400/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-1400] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_poly_largeData_batch16/checkpoint-2500\n",
      "Configuration saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2500/config.json\n",
      "Model weights saved in ./fine_mlm_results_poly_largeData_batch16/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_poly_largeData_batch16/checkpoint-1600] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500 (score: 0.04366203397512436).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_poly_largeData_batch16',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=100*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 100*16/batch_size,\n",
    "    save_total_limit = 10,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dec1db1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_poly_largeData_batch16/checkpoint-1500\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_poly_largeData_batch16/checkpoint-1500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuuElEQVR4nO3debyWc/7H8denlJKEmEGbxoQWnDhTlklZsmQJhRiRLevYjW0GEzN+hjGDyRI1YWQfhMhYklAqpVVJVCciyZIWLZ/fH9/rOLfjnPvcdc51X/d9n/fz8bgf59ru6/pc1znn/tzX93tdn8vcHRERkcrUSToAERHJbUoUIiKSlhKFiIikpUQhIiJpKVGIiEhaShQiIpKWEoWsFzObbmbdko4jV5jZ1WZ2f0LbHmpmNyax7ZpmZr8zs5c38L36m4yZEkUeM7NPzGyFmS0zs0XRB8emcW7T3du7+6g4t1HKzDY2s5vMbH60nx+a2eVmZtnYfgXxdDOzktRp7v5Xdz8jpu2ZmV1gZtPM7HszKzGzJ8xslzi2t6HM7Hoz+0911uHuD7v7QRls62fJMZt/k7WVEkX+O8LdNwWKgI7AVcmGs/7MbKNKZj0BHAD0ABoDfYH+wO0xxGBmlmv/D7cDFwIXAFsCOwLPAIfV9IbS/A5il+S2JUPurleevoBPgANTxv8GvJAyvifwNvA18D7QLWXelsC/gU+BpcAzKfMOByZH73sb2LX8NoHtgBXAlinzOgJfAvWi8dOAmdH6RwKtUpZ14DzgQ+DjCvbtAGAl0KLc9M7AWuDX0fgo4CbgXeBb4NlyMaU7BqOAvwBvRfvya+DUKObvgLnAWdGyjaJl1gHLotd2wPXAf6Jlto/26xRgfnQsrknZXkPggeh4zAT+AJRU8rttE+1npzS//6HAQOCFKN5xwA4p828HFkTHZSLQJWXe9cCTwH+i+WcAnYB3omP1GfAvoH7Ke9oD/wO+Aj4HrgYOAX4AVkfH5P1o2SbA4Gg9C4EbgbrRvH7RMf8HsCSa1w8YE823aN4XUWxTgQ6ELwmro+0tA54r/38A1I3i+ig6JhMp9zek1wZ81iQdgF7V+OX99B+kefQPdXs03iz6J+xBOHPsHo1vHc1/AXgM2AKoB3SNpneM/kE7R/90p0Tb2biCbb4GnJkSzy3APdFwT2AO0BbYCPgj8HbKsh596GwJNKxg3/4PeKOS/Z5H2Qf4qOiDqAPhw/wpyj64qzoGowgf6O2jGOsRvq3vEH1YdQWWA7tHy3ej3Ac7FSeK+whJYTdgFdA2dZ+iY94cmFJ+fSnrPRuYV8Xvf2i0P52i+B8GHk2ZfxLQNJp3KbAIaJAS92rgqOjYNAT2ICTWjaJ9mQlcFC3fmPChfynQIBrvXP4YpGz7aeDe6HfyC0IiL/2d9QPWAL+PttWQnyaKgwkf8JtHv4e2wLYp+3xjmv+Dywn/BztF790NaJr0/2q+vxIPQK9q/PLCP8gywjcnB14FNo/mXQE8VG75kYQP/m0J34y3qGCddwM3lJs2i7JEkvpPeQbwWjRshG+v+0bjLwKnp6yjDuFDt1U07sD+afbt/tQPvXLzxhJ9Uyd82P9fyrx2hG+cddMdg5T3DqjiGD8DXBgNdyOzRNE8Zf67QJ9oeC5wcMq8M8qvL2XeNcDYKmIbCtyfMt4D+CDN8kuB3VLiHl3F+i8Cno6GTwAmVbLcj8cgGv8lIUE2TJl2AvB6NNwPmF9uHf0oSxT7A7MJSatOBfucLlHMAnpW939Lr5++cq1NVtbfUe7emPAhtjOwVTS9FXCsmX1d+gJ+S0gSLYCv3H1pBetrBVxa7n0tCM0s5T0F7GVm2wL7EpLPmynruT1lHV8RkkmzlPcvSLNfX0axVmTbaH5F65lHODPYivTHoMIYzOxQMxtrZl9Fy/eg7JhmalHK8HKg9AKD7cptL93+L6Hy/c9kW5jZZWY208y+ifalCT/dl/L7vqOZPR9dGPEt8NeU5VsQmnMy0YrwO/gs5bjfSzizqHDbqdz9NUKz10DgCzMbZGabZbjt9YlTMqREUSDc/Q3Ct61bo0kLCN+mN095NXL3/4vmbWlmm1ewqgXAX8q9bxN3f6SCbS4FXgaOB04knAF4ynrOKreehu7+duoq0uzSK0BnM2uROtHMOhM+DF5LmZy6TEtCk8qXVRyDn8VgZhsTkt+twC/dfXNgBCHBVRVvJj4jNDlVFHd5rwLNzax4QzZkZl0IfSDHEc4cNwe+oWxf4Of7czfwAdDG3TcjtPWXLr8A+FUlmyu/ngWEM4qtUo77Zu7ePs17frpC9zvcfQ/CGeKOhCalKt8XbXuHKpaR9aREUVj+CXQ3s90InZRHmNnBZlbXzBpEl3c2d/fPCE1Dd5nZFmZWz8z2jdZxH3C2mXWOrgRqZGaHmVnjSrY5DDgZ6B0Nl7oHuMrM2gOYWRMzOzbTHXH3Vwgflk+ZWftoH/aM9utud/8wZfGTzKydmW0CDACedPe16Y5BJZutD2wMLAbWmNmhQOolm58DTc2sSab7Uc7jhGOyhZk1A86vbMFo/+4CHolirh/F38fMrsxgW40J/QCLgY3M7Fqgqm/ljQmdx8vMbGfgnJR5zwPbmtlF0WXLjaOkDeG4bF961Vj09/Uy8Hcz28zM6pjZDmbWNYO4MbPfRH9/9YDvCRc1rEvZVmUJC0KT5Q1m1ib6+93VzJpmsl2pnBJFAXH3xcCDwLXuvoDQoXw14cNiAeFbWenvvC/hm/cHhM7ri6J1TADOJJz6LyV0SPdLs9nhhCt0Frn7+ymxPA3cDDwaNWNMAw5dz13qBbwOvEToi/kP4Uqa35db7iHC2dQiQkfrBVEMVR2Dn3D376L3Pk7Y9xOj/Sud/wHwCDA3alKpqDkunQFACfAx4YzpScI378pcQFkTzNeEJpWjgecy2NZIwnGbTWiOW0n6pi6Aywj7/B3hC8NjpTOiY9MdOIJwnD8E9otmPxH9XGJm70XDJxMS7wzCsXySzJrSICS0+6L3zSM0w90SzRsMtIuO/zMVvPc2wu/vZULSG0zoLJdqsLKWApH8Y2ajCB2pidwdXR1mdg6hozujb9oiSdEZhUiWmNm2ZrZP1BSzE+FS06eTjkukKrElCjMbYmZfmNm0Suabmd1hZnPMbIqZ7R5XLCI5oj7h6p/vCJ3xzxL6IURyWmxNT1Hn6DLgQXfvUMH8HoS25h6Em7tud/fO5ZcTEZFkxXZG4e6jCdfOV6YnIYm4u48FNo+uxxcRkRySZDGuZvz0KoySaNpn5Rc0s/6EOi80atRoj5133jkrAUrFZs2CFSugoa4lEcl5v1w1j03XfM37vuZLd996Q9aRF1Ub3X0QMAiguLjYJ0yYkHBEtVu3buHnqFFJRiEilSrtUjCDu++GL77Arr9+3oauLsmrnhby0ztTm0fTRERkQy1cCD17wrDo/tdzzoHrrqvWKpNMFMOBk6Orn/YEvonu6BQRkfXlDvfdB+3awSuvwLJlNbbq2JqezOwRQqG6rSw8Few6QqEw3P0eQg2dHoQ7f5cTngMgIiLr66OP4Mwz4fXXYb/9QsLYoeZKXsWWKNz9hCrmO+HBNSIiUh1Tp8LEiTBoEJxxRuibqEF50ZktIiLlTJsG770HJ58MRx0Fc+dC03jqH6qEh4hIPvnhB7j+eth9d7jmGli5MkyPKUmAEoWISP4YNy4kiD//GY4/HiZNggYNYt+smp5ERPLBwoXQpQv88pfw/PNw2GFZ27TOKEREctns2eFns2bw2GMwfXpWkwQoUYiI5Kavv4b+/WHnnWH06DDt6KNhs0wfH15z1PQkIpJrhg8Pd1QvWgSXXw6/+U2i4ShRiIjkkjPOgMGDYZdd4Nlnobg46YiUKEREEpdaxK+4GFq1giuugPr1k40rokQhIpKkBQvg7LOhTx/o2zcM5xh1ZouIJGHdulACvH37ULN/1aqkI6qUzihERLLtww9DX8To0XDggaFGU+vWSUdVKSUKEZFsmzEDpkyBIUOgX78aL+JX05QoRESy4f33YfJkOOWU8GChuXNhiy2Sjioj6qMQEYnTqlXwpz+Fq5n+9KeyIn55kiRAiUJEJD7vvAMdO8KNN8KJJ2atiF9NU9OTiEgcFi6Erl1hm21gxAg49NCkI9pgOqMQEalJM2eGn82aweOPhyJ+eZwkQIlCRKRmLF0Kp50G7drBm2+GaUcdBY0bJxpWTVDTk4hIdT39NJx7LixeDFddlXgRv5qmRCEiUh2nnQb//jcUFcELL4Qn0BUYJQoRkfWVWsRvzz2hTRu47DKoVy/ZuGKiRCEisj7mzYOzzgqXu558cni4UIFTZ7aISCbWrYOBA6FDBxgzBlavTjqirNEZhYhIVWbNCkX8xoyBgw6Ce++F7bdPOqqsUaIQEanKrFnhfoihQ0NzU44X8atpShQiIhWZNCkU8Tv1VDjyyFDEb/PNk44qEeqjEBFJtXIlXH11uBfi+uvLivjV0iQBShQiImXeeivcD3HTTaGJafLkvCziV9PU9CQiAqGI3377hRpNI0eGTmsBlCiyZtAgGDYs6ShqxuTJ4UuXSEGYMSPUZ2rWDJ56KiSLTTdNOqqcoqanLBk2LHzAFoKionCvkUhe++qr8BjS9u3Ds6sBjjhCSaICOqPIoqIiGDUq6ShEhKeegvPOgyVL4JproFOnpCPKaUoUIlK79OsHDzwQive99JLaUTOgRCEihS+1iN/ee0PbtnDppbCRPgIzEWsfhZkdYmazzGyOmV1ZwfyWZva6mU0ysylm1iPOeESkFvr443AF04MPhvH+/eGKK5Qk1kNsicLM6gIDgUOBdsAJZtau3GJ/BB53945AH+CuuOIRkVpm7Vq4445QxG/s2LKzCllvcZ5RdALmuPtcd/8BeBToWW4ZBzaLhpsAn8YYj4jUFjNnQpcucOGF0LVrqNPUr1/SUeWtOM+9mgELUsZLgM7llrkeeNnMfg80Ag6saEVm1h/oD9CyZcsaD1RECsycOaGQ30MPwe9+V+uK+NW0pO+jOAEY6u7NgR7AQ2b2s5jcfZC7F7t78dZbb531IEUkD0ycCEOGhOEjjgh9EyedpCRRA+JMFAuBFinjzaNpqU4HHgdw93eABsBWMcYkIoVmxQq48kro3BluuKGsiN9mm6V/n2QszkQxHmhjZq3NrD6hs3p4uWXmAwcAmFlbQqJYHGNMIlJIRo+G3XaDm28OfRCTJqmIXwxi66Nw9zVmdj4wEqgLDHH36WY2AJjg7sOBS4H7zOxiQsd2P3ddmiAiGVi4EA44AFq0gFdeCcMSi1gvJHb3EcCIctOuTRmeAewTZwwiUmCmToVddglF/J5+OhTxa9Qo6agKWtKd2SIimfnyS+jbF3bdtayI3+GHK0lkgW5NFJHc5g5PPAHnnw9Ll8J114WOa8kaJQoRyW2nnBLuhyguhldfDc1OklVKFCKSe1KL+HXtGpqbLrpI9ZkSoj4KEcktc+fCgQfC0KFh/PTT4bLLlCQSpEQhIrlh7Vr45z9D09L48VBHH0+5QilaRJI3YwacdhqMGweHHQb33APNmycdlUSUKEQkeR9/DB99FB4u36eP6jPlGCUKEUnG+PEweTKceWY4i5g7Fxo3TjoqqYAaAUUku5YvD53Te+4JN91UVsRPSSJnKVGISPaMGhUudf3738OZhIr45QU1PYlIdpSUQPfu0KoVvPZaqNEkeUFnFCISr/ffDz+bN4dnn4UpU5Qk8owShYjEY/FiOPFEKCqCN94I03r0gE02STQsWX9qehKRmuUOjz4KF1wA33wDf/4z7LVX0lFJNShRiEjN6tsXHn44VHgdPBjat086IqmmjBOFmW3i7svjDEZE8tS6deEmObPQ/7DHHuGMom7dpCOTGlBlH4WZ7W1mM4APovHdzOyu2CMTkfwwZ054DOm//x3GTz8dLr5YSaKAZNKZ/Q/gYGAJgLu/D+wbZ1AikgfWrIFbbw1F/CZNgvr1k45IYpJR05O7L7Cf1l5ZG084IpIXpk2DU0+FCROgZ0+46y7Ybruko5KYZJIoFpjZ3oCbWT3gQmBmvGGJSE6bPx/mzQtXNx13nIr4FbhMEsXZwO1AM2Ah8DJwbpxBiUgOGjcu3DzXv3+4H2LuXNh006SjkizIJFHs5O6/S51gZvsAb8UTUv4aNChUSa7I5MnhviORvPP99/CnP4WHCv3qV+EZ1htvrCRRi2TSmX1nhtNqvWHDQkKoSFFRuElVJK+89loo4vePf8DZZ8N774UkIbVKpWcUZrYXsDewtZldkjJrM0DXvVWiqCgUyBTJeyUlcPDB0Lp1KMGxry52rK3SNT3VBzaNlkktFP8t0DvOoEQkQZMmQceOoYjfc89B167QsGHSUUmCKk0U7v4G8IaZDXX3eVmMSUSS8Pnn4W7qxx8Pp8Vdu8IhhyQdleSATDqzl5vZLUB74McnjLj7/rFFJSLZ4x5qM114ISxbBjfeCHvvnXRUkkMy6cx+mFC+ozXwZ+ATYHyMMYlINp14Yijkt9NO4WqMa66BevWSjkpySCZnFE3dfbCZXZjSHKVEIZLPUov4HXRQKAN+3nmqzyQVyuSMYnX08zMzO8zMOgJbxhiTiMRp9uxQ4XXIkDB+6qmq9CppZXJGcaOZNQEuJdw/sRlwUZxBiUgM1qyB226D666DBg10JZNkrMpE4e7PR4PfAPvBj3dmi0i+mDIFTjsNJk6Eo4+GgQNh222TjkryRLob7uoCxxFqPL3k7tPM7HDgaqAh0DE7IYpItZWUwIIF8MQT0KuXivjJeknXRzEYOANoCtxhZv8BbgX+5u4ZJQkzO8TMZpnZHDO7spJljjOzGWY23cwqqZQkIuvt7bfhnnvCcGkRv969lSRkvaVreioGdnX3dWbWAFgE7ODuSzJZcXRGMhDoDpQA481suLvPSFmmDXAVsI+7LzWzX2zojohIZNmycInrnXfCDjuEzuqNN4ZGjZKOTPJUujOKH9x9HYC7rwTmZpokIp2AOe4+191/AB4FepZb5kxgoLsvjbbzxXqsX0TKe/ll6NAhJInzzlMRP6kR6c4odjazKdGwATtE4wa4u+9axbqbAQtSxkuAzuWW2RHAzN4iFBq83t1fKr8iM+sP9Ado2bJlFZsVqaUWLIDDDgtnEaNHw29/m3REUiDSJYq2Wdp+G6Ab0BwYbWa7uPvXqQu5+yBgEEBxcbFnIS6R/DFxIuyxB7RoASNGQJcu4fJXkRpSadOTu89L98pg3QuBFinjzaNpqUqA4e6+2t0/BmYTEoeIVGXRIjj2WCguDmXAAbp3V5KQGpfJndkbajzQxsxam1l9oA8wvNwyzxDOJjCzrQhNUXNjjEkk/7nDAw9Au3ahDPhf/6oifhKrTO7M3iDuvsbMzgdGEvofhrj7dDMbAExw9+HRvIPMbAawFrh8PTvMRWqfPn1CKfB99oH774edd046IilwGSUKM2sItHT3WeuzcncfAYwoN+3alGEHLoleIlKZ1CJ+PXqEfohzz4U6cTYKiARV/pWZ2RHAZOClaLzIzMo3IYlIXD74IDyGdPDgMH7KKXD++UoSkjWZ/KVdT7gn4msAd59MeDaFiMRp9erQ/7DbbjBjBmy6adIRSS2VSdPTanf/xn56278uURWJ0+TJ4Y7qyZND2Y0774Rttkk6KqmlMkkU083sRKBuVHLjAuDteMMSqeUWLQqvp56CY45JOhqp5TJpevo94XnZq4BhhHLjF8UYk0jtNGYM3HVXGD7kEPjoIyUJyQmZJIqd3f0ad/9N9PpjVPtJRGrCd9+FzukuXeCf/4RVq8L0TTZJNCyRUpkkir+b2Uwzu8HMOsQekUhtMnJkKOJ3111w4YUq4ic5qcpE4e77EZ5stxi418ymmtkfY49MpNAtWACHHx7OHMaMCWcTurJJclBGF2K7+yJ3vwM4m3BPxbXp3yEiFXKHd98Nwy1awIsvwqRJKsEhOS2TG+7amtn1ZjYVuJNwxVPz2CMTKTSffRYeQ9q5c1kRvwMPVBE/yXmZXB47BHgMONjdP405HpHC4w5Dh8Ill8DKlXDzzaFOk0ieqDJRuPte2QhEpGAddxw8+WS4qun++2HHHZOOSGS9VJoozOxxdz8uanJKvRM70yfcidRea9eGAn516sARR8D++8NZZ6k+k+SldGcUF0Y/D89GICIFY+ZMOP30UILjzDPh5JOTjkikWtI94e6zaPDcCp5ud252whPJI6tXw403QlERzJoFTZokHZFIjcikM7s7cEW5aYdWMC1nDRoEw4bFv53Jk8NnhNRCkyZBv34wZQocfzzccQf84hdJRyVSI9L1UZxDOHP4lZlNSZnVGHgr7sBq0rBh2fkQLyqCE0+MdxuSoz7/HL78Ep55Bnr2TDoakRqV7oxiGPAicBNwZcr079z9q1ijikFREYwalXQUUlBGj4apU+G880IRvzlzoGHDpKMSqXHpLsFwd/8EOA/4LuWFmW0Zf2giOerbb8NjSLt2DU1MpUX8lCSkQFV1RnE4MJFweWzqk4sc+FWMcYnkphEjwmWun34abqAbMEBF/KTgVZoo3P3w6KceeyoCoYhfz56w007hBrrOnZOOSCQrMqn1tI+ZNYqGTzKz28ysZfyhieQAdxg7Ngy3aAEvvxxKgStJSC2SyW2idwPLzWw34FLgI+ChWKMSyQWffgpHHQV77VVWxG+//aB+/UTDEsm2TBLFGnd3oCfwL3cfSLhEVqQwuYeaTO3ahTOIW29VET+p1TK54e47M7sK6At0MbM6QL14wxJJUO/e8N//hqua7r8ffv3rpCMSSVQmZxTHA6uA09x9EeFZFLfEGpVItq1dC+vWheGjjoJ77oHXXlOSECGzR6EuAh4GmpjZ4cBKd38w9shEsmXatNC0NHhwGO/bV5VeRVJkctXTccC7wLHAccA4M+sdd2AisfvhB/jzn2H33eGjj2CLLZKOSCQnZdJHcQ3wG3f/AsDMtgZeAZ6MMzCRWE2cGIr4TZsWCnT985+w9dZJRyWSkzJJFHVKk0RkCZn1bYjkriVL4Ouv4bnn4HA9ckUknUwSxUtmNhJ4JBo/HhgRX0giMXn99VDE74IL4KCD4MMPoUGDpKMSyXmZdGZfDtwL7Bq9Brl73jyLQoRvvgmd0/vvD3ffXVbET0lCJCPpnkfRBrgV2AGYClzm7guzFZhIjXjuOTj7bFi0CC67LHReq4ifyHpJd0YxBHge6EWoIHtnViISqSkLFkCvXtC0aajXdMstsMkmSUclknfS9VE0dvf7ouFZZvZeNgISqRZ3eOcd2HvvsiJ+e++t+kwi1ZDujKKBmXU0s93NbHegYbnxKpnZIWY2y8zmmNmVaZbrZWZuZsXruwMiPyopgSOPDDfPlRbx69ZNSUKkmtKdUXwG3JYyvihl3IH9063YzOoCA4HuQAkw3syGu/uMcss1Bi4Exq1f6CKRdevgvvvg8sthzRq47Tb47W+TjkqkYKR7cNF+1Vx3J2COu88FMLNHCRVoZ5Rb7gbgZuDyam5PaqteveCZZ8JVTffdB7/SwxdFalKcN841AxakjJdE034UNWG1cPcX0q3IzPqb2QQzm7B48eKaj1Tyz5o1ZUX8evUKCeKVV5QkRGKQ2B3WUbny2wgPQ0rL3Qe5e7G7F2+tMgsyZUp4mNB90bUWJ50EZ5wBZunfJyIbJM5EsRBokTLePJpWqjHQARhlZp8AewLD1aEtlVq1Cq67DvbYA+bNU20mkSzJpHqsRc/KvjYab2lmnTJY93igjZm1NrP6QB9geOlMd//G3bdy9+3dfXtgLHCku0/YoD2RwjZ+fKjyOmAAnHACzJwJxxyTdFQitUImZxR3AXsBJ0Tj3xGuZkrL3dcA5wMjgZnA4+4+3cwGmNmRGxiv1FZLl8KyZTBiBDz4YLiJTkSyIpOigJ3dfXczmwTg7kujM4QqufsIyhUQdPdrK1m2WybrlFrktddCEb8LLwxF/GbPVvkNkQRkckaxOronwuHH51GsizUqqd2+/hrOPBMOOADuvbesiJ+ShEgiMkkUdwBPA78ws78AY4C/xhqV1F7PPgvt2sGQIfCHP4QHDClBiCSqyqYnd3/YzCYCBwAGHOXuM2OPTGqf+fPh2GOhbVsYPhyKdQGcSC6oMlGYWUtgOfBc6jR3nx9nYFJLuMOYMdClC7RsGW6a23NP1WcSySGZdGa/QOifMKAB0BqYBbSPMS6pDebPD8+KePFFGDUKunaFffdNOioRKSeTpqddUsejshvnxhaRFL516+Cee+CKK8IZxR13qIifSA7L5IziJ9z9PTPrHEcwUkscc0zotO7eHQYNgu23TzoiEUkjkz6KS1JG6wC7A5/GFtEGGDQIhg2rfP7kyVBUlK1opEJr1kCdOuF1/PHQsyf066f6TCJ5IJPLYxunvDYm9Fn0jDOo9TVsWEgGlSkqghNPzFY08jPvvw+dO4eMDqEEx6mnKkmI5Im0ZxTRjXaN3f2yLMWzwYqKQn+o5JCVK+HGG+Hmm2HLLWGbbZKOSEQ2QKWJwsw2cvc1ZrZPNgOSAvHuu3DKKfDBB+HnbbeFZCEieSfdGcW7hP6IyWY2HHgC+L50prv/N+bYJJ99+y2sWAEvvQQHH5x0NCJSDZlc9dQAWEJ4Rnbp/RQOKFHIT738MkyfDhdfDAceCLNmqfyGSAFIlyh+EV3xNI2yBFHKY41K8svSpXDJJTB0KLRvD+eeGxKEkoRIQUh31VNdYNPo1ThluPQlAv/9byji99BDcNVVMGGCEoRIgUl3RvGZuw/IWiSSf+bPhz59oEOH8EChjh2TjkhEYpDujEIXucvPucMbb4Thli3Dw4XGjVOSEClg6RLFAVmLQvLDvHlw6KHQrVtZsvjtb6FevUTDEpF4VZoo3P2rbAYiOWzdOvjXv0JH9ZgxcOedoSy4iNQK610UUGqho46C554L90Pcey+0apV0RCKSRUoUUrHVq6Fu3VDE74QToHdv6NtX9ZlEaqFMigJKbfPee9CpU3hmBIREcfLJShIitZQShZRZsSLcC9GpEyxaBC1aJB2RiOQANT1JMHZsKN43ezacdhrceitssUXSUYlIDlCikOD770O/xP/+F+o0iYhElChqs5deCkX8Lr0UDjgglASvXz/pqEQkx6iPojZasiQ0Mx16KDzwAPzwQ5iuJCEiFVCiqE3c4cknQxG/YcPgj3+E8eOVIEQkLTU91Sbz54eHh++6a3h2xG67JR2RiOQBnVEUOvdQuA/CHdWjRoUrnJQkRCRDShSF7OOP4aCDQkd1aRG/vfeGjXQiKSKZU6IoRGvXwu23h+dEjBsHd9+tIn4issH01bIQ9ewJL7wAPXqEMhy6w1pEqkGJolCkFvHr2zfUZzrxRNVnEpFqi7XpycwOMbNZZjbHzK6sYP4lZjbDzKaY2atmpvrVG2LCBCguDk1MAMcfD7/7nZKEiNSI2BKFmdUFBgKHAu2AE8ysXbnFJgHF7r4r8CTwt7jiKUgrVsAVV0DnzrB4sZ4TISKxiPOMohMwx93nuvsPwKNAz9QF3P11d18ejY4FmscYT2F5551wievf/haK+M2YAYcfnnRUIlKA4uyjaAYsSBkvATqnWf504MWKZphZf6A/QMuWLWsqvvy2YkV4ROkrr4TLX0VEYpITndlmdhJQDHStaL67DwIGARQXF3sWQ8stI0aEIn6XXw777w8zZ0K9eklHJSIFLs6mp4VA6nWZzaNpP2FmBwLXAEe6+6oY48lfX34JJ50Ehx0GDz9cVsRPSUJEsiDORDEeaGNmrc2sPtAHGJ66gJl1BO4lJIkvYowlP7nDo49C27bw+ONw3XXw7rsq4iciWRVb05O7rzGz84GRQF1giLtPN7MBwAR3Hw7cAmwKPGHhUs757n5kXDHlnfnzQznw3XaDwYNhl12SjkhEaqFY+yjcfQQwoty0a1OG9Si18tzh1VfDU+ZatQo1mn7zm3AznYhIAlTrKZd89FG4gql797IifnvuqSQhIonK60QxaBB06waTJycdSTWtXQu33RaaliZOhHvvVRE/EckZOXF57IYaNiwkiaKiUNYobx1xBLz4Yrhh7u67obnuOxSR3JHXiQJCkhg1KukoNsAPP4TnQtSpA/36hUJ+ffqoPpOI5Jy8bnrKW+++C3vsAXfdFcaPOy5Ue1WSEJEcpESRTcuXw6WXwl57wdKlsMMOSUckIlKlvG96yhtjxoR7IubOhbPOgptvhiZNko5KRKRKShTZUvpgoddfD5dqiYjkCSWKOD33XCjc94c/wH77hVLgG+mQi0h+UR9FHBYvDtfrHnkkPPJIWRE/JQkRyUNKFDXJPdzc0bYtPPkkDBgA48apiJ+I5DV9xa1J8+fDqadCx46hiF/79klHJCJSbTqjqK5162DkyDDcqhW8+Sa89ZaShIgUDCWK6vjww/CkuUMOgdGjw7ROnVTET0QKihLFhlizBm65BXbdNRSbGjxYRfxEpGCpj2JDHH54aG7q2TOU4dhuu6QjEhGJjRJFplatCs+orlMHzjgDTjsNjj1W9ZlEpOCp6SkTY8fC7rvDwIFhvHfvUMhPSUJEagElinS+/x4uvhj23hu++w7atEk6IhGRrFPTU2XefDMU8fv4Yzj3XLjpJthss6SjEhHJOiWKyqxZE/ok3ngD9t036WhERBKjRJHqmWdCEb+rrgpF/KZPV30mEan11EcB8PnnoXP66KNDjSYV8RMR+VHtThTu8NBD0K4dPPss/OUv4QonFfETEflR7f7KPH9+uCeiuDjcXb3zzklHJCKSc2pfoigt4nfooaGI31tvhWqvqs8kInli9erVlJSUsHLlyp/Na9CgAc2bN6devXo1tr3alShmzw5nEG++CaNGQdeu4WxCRCSPlJSU0LhxY7bffnss5cZfd2fJkiWUlJTQunXrGtte7eijWLMGbr45FPGbOhX+/W9d8ioieWvlypU0bdr0J0kCwMxo2rRphWca1VE7zigOOwxefhmOOSaU4dhmm6QjEhGplvJJoqrp1VG4iWLlynDDXN260L9/ePXqlXRUIiJ5pzCbnt56C4qKyor49eqlJCEisoEKK1EsWwYXXBAeIrRyJbRtm3REIiKxcPf1ml4dhZMo3ngDOnSAf/0Lzj8fpk2D7t2TjkpEpMY1aNCAJUuW/CwplF711KBBgxrdXmH1UWyySbj0dZ99ko5ERCQ2zZs3p6SkhMWLF/9sXul9FDUprxNFl8X/peXyD4Crwz0RU6fqxjkRKXj16tWr0fskqhJr05OZHWJms8xsjpldWcH8jc3ssWj+ODPbPqMVL1oEvXtzw4xedFnydFkRPyUJEZEaF1uiMLO6wEDgUKAdcIKZtSu32OnAUnf/NfAP4OYqV7xkSeikfv55BrW+ifOK3lYRPxGRGMV5RtEJmOPuc939B+BRoGe5ZXoCD0TDTwIHWBV3i/gn85iyrgN9d32fP3x1JWvr1Fw9ExER+bk4+yiaAQtSxkuAzpUt4+5rzOwboCnwZepCZtYf6B+Nrtrt2zHTGB8qvb7xBsRwI2K+2Ipyx6oW07Eoo2NRRseizE4b+sa86Mx290HAIAAzm+DuquSHjkUqHYsyOhZldCzKmNmEDX1vnE1PC4EWKePNo2kVLmNmGwFNgCUxxiQiIuspzkQxHmhjZq3NrD7QBxhebpnhwCnRcG/gNY/jtkIREdlgsTU9RX0O5wMjgbrAEHefbmYDgAnuPhwYDDxkZnOArwjJpCqD4oo5D+lYlNGxKKNjUUbHoswGHwvTF3gREUmncGo9iYhILJQoREQkrZxNFLGV/8hDGRyLS8xshplNMbNXzaxVEnFmQ1XHImW5XmbmZlawl0ZmcizM7Ljob2O6mQ3LdozZksH/SEsze93MJkX/Jz2SiDNuZjbEzL4ws2mVzDczuyM6TlPMbPeMVuzuOfcidH5/BPwKqA+8D7Qrt8y5wD3RcB/gsaTjTvBY7AdsEg2fU5uPRbRcY2A0MBYoTjruBP8u2gCTgC2i8V8kHXeCx2IQcE403A74JOm4YzoW+wK7A9Mqmd8DeBEwYE9gXCbrzdUziljKf+SpKo+Fu7/u7suj0bGEe1YKUSZ/FwA3EOqG1ewT5nNLJsfiTGCguy8FcPcvshxjtmRyLBzYLBpuAnyaxfiyxt1HE64grUxP4EEPxgKbm9m2Va03VxNFReU/mlW2jLuvAUrLfxSaTI5FqtMJ3xgKUZXHIjqVbuHuL2QzsARk8nexI7Cjmb1lZmPN7JCsRZddmRyL64GTzKwEGAH8Pjuh5Zz1/TwB8qSEh2TGzE4CioGuSceSBDOrA9wG9Es4lFyxEaH5qRvhLHO0me3i7l8nGVRCTgCGuvvfzWwvwv1bHdx9XdKB5YNcPaNQ+Y8ymRwLzOxA4BrgSHdflaXYsq2qY9EY6ACMMrNPCG2wwwu0QzuTv4sSYLi7r3b3j4HZhMRRaDI5FqcDjwO4+ztAA0LBwNomo8+T8nI1Uaj8R5kqj4WZdQTuJSSJQm2HhiqOhbt/4+5bufv27r49ob/mSHff4GJoOSyT/5FnCGcTmNlWhKaouVmMMVsyORbzgQMAzKwtIVH8/DmihW84cHJ09dOewDfu/llVb8rJpiePr/xH3snwWNwCbAo8EfXnz3f3IxMLOiYZHotaIcNjMRI4yMxmAGuBy9294M66MzwWlwL3mdnFhI7tfoX4xdLMHiF8Odgq6o+5DqgH4O73EPpnegBzgOXAqRmttwCPlYiI1KBcbXoSEZEcoUQhIiJpKVGIiEhaShQiIpKWEoWIiKSlRCE5yczWmtnklNf2aZZdVgPbG2pmH0fbei+6e3d913G/mbWLhq8uN+/t6sYYraf0uEwzs+fMbPMqli8q1Eqpkj26PFZykpktc/dNa3rZNOsYCjzv7k+a2UHAre6+azXWV+2YqlqvmT0AzHb3v6RZvh+hgu75NR2L1B46o5C8YGabRs/aeM/MpprZz6rGmtm2ZjY65Rt3l2j6QWb2TvTeJ8ysqg/w0cCvo/deEq1rmpldFE1rZGYvmNn70fTjo+mjzKzYzP4PaBjF8XA0b1n081EzOywl5qFm1tvM6prZLWY2PnpOwFkZHJZ3iAq6mVmnaB8nmdnbZrZTdJfyAOD4KJbjo9iHmNm70bIVVd8V+amk66frpVdFL8KdxJOj19OEKgKbRfO2ItxZWnpGvCz6eSlwTTRcl1D7aSvCB3+jaPoVwLUVbG8o0DsaPhYYB+wBTAUaEe58nw50BHoB96W8t0n0cxTR8y9KY0pZpjTGo4EHouH6hEqeDYH+wB+j6RsDE4DWFcS5LGX/ngAOicY3AzaKhg8EnoqG+wH/Snn/X4GTouHNCfWfGiX9+9Yrt185WcJDBFjh7kWlI2ZWD/irme0LrCN8k/4lsCjlPeOBIdGyz7j7ZDPrSnhQzVtReZP6hG/iFbnFzP5IqAF0OqE20NPu/n0Uw3+BLsBLwN/N7GZCc9Wb67FfLwK3m9nGwCHAaHdfETV37WpmvaPlmhAK+H1c7v0NzWxytP8zgf+lLP+AmbUhlKioV8n2DwKONLPLovEGQMtoXSIVUqKQfPE7YGtgD3dfbaE6bIPUBdx9dJRIDgOGmtltwFLgf+5+QgbbuNzdnywdMbMDKlrI3WdbeO5FD+BGM3vV3QdkshPuvtLMRgEHA8cTHrID4Yljv3f3kVWsYoW7F5nZJoTaRucBdxAe1vS6ux8ddfyPquT9BvRy91mZxCsC6qOQ/NEE+CJKEvsBP3suuIVnhX/u7vcB9xMeCTkW2MfMSvscGpnZjhlu803gKDPbxMwaEZqN3jSz7YDl7v4fQkHGip47vDo6s6nIY4RibKVnJxA+9M8pfY+Z7Rhts0Ienmh4AXCplZXZLy0X3S9l0e8ITXClRgK/t+j0ykLlYZG0lCgkXzwMFJvZVOBk4IMKlukGvG9mkwjf1m9398WED85HzGwKodlp50w26O7vEfou3iX0Wdzv7pOAXYB3oyag64AbK3j7IGBKaWd2OS8THi71iodHd0JIbDOA98xsGqFsfNoz/iiWKYSH8vwNuCna99T3vQ60K+3MJpx51Itimx6Ni6Sly2NFRCQtnVGIiEhaShQiIpKWEoWIiKSlRCEiImkpUYiISFpKFCIikpYShYiIpPX/WjMnXAqGVykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_poly_largeData_batch16/checkpoint-1500\",num_labels=2)\n",
    "poly_test_trainer = Trainer(poly_fine_tuned_model) \n",
    "raw_pred,_,_=poly_test_trainer.predict(test_dataset) \n",
    "fpr, tpr, threshold = roc_curve(test_labels,raw_pred[:,1])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1b84fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.00147275, 0.01030928, 0.01030928, 0.0191458 ,\n",
       "        0.0191458 , 0.04270987, 0.04270987, 0.08836524, 0.09131075,\n",
       "        0.11929308, 0.11929308, 0.13991163, 0.13991163, 0.2916053 ,\n",
       "        0.2916053 , 1.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.16666667, 0.16666667,\n",
       "        0.33333333, 0.33333333, 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.66666667, 0.66666667, 0.83333333, 0.83333333,\n",
       "        1.        , 1.        ]),\n",
       " array([ 1.0451297 ,  0.04512969, -0.7204098 , -0.77648747, -1.1161269 ,\n",
       "        -1.1819223 , -1.5454829 , -1.5538887 , -2.0171494 , -2.0263326 ,\n",
       "        -2.2912147 , -2.2997682 , -2.4341824 , -2.4374282 , -3.0565283 ,\n",
       "        -3.0578592 , -3.898161  ], dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fb6ce48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[584  95]\n",
      " [  2   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92       679\n",
      "           1       0.04      0.67      0.08         6\n",
      "\n",
      "    accuracy                           0.86       685\n",
      "   macro avg       0.52      0.76      0.50       685\n",
      "weighted avg       0.99      0.86      0.92       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels = [1 if x > -2.4374282 else 0 for x in raw_pred[:,1]]\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b30d7",
   "metadata": {},
   "source": [
    "# Finetune New Model for IFTA 4labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddf4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report\"].tolist()\n",
    "label1 = data[\"IFTA\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c917154",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "label = [0 if l in [\"nosig\",\"minimal\",\"noinfo\"] else 1 for l in label2]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5aaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "label = [0 if l in [\"nosig\",\"minimal\",\"noinfo\"] else (1 if l==\"mild\" else (2 if l==\"moderate\" else 3)) for l in label2]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4195432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2444fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred,average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49097e12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mlm_results_largeData_extended_tokenizer/checkpoint-1100 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./mlm_results_largeData_extended_tokenizer/checkpoint-1100 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\",num_labels=4)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=4)\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData_extended_tokenizer/checkpoint-1100\",num_labels=4)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\",num_labels=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4595ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.053200</td>\n",
       "      <td>0.791820</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.652951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.813400</td>\n",
       "      <td>0.706268</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.655492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.749000</td>\n",
       "      <td>0.694519</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.669204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.753696</td>\n",
       "      <td>0.680292</td>\n",
       "      <td>0.680292</td>\n",
       "      <td>0.680292</td>\n",
       "      <td>0.628765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.639975</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.729725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.695442</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.705799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.659200</td>\n",
       "      <td>0.666660</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.666407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.664100</td>\n",
       "      <td>0.638096</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.729343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.639439</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.689931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.587391</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.751725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.573200</td>\n",
       "      <td>0.596641</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.750085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.541500</td>\n",
       "      <td>0.564677</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.758972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.529700</td>\n",
       "      <td>0.627492</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.736579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.493600</td>\n",
       "      <td>0.601766</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.748417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>0.559162</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.763259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.558994</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.761706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>0.657018</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.758528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.788806</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.733908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.599436</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.777047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.581736</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.775548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.327500</td>\n",
       "      <td>0.690289</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.756222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.293800</td>\n",
       "      <td>0.698214</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.745321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.786688</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.741913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>0.736774</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.756372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.227100</td>\n",
       "      <td>0.764563</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.775991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.834526</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.772247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>0.871938</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.756812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.772283</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.882174</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.763325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>0.888933</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.772286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>0.869444</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.771053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.930357</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.924311</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.778731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>0.926318</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.775454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800 (score: 0.5589938759803772).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.43524026149927186, metrics={'train_runtime': 1176.4362, 'train_samples_per_second': 23.274, 'train_steps_per_second': 1.462, 'total_flos': 7204110059028480.0, 'train_loss': 0.43524026149927186, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e726a1b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:34, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.117900</td>\n",
       "      <td>0.825132</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.638509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.815600</td>\n",
       "      <td>0.693323</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.670370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>0.732824</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>0.620212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.638288</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.685744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.698300</td>\n",
       "      <td>0.688315</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.628203</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.737862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.635400</td>\n",
       "      <td>0.658185</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.682683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>0.647326</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.698469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.589800</td>\n",
       "      <td>0.621179</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.713611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.570200</td>\n",
       "      <td>0.686406</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.703207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.614800</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.729294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.602851</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.736870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.541600</td>\n",
       "      <td>0.649269</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.740930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>0.645992</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.708303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.603228</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.755264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.580238</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.742535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.459900</td>\n",
       "      <td>0.632746</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.730986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>0.712483</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.743467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.621533</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.743903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.580101</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.759284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>0.644537</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.732178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.655577</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.754329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>0.700622</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.748632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.403900</td>\n",
       "      <td>0.674137</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.744392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.643027</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.762827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.277500</td>\n",
       "      <td>0.725949</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.755338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.722019</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.743310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.280200</td>\n",
       "      <td>0.683670</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.766905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.268200</td>\n",
       "      <td>0.724648</td>\n",
       "      <td>0.779562</td>\n",
       "      <td>0.779562</td>\n",
       "      <td>0.779562</td>\n",
       "      <td>0.772709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>0.721449</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.757755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.220800</td>\n",
       "      <td>0.734789</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.762770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.735018</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.774690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.731191</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.773453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.175500</td>\n",
       "      <td>0.748064</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.763759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000 (score: 0.5801013708114624).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4814317460670028, metrics={'train_runtime': 1176.9718, 'train_samples_per_second': 23.263, 'train_steps_per_second': 1.461, 'total_flos': 7204110059028480.0, 'train_loss': 0.4814317460670028, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4937e783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>0.798756</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.695720</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.719402</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.646434</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.651195</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.626138</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.613128</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.593151</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.572117</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.666607</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.583680</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.602828</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.592849</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.576115</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.696709</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.722401</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.728717</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.802285</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.854360</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.898031</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.911389</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.949623</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600 (score: 0.5721173882484436).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4371066925137542, metrics={'train_runtime': 1193.3504, 'train_samples_per_second': 22.944, 'train_steps_per_second': 1.441, 'total_flos': 7204110059028480.0, 'train_loss': 0.4371066925137542, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2840708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2817' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2817/3440 32:08 < 07:06, 1.46 it/s, Epoch 16.37/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.082600</td>\n",
       "      <td>0.832251</td>\n",
       "      <td>0.649635</td>\n",
       "      <td>0.649635</td>\n",
       "      <td>0.649635</td>\n",
       "      <td>0.594353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.803200</td>\n",
       "      <td>0.725592</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.669213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.711215</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.671332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.662900</td>\n",
       "      <td>0.628336</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.738075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.699400</td>\n",
       "      <td>0.666878</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.693153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.585060</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.744130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.591232</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.733569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.613890</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.738821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.624093</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.728393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.536800</td>\n",
       "      <td>0.604265</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.750196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>0.688888</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.741806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.543500</td>\n",
       "      <td>0.613143</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.699005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.629802</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.766409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>0.645985</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.743668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.422400</td>\n",
       "      <td>0.618034</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.774778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.462900</td>\n",
       "      <td>0.610232</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.747817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.607352</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.760514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.361300</td>\n",
       "      <td>0.650410</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.351700</td>\n",
       "      <td>0.770923</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.738495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.765775</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.747779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.344500</td>\n",
       "      <td>0.738100</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.747099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.294800</td>\n",
       "      <td>0.702759</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.767961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.700298</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.760778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.706408</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.764660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.214600</td>\n",
       "      <td>0.881522</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.734325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>0.870528</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.759942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.896745</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.779336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>0.944940</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.776849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.908062</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.778887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.874577</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.778861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.943872</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.771123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>1.009949</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.784328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>1.022447</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.769264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.131800</td>\n",
       "      <td>1.055986</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.789186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>1.093788</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.759821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>1.178526</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.766905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>1.252426</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>1.246350</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.761433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>1.224592</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.763894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>1.331711</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.763229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>1.347715</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.775425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>1.284662</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.771511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>1.492541</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.770155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>1.463255</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.775904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>1.459274</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.777349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>1.426023</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.773698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>1.529980</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.758111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>1.542813</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.768302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>1.398852</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.767179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>1.405927</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.773687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>1.712001</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.764699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>1.547597</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.777508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>1.598827</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.775204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>1.623898</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.768642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>1.602086</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.772414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.589327</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.777321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_bioBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720f59e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.990500</td>\n",
       "      <td>0.758615</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.792100</td>\n",
       "      <td>0.691256</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.745400</td>\n",
       "      <td>0.681075</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.661200</td>\n",
       "      <td>0.648920</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.670400</td>\n",
       "      <td>0.661237</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.629094</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.592628</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>0.591421</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>0.592813</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.627654</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.556700</td>\n",
       "      <td>0.612361</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.513900</td>\n",
       "      <td>0.571326</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.600316</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.484700</td>\n",
       "      <td>0.613330</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.403900</td>\n",
       "      <td>0.615314</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.603075</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.406100</td>\n",
       "      <td>0.598215</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.365900</td>\n",
       "      <td>0.637638</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.340300</td>\n",
       "      <td>0.694690</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.640048</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.335300</td>\n",
       "      <td>0.641466</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.645686</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "      <td>0.783942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.253300</td>\n",
       "      <td>0.707916</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.261700</td>\n",
       "      <td>0.689494</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.765679</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.198100</td>\n",
       "      <td>0.743555</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.199600</td>\n",
       "      <td>0.775621</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.168200</td>\n",
       "      <td>0.796248</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.162400</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>0.791241</td>\n",
       "      <td>0.791241</td>\n",
       "      <td>0.791241</td>\n",
       "      <td>0.791241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.162300</td>\n",
       "      <td>0.805463</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.126300</td>\n",
       "      <td>0.779602</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>0.792701</td>\n",
       "      <td>0.792701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.812945</td>\n",
       "      <td>0.794161</td>\n",
       "      <td>0.794161</td>\n",
       "      <td>0.794161</td>\n",
       "      <td>0.794161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.820538</td>\n",
       "      <td>0.791241</td>\n",
       "      <td>0.791241</td>\n",
       "      <td>0.791241</td>\n",
       "      <td>0.791241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.117400</td>\n",
       "      <td>0.816378</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.795620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-7-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600 (score: 0.5713257193565369).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4045818965102351, metrics={'train_runtime': 1178.3204, 'train_samples_per_second': 23.236, 'train_steps_per_second': 1.46, 'total_flos': 7204110059028480.0, 'train_loss': 0.4045818965102351, 'epoch': 10.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_bioBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 3,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110a48f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1588' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1588/2580 17:58 < 11:14, 1.47 it/s, Epoch 9.23/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.064600</td>\n",
       "      <td>0.756067</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.633415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.778400</td>\n",
       "      <td>0.692418</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.695014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.745400</td>\n",
       "      <td>0.676375</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.670293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.654000</td>\n",
       "      <td>0.611749</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.741708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.619887</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.722257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.616300</td>\n",
       "      <td>0.580796</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.751332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>0.595783</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.729576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.597700</td>\n",
       "      <td>0.610067</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.726758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.512400</td>\n",
       "      <td>0.632559</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.729761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.657278</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.722523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.653106</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.724932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.596308</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.754685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>0.624407</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.756559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.481800</td>\n",
       "      <td>0.647439</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.757816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.627795</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.423300</td>\n",
       "      <td>0.645258</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.733882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.658871</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.752269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.694164</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.752197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.680886</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.749802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.786462</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.764647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.756357</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.734757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.246000</td>\n",
       "      <td>0.751230</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.744250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.836718</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.747394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.245200</td>\n",
       "      <td>0.856266</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.747980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.959999</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.740333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>1.011179</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.718741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.158500</td>\n",
       "      <td>0.909842</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.752511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>1.011550</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.751888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>1.114973</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.744913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>1.115165</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.749568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.144500</td>\n",
       "      <td>1.222750</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.752874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d742d61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1701' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1701/2580 19:13 < 09:57, 1.47 it/s, Epoch 9.88/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.747587</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.670091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.661478</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.667099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.734500</td>\n",
       "      <td>0.634644</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.698857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.638800</td>\n",
       "      <td>0.644422</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.622456</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.698836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>0.595209</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.736187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.604900</td>\n",
       "      <td>0.584894</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.750801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.586500</td>\n",
       "      <td>0.630096</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.726158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.528200</td>\n",
       "      <td>0.584605</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.751707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.489500</td>\n",
       "      <td>0.620400</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.746969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.532800</td>\n",
       "      <td>0.608502</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.750530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.588035</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.740115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.594293</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.757023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>0.589995</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.756542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.595060</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.772310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.419600</td>\n",
       "      <td>0.585147</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.757536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>0.598379</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.773983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.609570</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.759737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.302600</td>\n",
       "      <td>0.672308</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.774188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.731767</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.763432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.709686</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.755555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.737635</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.779737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.791774</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.768848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.772359</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.757709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>0.870250</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.762828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.886025</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.744502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.916215</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.757553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>0.995487</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.762533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>1.025289</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.745457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>1.008063</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.751976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.129100</td>\n",
       "      <td>1.083507</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.758378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>1.212925</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.762525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>1.191852</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.744352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5/11 00:02 < 00:03, 1.51 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dfb58d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 20:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.048700</td>\n",
       "      <td>0.814612</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.712199</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.740900</td>\n",
       "      <td>0.676847</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.654700</td>\n",
       "      <td>0.611833</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.644400</td>\n",
       "      <td>0.614967</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.590438</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.594900</td>\n",
       "      <td>0.598589</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.572400</td>\n",
       "      <td>0.613279</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.611483</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.517200</td>\n",
       "      <td>0.671728</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.585132</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.474200</td>\n",
       "      <td>0.585015</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.390900</td>\n",
       "      <td>0.644382</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>0.665585</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.347600</td>\n",
       "      <td>0.636609</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.680319</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.717180</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.804487</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>0.826737</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.780093</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.822262</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>0.858725</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.150600</td>\n",
       "      <td>0.893726</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>0.965695</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.146900</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.958499</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.030151</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>1.022825</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>1.045893</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>1.085118</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>1.090085</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>1.091535</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650 (score: 0.5850153565406799).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 3,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975faf0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.129500</td>\n",
       "      <td>0.944522</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.563856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.874700</td>\n",
       "      <td>0.726332</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.654389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.804800</td>\n",
       "      <td>0.763113</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.672993</td>\n",
       "      <td>0.626272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>0.737253</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.664686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>0.716758</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.713015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.668982</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.703040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.676200</td>\n",
       "      <td>0.679453</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.706461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.663500</td>\n",
       "      <td>0.682153</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.705735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.600400</td>\n",
       "      <td>0.643007</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.708104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.603400</td>\n",
       "      <td>0.775869</td>\n",
       "      <td>0.659854</td>\n",
       "      <td>0.659854</td>\n",
       "      <td>0.659854</td>\n",
       "      <td>0.676687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.619800</td>\n",
       "      <td>0.641273</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.731768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.629614</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.723221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>0.624694</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.714218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.560200</td>\n",
       "      <td>0.687751</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.716217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.487200</td>\n",
       "      <td>0.597822</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.741680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.549600</td>\n",
       "      <td>0.596343</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.745698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.628725</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.494900</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.745980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.663772</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.743818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.682043</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.720464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.628026</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.754567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.751422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.712332</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.733033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.704382</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.745076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>0.735144</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.744143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>0.723800</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.751066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.705444</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.754843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.739168</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.762297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.772054</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.752960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.275700</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.763899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.222500</td>\n",
       "      <td>0.790639</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.826000</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.763416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.819847</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.761676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.825295</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.762998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800 (score: 0.5963426232337952).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_vanBERTcased_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a90621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1303' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1303/1720 14:40 < 04:42, 1.48 it/s, Epoch 7.57/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.070400</td>\n",
       "      <td>0.903064</td>\n",
       "      <td>0.595620</td>\n",
       "      <td>0.595620</td>\n",
       "      <td>0.595620</td>\n",
       "      <td>0.595620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.869100</td>\n",
       "      <td>0.734066</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.795300</td>\n",
       "      <td>0.821656</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.739800</td>\n",
       "      <td>0.672216</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.667618</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.671694</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.678200</td>\n",
       "      <td>0.665106</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.676300</td>\n",
       "      <td>0.658970</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.605300</td>\n",
       "      <td>0.624236</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.572800</td>\n",
       "      <td>0.694177</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.616900</td>\n",
       "      <td>0.576107</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.575655</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.561800</td>\n",
       "      <td>0.627536</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.744009</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.486700</td>\n",
       "      <td>0.627668</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.595217</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.448800</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.440400</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.664885</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.444800</td>\n",
       "      <td>0.678643</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.376300</td>\n",
       "      <td>0.665569</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>0.742330</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.337600</td>\n",
       "      <td>0.718619</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.721797</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.257000</td>\n",
       "      <td>0.857774</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.785288</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_vanBERTcased_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-244cb6877b73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_vanBERTcased_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a39ba53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>0.798756</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.695720</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.719402</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.646434</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.651195</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.626138</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.613128</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.593151</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.572117</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.666607</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.583680</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.602828</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.592849</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.576115</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.696709</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.722401</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.728717</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.802285</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.854360</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.898031</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.911389</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.949623</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600 (score: 0.5721173882484436).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4371066925137542, metrics={'train_runtime': 1193.3504, 'train_samples_per_second': 22.944, 'train_steps_per_second': 1.441, 'total_flos': 7204110059028480.0, 'train_loss': 0.4371066925137542, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "410476ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>0.798756</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.695720</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.719402</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.646434</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.651195</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.626138</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.613128</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.593151</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.572117</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.666607</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.583680</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.602828</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.592849</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.576115</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.696709</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.722401</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.728717</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.802285</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.854360</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.898031</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.911389</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.949623</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600 (score: 0.5721173882484436).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4371066925137542, metrics={'train_runtime': 1193.3504, 'train_samples_per_second': 22.944, 'train_steps_per_second': 1.441, 'total_flos': 7204110059028480.0, 'train_loss': 0.4371066925137542, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e57f01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>0.798756</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.695720</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.719402</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.646434</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.651195</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.626138</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.613128</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.593151</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.572117</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.666607</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.583680</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.602828</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.592849</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.576115</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.696709</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.722401</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.728717</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.802285</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.854360</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.898031</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.911389</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.949623</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600 (score: 0.5721173882484436).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4371066925137542, metrics={'train_runtime': 1193.3504, 'train_samples_per_second': 22.944, 'train_steps_per_second': 1.441, 'total_flos': 7204110059028480.0, 'train_loss': 0.4371066925137542, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04743f55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 19:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.024100</td>\n",
       "      <td>0.798756</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.695720</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.719402</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.646434</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.695400</td>\n",
       "      <td>0.651195</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.661700</td>\n",
       "      <td>0.631863</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.626138</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.613128</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.571800</td>\n",
       "      <td>0.593151</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.576800</td>\n",
       "      <td>0.599471</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.572117</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.536000</td>\n",
       "      <td>0.594691</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.666607</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.470300</td>\n",
       "      <td>0.583680</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.602828</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.423800</td>\n",
       "      <td>0.592849</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.779589</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.627572</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.576115</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.343900</td>\n",
       "      <td>0.696709</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.611969</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.831469</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>0.722401</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.225600</td>\n",
       "      <td>0.728717</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.776050</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.802285</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>0.809409</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.854360</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.898031</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.154900</td>\n",
       "      <td>0.911389</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>0.935658</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.165800</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.949623</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-d1d2f2990db6>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600 (score: 0.5721173882484436).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1720, training_loss=0.4371066925137542, metrics={'train_runtime': 1193.3504, 'train_samples_per_second': 22.944, 'train_steps_per_second': 1.441, 'total_flos': 7204110059028480.0, 'train_loss': 0.4371066925137542, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc5033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1555' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1555/2580 17:39 < 11:39, 1.47 it/s, Epoch 9.03/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.049900</td>\n",
       "      <td>0.758938</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.642080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.764900</td>\n",
       "      <td>0.685762</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.694325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.741400</td>\n",
       "      <td>0.668219</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.697535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.670300</td>\n",
       "      <td>0.642596</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.742402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.650734</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.707830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.636700</td>\n",
       "      <td>0.583526</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.737267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.594300</td>\n",
       "      <td>0.621376</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.707737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.593900</td>\n",
       "      <td>0.611106</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.741527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.652628</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.727848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.630854</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.706747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.643946</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.749716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.599591</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.738817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.477500</td>\n",
       "      <td>0.604248</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.762514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.607522</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.760721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.423700</td>\n",
       "      <td>0.627876</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.743844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.614554</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.770260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.636092</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.756315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.311800</td>\n",
       "      <td>0.650352</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.758553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.328600</td>\n",
       "      <td>0.639333</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.770109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.748827</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.761097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.281900</td>\n",
       "      <td>0.735232</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.748417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.659332</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.785401</td>\n",
       "      <td>0.784607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.761024</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.763032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.744741</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.770796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>0.868602</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.763476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.918705</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.750654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.843330</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.771243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>0.939882</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.769943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.947064</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.995658</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.758139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>1.004554</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.778102</td>\n",
       "      <td>0.779047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d40e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2008' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2008/2580 22:51 < 06:31, 1.46 it/s, Epoch 11.67/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.032100</td>\n",
       "      <td>0.743654</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.658339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.768100</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.693577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>0.671507</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.687820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>0.650305</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.722381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.668800</td>\n",
       "      <td>0.651278</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.697643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.613200</td>\n",
       "      <td>0.601414</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.739195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>0.583139</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.772386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.578500</td>\n",
       "      <td>0.617981</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.731946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.592220</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.757184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.515300</td>\n",
       "      <td>0.617855</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.616242</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.753310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.579448</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.751618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>0.607204</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.757820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.590427</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.774012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.387300</td>\n",
       "      <td>0.668242</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.763510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.589336</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>0.617274</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.756588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.308400</td>\n",
       "      <td>0.669368</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.761015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.664046</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.762990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.701815</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.771559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.302100</td>\n",
       "      <td>0.697202</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.745014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.214200</td>\n",
       "      <td>0.730540</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.752444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.830601</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.750979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.848666</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.729582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>0.947511</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.762760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.154700</td>\n",
       "      <td>1.051184</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.746971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.977755</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.748857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>1.045361</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.754539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>1.077649</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.752516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>1.022556</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.750943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>1.113848</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.750756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>1.176983</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.766436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>1.153478</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>1.146334</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.751527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.231169</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.741557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.268594</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.756648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>1.321501</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.755938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>1.394507</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.741599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>1.414006</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>1.400612</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.755978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ebb2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 34:10, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.015900</td>\n",
       "      <td>0.744287</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.729727</td>\n",
       "      <td>0.674453</td>\n",
       "      <td>0.674453</td>\n",
       "      <td>0.674453</td>\n",
       "      <td>0.674453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>0.634581</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.635200</td>\n",
       "      <td>0.636945</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.636400</td>\n",
       "      <td>0.620463</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>0.578580</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.572303</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.635799</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.530900</td>\n",
       "      <td>0.614590</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "      <td>0.728467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.513900</td>\n",
       "      <td>0.603926</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>0.606816</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.443400</td>\n",
       "      <td>0.597228</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.601574</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.430900</td>\n",
       "      <td>0.608411</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.664766</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.646078</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "      <td>0.769343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.620418</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.251100</td>\n",
       "      <td>0.670433</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "      <td>0.767883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.252700</td>\n",
       "      <td>0.654251</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.781022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.254700</td>\n",
       "      <td>0.708646</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.765909</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>0.742377</td>\n",
       "      <td>0.789781</td>\n",
       "      <td>0.789781</td>\n",
       "      <td>0.789781</td>\n",
       "      <td>0.789781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.781189</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.780261</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "      <td>0.786861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.935985</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.872786</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.145100</td>\n",
       "      <td>0.912403</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>1.000513</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.937780</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.979901</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.984003</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>1.034392</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>1.032458</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "      <td>0.782482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>1.037921</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1350/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1450/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1550/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1650/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350 (score: 0.5723028779029846).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33729d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1457' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1457/1720 29:11 < 05:16, 0.83 it/s, Epoch 8.47/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.489062</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>0.698133</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.339426</td>\n",
       "      <td>0.837956</td>\n",
       "      <td>0.837956</td>\n",
       "      <td>0.837956</td>\n",
       "      <td>0.837956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.394600</td>\n",
       "      <td>0.405774</td>\n",
       "      <td>0.858394</td>\n",
       "      <td>0.858394</td>\n",
       "      <td>0.858394</td>\n",
       "      <td>0.858394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.368293</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.325724</td>\n",
       "      <td>0.855474</td>\n",
       "      <td>0.855474</td>\n",
       "      <td>0.855474</td>\n",
       "      <td>0.855474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.318666</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.306600</td>\n",
       "      <td>0.330523</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.861314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.304657</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>0.349651</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.303900</td>\n",
       "      <td>0.313515</td>\n",
       "      <td>0.872993</td>\n",
       "      <td>0.872993</td>\n",
       "      <td>0.872993</td>\n",
       "      <td>0.872993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.368461</td>\n",
       "      <td>0.816058</td>\n",
       "      <td>0.816058</td>\n",
       "      <td>0.816058</td>\n",
       "      <td>0.816058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.333779</td>\n",
       "      <td>0.851095</td>\n",
       "      <td>0.851095</td>\n",
       "      <td>0.851095</td>\n",
       "      <td>0.851095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.279500</td>\n",
       "      <td>0.366855</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.849635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.309430</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.426355</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.355406</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>0.862774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.340427</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.391551</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.856934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.321940</td>\n",
       "      <td>0.874453</td>\n",
       "      <td>0.874453</td>\n",
       "      <td>0.874453</td>\n",
       "      <td>0.874453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.364061</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>0.877372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.235900</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "      <td>0.870073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>0.402609</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.875912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.401696</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.432775</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.884672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.179800</td>\n",
       "      <td>0.390974</td>\n",
       "      <td>0.878832</td>\n",
       "      <td>0.878832</td>\n",
       "      <td>0.878832</td>\n",
       "      <td>0.878832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.417480</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.875912</td>\n",
       "      <td>0.875912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.204300</td>\n",
       "      <td>0.441230</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.427339</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>0.877372</td>\n",
       "      <td>0.877372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-50/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-150/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-250/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-350/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-450/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-550/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-650/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-750/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-850/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-950/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1050/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1050/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1150/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1250/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1350/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1450/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_clibert_ifta_2labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed36dcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1122' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1122/1720 22:14 < 11:52, 0.84 it/s, Epoch 6.52/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.016500</td>\n",
       "      <td>0.845944</td>\n",
       "      <td>0.614599</td>\n",
       "      <td>0.614599</td>\n",
       "      <td>0.614599</td>\n",
       "      <td>0.614599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.810400</td>\n",
       "      <td>0.717486</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.745800</td>\n",
       "      <td>0.740492</td>\n",
       "      <td>0.661314</td>\n",
       "      <td>0.661314</td>\n",
       "      <td>0.661314</td>\n",
       "      <td>0.661314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.686857</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.703500</td>\n",
       "      <td>0.643531</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.589342</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>0.614603</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.619964</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.609787</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.539800</td>\n",
       "      <td>0.643342</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.556800</td>\n",
       "      <td>0.592334</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "      <td>0.776642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>0.600202</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.521400</td>\n",
       "      <td>0.609511</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.567761</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.598912</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.770803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.593248</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.609573</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.773723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.355900</td>\n",
       "      <td>0.647959</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.336400</td>\n",
       "      <td>0.643076</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>0.653876</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.323100</td>\n",
       "      <td>0.716864</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.641087</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-50/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-150/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-250/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-350/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-450/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-550/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-650/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-750/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-850/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-950/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1050/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1050/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=4)\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_clibert_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466a372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./fine_mlm_results_largeData_batch16/checkpoint-1450 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1707' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1707/1720 34:05 < 00:15, 0.83 it/s, Epoch 9.92/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.070200</td>\n",
       "      <td>0.804527</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.652555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.713910</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.761800</td>\n",
       "      <td>0.711712</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.653100</td>\n",
       "      <td>0.697373</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.675374</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.633513</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.640288</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>0.616602</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.547700</td>\n",
       "      <td>0.628265</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.565500</td>\n",
       "      <td>0.626583</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.664894</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.640562</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.494500</td>\n",
       "      <td>0.620032</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.612423</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.711370</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.671058</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.387900</td>\n",
       "      <td>0.698244</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.333500</td>\n",
       "      <td>0.734457</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.709146</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.348900</td>\n",
       "      <td>0.767844</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.773723</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.812472</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.237200</td>\n",
       "      <td>0.821161</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.197100</td>\n",
       "      <td>0.968318</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.955153</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.217100</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.990913</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.144400</td>\n",
       "      <td>1.029794</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.988860</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "      <td>0.754745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.146100</td>\n",
       "      <td>1.010472</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>1.020531</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>1.054830</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>1.050167</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-50/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-100/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-150/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-200/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-250/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-300/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-350/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-400/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-450/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-500/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-550/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-650/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-700/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-750/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-800/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-850/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-900/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-950/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1000/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1050/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1050/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1100/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1150/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1200/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1250/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1300/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1350/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1400/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1450/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1500/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1550/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-50] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1600/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1650/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-150] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1700/config.json\n",
      "Model weights saved in ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model_isRejection = AutoModelForSequenceClassification.\\\n",
    "from_pretrained(\"./fine_mlm_results_largeData_batch16/checkpoint-1450\",num_labels=4,ignore_mismatched_sizes=True)\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_isRejection,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5d1a5c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_ifta_binary_largeData_batch16/checkpoint-600/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_ifta_binary_largeData_batch16/checkpoint-600\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_ifta_binary_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_ifta_binary_largeData_batch16/checkpoint-600.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322  45]\n",
      " [ 45 273]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       367\n",
      "           1       0.86      0.86      0.86       318\n",
      "\n",
      "    accuracy                           0.87       685\n",
      "   macro avg       0.87      0.87      0.87       685\n",
      "weighted avg       0.87      0.87      0.87       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifta2_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_ifta_binary_largeData_batch16/checkpoint-600\",num_labels=2)\n",
    "ifta2_test_trainer = Trainer(ifta2_fine_tuned_model) \n",
    "raw_pred,_,_=ifta2_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0112b75d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[301  66]\n",
      " [ 20 298]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88       367\n",
      "           1       0.82      0.94      0.87       318\n",
      "\n",
      "    accuracy                           0.87       685\n",
      "   macro avg       0.88      0.88      0.87       685\n",
      "weighted avg       0.88      0.87      0.87       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clibert_ifta2_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_clibert_ifta_2labels_largeData_batch16/checkpoint-1000\",num_labels=2)\n",
    "clibert_ifta2_test_trainer = Trainer(clibert_ifta2_fine_tuned_model) \n",
    "raw_pred,_,_=clibert_ifta2_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a892e1be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_ifta_4labels_largeData_batch16/checkpoint-900/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_ifta_4labels_largeData_batch16/checkpoint-900\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_ifta_4labels_largeData_batch16/checkpoint-900/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_ifta_4labels_largeData_batch16/checkpoint-900.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[323  41   3   0]\n",
      " [ 37 160  26   1]\n",
      " [  3  23  45   1]\n",
      " [  1   3   9   9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       367\n",
      "           1       0.70      0.71      0.71       224\n",
      "           2       0.54      0.62      0.58        72\n",
      "           3       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.78       685\n",
      "   macro avg       0.74      0.66      0.68       685\n",
      "weighted avg       0.79      0.78      0.78       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifta4_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_ifta_4labels_largeData_batch16/checkpoint-900\",num_labels=4)\n",
    "ifta4_test_trainer = Trainer(ifta4_fine_tuned_model) \n",
    "raw_pred,_,_=ifta4_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e77659e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[322  41   4   0]\n",
      " [ 31 173  20   0]\n",
      " [  4  31  37   0]\n",
      " [  1   4  14   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       367\n",
      "           1       0.69      0.77      0.73       224\n",
      "           2       0.49      0.51      0.50        72\n",
      "           3       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.78       685\n",
      "   macro avg       0.77      0.57      0.59       685\n",
      "weighted avg       0.79      0.78      0.78       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifta4_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850\",num_labels=4)\n",
    "ifta4_test_trainer = Trainer(ifta4_fine_tuned_model) \n",
    "raw_pred,_,_=ifta4_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2609d7ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[327  39   1   0]\n",
      " [ 50 160  13   1]\n",
      " [  5  29  37   1]\n",
      " [  2   2  13   5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       367\n",
      "           1       0.70      0.71      0.70       224\n",
      "           2       0.58      0.51      0.54        72\n",
      "           3       0.71      0.23      0.34        22\n",
      "\n",
      "    accuracy                           0.77       685\n",
      "   macro avg       0.71      0.59      0.62       685\n",
      "weighted avg       0.77      0.77      0.77       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clibert_ifta4_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_clibert_ifta_4labels_largeData_batch16/checkpoint-800\",num_labels=4)\n",
    "clibert_ifta4_test_trainer = Trainer(clibert_ifta4_fine_tuned_model) \n",
    "raw_pred,_,_=clibert_ifta4_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b728fac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[293  72   2   0]\n",
      " [ 25 174  24   1]\n",
      " [  1  28  41   2]\n",
      " [  1   5  10   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       367\n",
      "           1       0.62      0.78      0.69       224\n",
      "           2       0.53      0.57      0.55        72\n",
      "           3       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.75       685\n",
      "   macro avg       0.68      0.60      0.62       685\n",
      "weighted avg       0.77      0.75      0.75       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "isRej_bert_ifta4_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600\",num_labels=4)\n",
    "isRej_bert_ifta4_test_trainer = Trainer(isRej_bert_ifta4_fine_tuned_model) \n",
    "raw_pred,_,_=isRej_bert_ifta4_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba9274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bd160e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d6a001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[589  58]\n",
      " [ 20  18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       647\n",
      "           1       0.24      0.47      0.32        38\n",
      "\n",
      "    accuracy                           0.89       685\n",
      "   macro avg       0.60      0.69      0.63       685\n",
      "weighted avg       0.93      0.89      0.90       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rej_ifta = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16/checkpoint-600\",num_labels=2,ignore_mismatched_sizes=True)\n",
    "model_isRejection = AutoModelForSequenceClassification.\\\n",
    "from_pretrained(\"./fine_mlm_results_largeData_batch16/checkpoint-1450\",num_labels=2)\n",
    "\n",
    "model_rej_ifta.classifier = model_isRejection.classifier\n",
    "model_rej_ifta_test_trainer = Trainer(model_rej_ifta) \n",
    "\n",
    "try:\n",
    "    raw_pred,_,_=model_rej_ifta_test_trainer.predict(test_dataset) \n",
    "    pred_labels = np.argmax(raw_pred, axis=1)\n",
    "    print(confusion_matrix(test_labels,pred_labels))\n",
    "    print(classification_report(test_labels,pred_labels))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fec3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152ef68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8740f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48692e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59a1494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_datasets(q,train_text,test_text,tokenizer=tokenizer):\n",
    "    train_q = [q for i in range(len(train_text))]\n",
    "    test_q = [q for i in range(len(test_text))]\n",
    "\n",
    "    train_encodings = tokenizer(train_q,train_text,padding=\"max_length\", truncation=True, \n",
    "                                return_tensors=\"pt\",max_length=512)\n",
    "    test_encodings = tokenizer(test_q,test_text,padding=\"max_length\", truncation=True, \n",
    "                                return_tensors=\"pt\",max_length=512)\n",
    "    train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "    test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "    return train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268f93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_rej = \"Is there any rejection?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_rej,train_text,test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969a35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./qaRej_fine_mlm_results_largeData_batch16_padding',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3588f94c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file ./mlm_results_largeData/checkpoint-1100/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./mlm_results_largeData/checkpoint-1100\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./mlm_results_largeData/checkpoint-1100/pytorch_model.bin\n",
      "Some weights of the model checkpoint at ./mlm_results_largeData/checkpoint-1100 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./mlm_results_largeData/checkpoint-1100 and are newly initialized: ['classifier.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1720' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1720/1720 34:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.289600</td>\n",
       "      <td>0.228592</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.273546</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.242300</td>\n",
       "      <td>0.214299</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.203400</td>\n",
       "      <td>0.178727</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.174513</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.270110</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.222657</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.154800</td>\n",
       "      <td>0.140657</td>\n",
       "      <td>0.940146</td>\n",
       "      <td>0.472727</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.559140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.115459</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.110839</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.118552</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.655738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>0.117534</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.143800</td>\n",
       "      <td>0.098203</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.119233</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.169253</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.688525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>0.115554</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.130719</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.026300</td>\n",
       "      <td>0.137298</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.154926</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.143864</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.162275</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.162853</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.151824</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.160862</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.170403</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.163903</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.776119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.163773</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.168756</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.167656</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.169112</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.170329</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.170225</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-50\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-50/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-100\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-100/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-150\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-150/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-200\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-200/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-250\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-250/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-300\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-300/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-350\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-350/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-400\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-400/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-450\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-450/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-500\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-500/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-550\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-550/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-600\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-600/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-650\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-650/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-700\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-700/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-750\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-750/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-800\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-800/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-850\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-850/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-900\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-900/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-950\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-950/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1000\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1000/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1050\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1050/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1050/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1100\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1100/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1150\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1150/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1200\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1200/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1250\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1250/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1300\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1300/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1350\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1350/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1450\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1450/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1500\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1500/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1550\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1550/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-50] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1600\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1600/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-100] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1650\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1650/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-150] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1700\n",
      "Configuration saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1700/config.json\n",
      "Model weights saved in ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-200] due to args.save_total_limit\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-700 (score: 0.0982029139995575).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9ea639c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[644   3]\n",
      " [ 12  26]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       647\n",
      "           1       0.90      0.68      0.78        38\n",
      "\n",
      "    accuracy                           0.98       685\n",
      "   macro avg       0.94      0.84      0.88       685\n",
      "weighted avg       0.98      0.98      0.98       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_isRejection_qa = AutoModelForSequenceClassification.\\\n",
    "from_pretrained(\"./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400\",num_labels=2)\n",
    "\n",
    "model_isRejection_qa = Trainer(model_isRejection_qa) \n",
    "\n",
    "raw_pred,_,_=model_isRejection_qa.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44bd6cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./qaRej_fine_mlm_results_largeData_batch16_padding/checkpoint-1450/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qaRej_fine_mlm_results_largeData_batch16_padding/checkpoint-1450\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./qaRej_fine_mlm_results_largeData_batch16_padding/checkpoint-1450/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./qaRej_fine_mlm_results_largeData_batch16_padding/checkpoint-1450.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[639   8]\n",
      " [ 13  25]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       647\n",
      "           1       0.76      0.66      0.70        38\n",
      "\n",
      "    accuracy                           0.97       685\n",
      "   macro avg       0.87      0.82      0.84       685\n",
      "weighted avg       0.97      0.97      0.97       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_isRejection_qa = AutoModelForSequenceClassification.\\\n",
    "from_pretrained(\"./qaRej_fine_mlm_results_largeData_batch16_padding/checkpoint-1450\",num_labels=2)\n",
    "\n",
    "model_isRejection_qa = Trainer(model_isRejection_qa) \n",
    "\n",
    "raw_pred,_,_=model_isRejection_qa.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27fce3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ifta = \"What is the grade of interstitial fibrosis and tubular atrophy?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_ifta,train_text,test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5126f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([4, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([4]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1254' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1254/1720 24:51 < 09:15, 0.84 it/s, Epoch 7.28/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.099400</td>\n",
       "      <td>0.831677</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.635036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.802100</td>\n",
       "      <td>0.699765</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>0.664003</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.649300</td>\n",
       "      <td>0.616398</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.662600</td>\n",
       "      <td>0.630112</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>0.603512</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.601900</td>\n",
       "      <td>0.604522</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.620190</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.518600</td>\n",
       "      <td>0.633640</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.603130</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>0.688723</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.477100</td>\n",
       "      <td>0.648360</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.478800</td>\n",
       "      <td>0.677715</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.486300</td>\n",
       "      <td>0.588901</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "      <td>0.750365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "      <td>0.753285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.678884</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.743066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>0.703423</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.716041</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.328400</td>\n",
       "      <td>0.710826</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.775193</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "      <td>0.735766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.767652</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.801708</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.759124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>0.882107</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "      <td>0.756204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>0.862479</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>1.043629</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model_isRejection = AutoModelForSequenceClassification.\\\n",
    "from_pretrained(\"./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400\",num_labels=4,ignore_mismatched_sizes=True)\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_isRejection,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfb808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mlm_results_largeData/checkpoint-1100 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./mlm_results_largeData/checkpoint-1100 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1720\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1258' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1258/1720 26:27 < 09:43, 0.79 it/s, Epoch 7.31/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.047200</td>\n",
       "      <td>0.810168</td>\n",
       "      <td>0.651095</td>\n",
       "      <td>0.651095</td>\n",
       "      <td>0.651095</td>\n",
       "      <td>0.651095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.824400</td>\n",
       "      <td>0.657859</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.764500</td>\n",
       "      <td>0.646473</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.609192</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "      <td>0.747445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.676500</td>\n",
       "      <td>0.689624</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.642600</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>0.737226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.634100</td>\n",
       "      <td>0.597360</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.608200</td>\n",
       "      <td>0.645355</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.607269</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.549900</td>\n",
       "      <td>0.631745</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.540200</td>\n",
       "      <td>0.596844</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "      <td>0.745985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.670587</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.605757</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.474500</td>\n",
       "      <td>0.646329</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.660412</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "      <td>0.764964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.608156</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.599613</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "      <td>0.757664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.646695</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.766423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>0.631575</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "      <td>0.775182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.666456</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.751825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.309800</td>\n",
       "      <td>0.687544</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "      <td>0.760584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.280900</td>\n",
       "      <td>0.649957</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.256500</td>\n",
       "      <td>0.805345</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.306800</td>\n",
       "      <td>0.712096</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "      <td>0.763504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>0.777177</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "      <td>0.762044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-50/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-300/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-350/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-400/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-450/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-500/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-550/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-600/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-650/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-750/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-800/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-850/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-900/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-950/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1000/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1050/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1150/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1200/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250\n",
      "Configuration saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250/config.json\n",
      "Model weights saved in ./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1250/pytorch_model.bin\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\",num_labels=4)\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5',          \n",
    "    num_train_epochs=10,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 30,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb06d2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[308  56   3   0]\n",
      " [ 33 165  24   2]\n",
      " [  4  29  38   1]\n",
      " [  3   0  16   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.86       367\n",
      "           1       0.66      0.74      0.70       224\n",
      "           2       0.47      0.53      0.50        72\n",
      "           3       0.50      0.14      0.21        22\n",
      "\n",
      "    accuracy                           0.75       685\n",
      "   macro avg       0.63      0.56      0.57       685\n",
      "weighted avg       0.76      0.75      0.75       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifta4_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700\",num_labels=4)\n",
    "ifta4_test_trainer = Trainer(ifta4_fine_tuned_model) \n",
    "raw_pred,_,_=ifta4_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb686f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([4, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([4]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.13.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[601  46]\n",
      " [ 18  20]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       647\n",
      "           1       0.30      0.53      0.38        38\n",
      "\n",
      "    accuracy                           0.91       685\n",
      "   macro avg       0.64      0.73      0.67       685\n",
      "weighted avg       0.93      0.91      0.92       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rej_ifta = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./qa_fine_mlm_results_kidbert_isRejection_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-700\",num_labels=2,ignore_mismatched_sizes=True)\n",
    "model_isRejection = AutoModelForSequenceClassification.\\\n",
    "from_pretrained(\"./qaRej_fine_mlm_results_largeData_batch16_weightDecay_1e-5/checkpoint-1400\",num_labels=2)\n",
    "\n",
    "model_rej_ifta.classifier = model_isRejection.classifier\n",
    "model_rej_ifta_test_trainer = Trainer(model_rej_ifta) \n",
    "\n",
    "try:\n",
    "    raw_pred,_,_=model_rej_ifta_test_trainer.predict(test_dataset) \n",
    "    pred_labels = np.argmax(raw_pred, axis=1)\n",
    "    print(confusion_matrix(test_labels,pred_labels))\n",
    "    print(classification_report(test_labels,pred_labels))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934067ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de3f74d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 685\n",
      "  Batch size = 8\n",
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[304  58   4   1]\n",
      " [ 26 184  11   3]\n",
      " [  2  34  28   8]\n",
      " [  1   1   7  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       367\n",
      "           1       0.66      0.82      0.73       224\n",
      "           2       0.56      0.39      0.46        72\n",
      "           3       0.52      0.59      0.55        22\n",
      "\n",
      "    accuracy                           0.77       685\n",
      "   macro avg       0.66      0.66      0.65       685\n",
      "weighted avg       0.78      0.77      0.77       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ifta4_fine_tuned_model = \\\n",
    "AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./qa_fine_mlm_results_kidbert_kidney_based_ifta_4labels_largeData_batch16_weightDecay_1e-5/checkpoint-1100\",num_labels=4)\n",
    "ifta4_test_trainer = Trainer(ifta4_fine_tuned_model) \n",
    "raw_pred,_,_=ifta4_test_trainer.predict(test_dataset) \n",
    "pred_labels = np.argmax(raw_pred, axis=1)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c12abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
