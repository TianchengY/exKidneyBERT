{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee773047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,BertForSequenceClassification, AutoTokenizer, AutoModel,AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AdamW,get_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d032fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mlm_results_largeData/checkpoint-1100 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./mlm_results_largeData/checkpoint-1100 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "base_kidneyBert = AutoModel.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2630bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_kidneyBert.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5f5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RejClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RejClassifier, self).__init__()\n",
    "        \n",
    "#         self.base_model = base_model\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.linear = nn.Linear(768, 256) # output features from bert is 768 and 2 is ur number of labels\n",
    "        self.linear2 = nn.Linear(256, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        #input_ids, attention_mask = inputs[\"input_ids\"],inputs[\"attention_mask\"]\n",
    "        #print(\"a\")\n",
    "        #outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "#         del inputs[\"labels\"]\n",
    "#         outputs = self.base_model(**inputs)\n",
    "        #print(\"b\")\n",
    "        \n",
    "        #print(\"c\",outputs,outputs.shape)\n",
    "        outputs = self.linear(outputs[1])\n",
    "        outputs = self.dropout(self.relu(outputs))\n",
    "        outputs = self.linear2(outputs)\n",
    "        #print(\"d\",outputs,outputs.shape)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "class IFTAClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IFTAClassifier, self).__init__()\n",
    "        \n",
    "#         self.base_model = base_model\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.linear = nn.Linear(768, 256) # output features from bert is 768 and 2 is ur number of labels\n",
    "        self.linear2 = nn.Linear(256, 4)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        #input_ids, attention_mask = inputs[\"input_ids\"],inputs[\"attention_mask\"]\n",
    "#         del inputs[\"labels\"]\n",
    "#         outputs = self.base_model(**inputs)\n",
    "        #print(\"e\",outputs,outputs.shape)\n",
    "        #outputs = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "#         outputs = self.dropout(outputs[1])\n",
    "        #print(\"f\",outputs,outputs.shape)\n",
    "#         outputs = self.linear(outputs)\n",
    "        #print(\"g\",outputs,outputs.shape)\n",
    "        outputs = self.linear(outputs[1])\n",
    "        outputs = self.dropout(self.relu(outputs))\n",
    "        outputs = self.linear2(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d062024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels,task_name=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.task_name = task_name\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        #item[\"task_name\"] = self.task_name\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    #pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    print(\"accuracy: {}, precision: {}, recall: {}, f1: {}\".format(accuracy,precision,recall,f1))\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e3f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_datasets(q,train_text,test_text,tokenizer=tokenizer):\n",
    "    train_q = [q for i in range(len(train_text))]\n",
    "    test_q = [q for i in range(len(test_text))]\n",
    "\n",
    "    train_encodings = tokenizer(train_q,train_text,padding=\"max_length\", truncation=True, \n",
    "                                return_tensors=\"pt\",max_length=512)\n",
    "    test_encodings = tokenizer(test_q,test_text,padding=\"max_length\", truncation=True, \n",
    "                                return_tensors=\"pt\",max_length=512)\n",
    "    train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "    test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "    return train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0abae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "483ea51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_rej\"].tolist()\n",
    "label1 = data[\"isRejection\"].tolist()\n",
    "label = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)\n",
    "# train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "#                             return_tensors=\"pt\",max_length=512)\n",
    "# test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "#                             return_tensors=\"pt\",max_length=512)\n",
    "# train_dataset = RenalDataset(train_encodings, train_labels,task_name=\"isrej\")\n",
    "# test_dataset = RenalDataset(test_encodings, test_labels,task_name=\"isrej\")\n",
    "q_rej = \"Is there any rejection?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_rej,train_text,test_text)\n",
    "isrej_train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size)\n",
    "isrej_test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092494d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_ifta\"].tolist()\n",
    "label1 = data[\"IFTA\"].tolist()\n",
    "label2 = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "label = [0 if l in [\"nosig\",\"minimal\",\"noinfo\"] else (1 if l==\"mild\" else (2 if l==\"moderate\" else 3)) for l in label2]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)\n",
    "# train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "#                             return_tensors=\"pt\",max_length=512)\n",
    "# test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "#                             return_tensors=\"pt\",max_length=512)\n",
    "# train_dataset = RenalDataset(train_encodings, train_labels,task_name = \"ifta\")\n",
    "# test_dataset = RenalDataset(test_encodings, test_labels,task_name = \"ifta\")\n",
    "q_ifta = \"What is the grade of interstitial fibrosis and tubular atrophy?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_ifta,train_text,test_text)\n",
    "ifta_train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size)\n",
    "ifta_test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38aebd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_isrej = RejClassifier()\n",
    "model_ifta = IFTAClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e32da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer_isrej = AdamW(list(base_kidneyBert.parameters())+list(model_isrej.parameters()), lr=5e-5)\n",
    "optimizer_ifta = AdamW(list(base_kidneyBert.parameters())+list(model_ifta.parameters()), lr=5e-5)\n",
    "num_epochs = 20\n",
    "num_training_steps = num_epochs * min(len(isrej_train_loader),len(ifta_train_loader))\n",
    "lr_scheduler_isrej = get_scheduler(\"linear\", optimizer=optimizer_isrej, num_warmup_steps=30, num_training_steps=num_training_steps)\n",
    "lr_scheduler_ifta = get_scheduler(\"linear\", optimizer=optimizer_ifta, num_warmup_steps=30, num_training_steps=num_training_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73a6b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IFTAClassifier(\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model_isrej.to(device)\n",
    "model_ifta.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aa17cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\",num_labels=4)\n",
    "# model_renal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6a2f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model,dataloader):\n",
    "    pred,labels = [],[]\n",
    "    model.eval() \n",
    "    base_kidneyBert.eval()\n",
    "    with torch.no_grad(): \n",
    "        for batch in dataloader:\n",
    "           \n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            cur_labels = batch[\"labels\"].to(\"cpu\").flatten().tolist()\n",
    "            del batch[\"labels\"]\n",
    "            outputs = model(base_kidneyBert(**batch))\n",
    "            predicted = torch.argmax(outputs, axis=1).to(\"cpu\").flatten().tolist() #torch.max(outputs.data,1) \n",
    "            pred+=predicted\n",
    "            labels+=cur_labels\n",
    "            \n",
    "            \n",
    "#             if pred == 0:\n",
    "#                 pred = predicted\n",
    "#                 labels = cur_labels\n",
    "#             else:\n",
    "#                 pred = torch.cat((pred,predicted),-1)\n",
    "#                 labels = torch.cat((labels,cur_labels),-1)\n",
    "#             total += labels.size(0)\n",
    "            \n",
    "#             correct += (predicted == labels).sum().item()\n",
    "            \n",
    "#     print('the accuracy is {:.4f}'.format(correct/total))\n",
    "    return pred,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42705250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54347a29f926447e8d7e941b798e0b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 2/20 Loss : 0.1552,0.5154\n",
      "accuracy: 0.9445255474452555, precision: 0.9445255474452555, recall: 0.9445255474452555, f1: 0.9445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.710948905109489, precision: 0.710948905109489, recall: 0.710948905109489, f1: 0.7109489051094892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 4/20 Loss : 0.1199,0.9246\n",
      "accuracy: 0.962043795620438, precision: 0.962043795620438, recall: 0.962043795620438, f1: 0.962043795620438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7445255474452555, precision: 0.7445255474452555, recall: 0.7445255474452555, f1: 0.7445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 5/20 Loss : 0.0424,0.3793\n",
      "accuracy: 0.9518248175182482, precision: 0.9518248175182482, recall: 0.9518248175182482, f1: 0.9518248175182482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.710948905109489, precision: 0.710948905109489, recall: 0.710948905109489, f1: 0.7109489051094892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 7/20 Loss : 0.0124,0.5633\n",
      "accuracy: 0.9635036496350365, precision: 0.9635036496350365, recall: 0.9635036496350365, f1: 0.9635036496350365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7489051094890511, precision: 0.7489051094890511, recall: 0.7489051094890511, f1: 0.7489051094890511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 8/20 Loss : 0.0013,0.4945\n",
      "accuracy: 0.9576642335766423, precision: 0.9576642335766423, recall: 0.9576642335766423, f1: 0.9576642335766423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7445255474452555, precision: 0.7445255474452555, recall: 0.7445255474452555, f1: 0.7445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 10/20 Loss : 0.0488,0.4588\n",
      "accuracy: 0.9445255474452555, precision: 0.9445255474452555, recall: 0.9445255474452555, f1: 0.9445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.708029197080292, precision: 0.708029197080292, recall: 0.708029197080292, f1: 0.708029197080292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 11/20 Loss : 0.0332,0.3511\n",
      "accuracy: 0.9605839416058394, precision: 0.9605839416058394, recall: 0.9605839416058394, f1: 0.9605839416058394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7635036496350365, precision: 0.7635036496350365, recall: 0.7635036496350365, f1: 0.7635036496350364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 13/20 Loss : 0.0017,0.3229\n",
      "accuracy: 0.9547445255474453, precision: 0.9547445255474453, recall: 0.9547445255474453, f1: 0.9547445255474453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7547445255474453, precision: 0.7547445255474453, recall: 0.7547445255474453, f1: 0.7547445255474453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 14/20 Loss : 0.0013,0.1532\n",
      "accuracy: 0.9518248175182482, precision: 0.9518248175182482, recall: 0.9518248175182482, f1: 0.9518248175182482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7211678832116788, precision: 0.7211678832116788, recall: 0.7211678832116788, f1: 0.7211678832116789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 16/20 Loss : 0.0007,0.4339\n",
      "accuracy: 0.9518248175182482, precision: 0.9518248175182482, recall: 0.9518248175182482, f1: 0.9518248175182482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7635036496350365, precision: 0.7635036496350365, recall: 0.7635036496350365, f1: 0.7635036496350364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 17/20 Loss : 0.0012,0.0808\n",
      "accuracy: 0.945985401459854, precision: 0.945985401459854, recall: 0.945985401459854, f1: 0.945985401459854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7532846715328467, precision: 0.7532846715328467, recall: 0.7532846715328467, f1: 0.7532846715328468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3600, EPOCHS : 19/20 Loss : 0.0002,0.0347\n",
      "accuracy: 0.9576642335766423, precision: 0.9576642335766423, recall: 0.9576642335766423, f1: 0.9576642335766423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7766423357664234, precision: 0.7766423357664234, recall: 0.7766423357664234, f1: 0.7766423357664234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3900, EPOCHS : 20/20 Loss : 0.0002,0.0380\n",
      "accuracy: 0.9562043795620438, precision: 0.9562043795620438, recall: 0.9562043795620438, f1: 0.9562043795620438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7737226277372263, precision: 0.7737226277372263, recall: 0.7737226277372263, f1: 0.7737226277372263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_isrej = 0\n",
    "best_f1_ifta = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "#             for k, v in batch_isrej.items():\n",
    "#                 v.detach()\n",
    "# #                 del v\n",
    "#             batch_isrej.clear()\n",
    "                \n",
    "#             batch_isrej = 0\n",
    "            \n",
    "#             torch.cuda.empty_cache()\n",
    "            \n",
    "            \n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "                \n",
    "                res_isrej = compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                res_ifta = compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "                if res_isrej[\"f1\"] > best_f1_isrej and res_ifta[\"f1\"] > best_f1_ifta:\n",
    "                    best_f1_isrej = res_isrej[\"f1\"]\n",
    "                    best_f1_ifta = res_ifta[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_both/f1_{best_f1_isrej}_{best_f1_ifta}\")\n",
    "                    torch.save(model_isrej_.state_dict(),f\"./fine_both/model_isrej_{best_f1_isrej}.pth\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_both/model_ifta_{best_f1_ifta}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4994284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kidneyBert.save_pretrained(f\"./fine_both/final\")\n",
    "torch.save(model_isrej.state_dict(),f\"./fine_both/model_isrej_final.pth\")\n",
    "torch.save(model_ifta.state_dict(),f\"./fine_both/model_ifta_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6675ac98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_isrej.load_state_dict(torch.load(\"./fine_both/model_isrej_final.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b26ff0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[638   9]\n",
      " [ 21  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       647\n",
      "           1       0.65      0.45      0.53        38\n",
      "\n",
      "    accuracy                           0.96       685\n",
      "   macro avg       0.81      0.72      0.75       685\n",
      "weighted avg       0.95      0.96      0.95       685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324  43   0   0]\n",
      " [ 37 164  23   0]\n",
      " [  3  31  38   0]\n",
      " [  3   4  12   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       367\n",
      "           1       0.68      0.73      0.70       224\n",
      "           2       0.52      0.53      0.52        72\n",
      "           3       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.77       685\n",
      "   macro avg       0.77      0.57      0.59       685\n",
      "weighted avg       0.78      0.77      0.77       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))\n",
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac83b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d4151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "975d05f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1471b661b1a24328bc702210a5ceed2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 2/20 Loss : 0.2560,0.0000\n",
      "accuracy: 0.9445255474452555, precision: 0.9445255474452555, recall: 0.9445255474452555, f1: 0.9445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 4/20 Loss : 0.2050,0.0000\n",
      "accuracy: 0.9562043795620438, precision: 0.9562043795620438, recall: 0.9562043795620438, f1: 0.9562043795620438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 6/20 Loss : 0.0197,0.0000\n",
      "accuracy: 0.9503649635036496, precision: 0.9503649635036496, recall: 0.9503649635036496, f1: 0.9503649635036496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 7/20 Loss : 0.0123,0.0000\n",
      "accuracy: 0.9635036496350365, precision: 0.9635036496350365, recall: 0.9635036496350365, f1: 0.9635036496350365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 9/20 Loss : 0.0687,0.0000\n",
      "accuracy: 0.9547445255474453, precision: 0.9547445255474453, recall: 0.9547445255474453, f1: 0.9547445255474453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 11/20 Loss : 0.0141,0.0000\n",
      "accuracy: 0.9635036496350365, precision: 0.9635036496350365, recall: 0.9635036496350365, f1: 0.9635036496350365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 13/20 Loss : 0.0038,0.0000\n",
      "accuracy: 0.964963503649635, precision: 0.964963503649635, recall: 0.964963503649635, f1: 0.964963503649635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 14/20 Loss : 0.0004,0.0000\n",
      "accuracy: 0.9664233576642336, precision: 0.9664233576642336, recall: 0.9664233576642336, f1: 0.9664233576642337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 16/20 Loss : 0.0024,0.0000\n",
      "accuracy: 0.9664233576642336, precision: 0.9664233576642336, recall: 0.9664233576642336, f1: 0.9664233576642337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 18/20 Loss : 0.0005,0.0000\n",
      "accuracy: 0.9693430656934306, precision: 0.9693430656934306, recall: 0.9693430656934306, f1: 0.9693430656934306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 20/20 Loss : 0.0001,0.0000\n",
      "accuracy: 0.9693430656934306, precision: 0.9693430656934306, recall: 0.9693430656934306, f1: 0.9693430656934306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1 = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "\n",
    "#             batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "#             labels = batch_ifta[\"labels\"]\n",
    "#             del batch_ifta[\"labels\"]\n",
    "#             feat = base_kidneyBert(**batch_ifta)\n",
    "#             outputs = model_ifta(feat)\n",
    "# #             outputs = model_ifta(batch_ifta)\n",
    "#             #print(10)\n",
    "            \n",
    "#             #print(11)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "#             #print(12)\n",
    "#             #print(\"q\",outputs,outputs.shape)\n",
    "#             #print(\"z\",labels,labels.shape)\n",
    "#             loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "#             loss_ifta.backward()\n",
    "\n",
    "#             optimizer_ifta.step()\n",
    "#             lr_scheduler_ifta.step()\n",
    "#             optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_ifta = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "                res = compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                if res[\"f1\"] > best_f1:\n",
    "                    best_f1 = res[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_rej/f1{best_f1}\")\n",
    "                    torch.save(model_isrej.state_dict(),f\"./fine_rej/model_isrej_{best_f1}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1124e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kidneyBert.save_pretrained(f\"./fine_rej/final\")\n",
    "torch.save(model_isrej.state_dict(),f\"./fine_rej/model_isrej_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb0464eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[641   6]\n",
      " [ 15  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       647\n",
      "           1       0.79      0.61      0.69        38\n",
      "\n",
      "    accuracy                           0.97       685\n",
      "   macro avg       0.89      0.80      0.84       685\n",
      "weighted avg       0.97      0.97      0.97       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e7a5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8196cdbf2f46509ec9b4ea1dcdd7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 2/20 Loss : 0.0000,0.3606\n",
      "accuracy: 0.7051094890510949, precision: 0.7051094890510949, recall: 0.7051094890510949, f1: 0.7051094890510949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 4/20 Loss : 0.0000,0.4748\n",
      "accuracy: 0.7284671532846715, precision: 0.7284671532846715, recall: 0.7284671532846715, f1: 0.7284671532846715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 6/20 Loss : 0.0000,0.3987\n",
      "accuracy: 0.7138686131386861, precision: 0.7138686131386861, recall: 0.7138686131386861, f1: 0.7138686131386861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 7/20 Loss : 0.0000,0.4292\n",
      "accuracy: 0.7386861313868613, precision: 0.7386861313868613, recall: 0.7386861313868613, f1: 0.7386861313868613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 9/20 Loss : 0.0000,0.1700\n",
      "accuracy: 0.7343065693430657, precision: 0.7343065693430657, recall: 0.7343065693430657, f1: 0.7343065693430656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 11/20 Loss : 0.0000,0.0980\n",
      "accuracy: 0.7138686131386861, precision: 0.7138686131386861, recall: 0.7138686131386861, f1: 0.7138686131386861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 13/20 Loss : 0.0000,0.0224\n",
      "accuracy: 0.7343065693430657, precision: 0.7343065693430657, recall: 0.7343065693430657, f1: 0.7343065693430656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 14/20 Loss : 0.0000,0.0817\n",
      "accuracy: 0.7386861313868613, precision: 0.7386861313868613, recall: 0.7386861313868613, f1: 0.7386861313868613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 16/20 Loss : 0.0000,0.0653\n",
      "accuracy: 0.7401459854014598, precision: 0.7401459854014598, recall: 0.7401459854014598, f1: 0.7401459854014598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 18/20 Loss : 0.0000,0.0056\n",
      "accuracy: 0.7416058394160584, precision: 0.7416058394160584, recall: 0.7416058394160584, f1: 0.7416058394160584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 20/20 Loss : 0.0000,0.0151\n",
      "accuracy: 0.7386861313868613, precision: 0.7386861313868613, recall: 0.7386861313868613, f1: 0.7386861313868613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1 = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "#             batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "#             labels = batch_isrej[\"labels\"]\n",
    "# #             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "#             #print(2)\n",
    "#             del batch_isrej[\"labels\"]\n",
    "#             feat = base_kidneyBert(**batch_isrej)\n",
    "# #             print(feat[0].shape,feat[1].shape)\n",
    "#             outputs = model_isrej(feat)\n",
    "#             #print(3)\n",
    "#             #print(4)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "#             #print(outputs,outputs.shape)\n",
    "#             #print(labels,labels.shape)\n",
    "#             loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "#             #print(6)\n",
    "#             loss_isrej.backward()\n",
    "#             #print(7)\n",
    "\n",
    "#             optimizer_isrej.step()\n",
    "#             lr_scheduler_isrej.step()\n",
    "#             optimizer_isrej.zero_grad()\n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_isrej = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "                res = compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "                if res[\"f1\"] > best_f1:\n",
    "                    best_f1 = res[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_ifta/f1{best_f1}\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_ifta/model_isrej_{best_f1}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ac4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kidneyBert.save_pretrained(f\"./fine_ifta/final\")\n",
    "torch.save(model_ifta.state_dict(),f\"./fine_ifta/model_ifta_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65dfd34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320  42   3   2]\n",
      " [ 49 144  30   1]\n",
      " [  2  29  40   1]\n",
      " [  2   2  14   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       367\n",
      "           1       0.66      0.64      0.65       224\n",
      "           2       0.46      0.56      0.50        72\n",
      "           3       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.74       685\n",
      "   macro avg       0.62      0.56      0.57       685\n",
      "weighted avg       0.74      0.74      0.74       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb52a44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 16.00 GiB total capacity; 14.15 GiB already allocated; 0 bytes free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_isrej = 0\n",
    "best_f1_ifta = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "            for k, v in batch_isrej.items():\n",
    "                del v\n",
    "                \n",
    "            batch_isrej = 0\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            \n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "                \n",
    "                res_isrej = compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                res_ifta = compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "                if res_isrej[\"f1\"] > best_f1_isrej and res_ifta[\"f1\"] > best_f1_ifta:\n",
    "                    best_f1_isrej = res_isrej[\"f1\"]\n",
    "                    best_f1_ifta = res_ifta[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_both/f1_{best_f1_isrej}_{best_f1_ifta}\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_both/model_isrej_{best_f1_isrej}.pth\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_both/model_ifta_{best_f1_ifta}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9650c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fe58caabf84b87818e6fc8d4e28d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            #lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_isrej = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "#                 compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ccf874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 1/10 Loss : 0.0000,0.5015\n",
      "accuracy: 0.7167883211678832, precision: 0.7167883211678832, recall: 0.7167883211678832, f1: 0.7167883211678832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 1/10 Loss : 0.0000,0.6111\n",
      "accuracy: 0.6875912408759124, precision: 0.6875912408759124, recall: 0.6875912408759124, f1: 0.6875912408759124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 2/10 Loss : 0.0000,1.2040\n",
      "accuracy: 0.7299270072992701, precision: 0.7299270072992701, recall: 0.7299270072992701, f1: 0.72992700729927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 2/10 Loss : 0.0000,0.4732\n",
      "accuracy: 0.7094890510948905, precision: 0.7094890510948905, recall: 0.7094890510948905, f1: 0.7094890510948906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 3/10 Loss : 0.0000,0.6230\n",
      "accuracy: 0.7124087591240876, precision: 0.7124087591240876, recall: 0.7124087591240876, f1: 0.7124087591240876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 3/10 Loss : 0.0000,0.6581\n",
      "accuracy: 0.7299270072992701, precision: 0.7299270072992701, recall: 0.7299270072992701, f1: 0.72992700729927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 4/10 Loss : 0.0000,0.9544\n",
      "accuracy: 0.7197080291970803, precision: 0.7197080291970803, recall: 0.7197080291970803, f1: 0.7197080291970803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 4/10 Loss : 0.0000,0.6450\n",
      "accuracy: 0.6963503649635037, precision: 0.6963503649635037, recall: 0.6963503649635037, f1: 0.6963503649635037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 4/10 Loss : 0.0000,0.0922\n",
      "accuracy: 0.7401459854014598, precision: 0.7401459854014598, recall: 0.7401459854014598, f1: 0.7401459854014598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 5/10 Loss : 0.0000,0.6349\n",
      "accuracy: 0.7445255474452555, precision: 0.7445255474452555, recall: 0.7445255474452555, f1: 0.7445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 5/10 Loss : 0.0000,0.6144\n",
      "accuracy: 0.7401459854014598, precision: 0.7401459854014598, recall: 0.7401459854014598, f1: 0.7401459854014598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3600, EPOCHS : 6/10 Loss : 0.0000,0.2996\n",
      "accuracy: 0.7065693430656934, precision: 0.7065693430656934, recall: 0.7065693430656934, f1: 0.7065693430656934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3900, EPOCHS : 6/10 Loss : 0.0000,0.2006\n",
      "accuracy: 0.7357664233576642, precision: 0.7357664233576642, recall: 0.7357664233576642, f1: 0.7357664233576642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:4200, EPOCHS : 7/10 Loss : 0.0000,0.4186\n",
      "accuracy: 0.7313868613138687, precision: 0.7313868613138687, recall: 0.7313868613138687, f1: 0.7313868613138687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:4500, EPOCHS : 7/10 Loss : 0.0000,0.7996\n",
      "accuracy: 0.7474452554744525, precision: 0.7474452554744525, recall: 0.7474452554744525, f1: 0.7474452554744525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:4800, EPOCHS : 8/10 Loss : 0.0000,0.3397\n",
      "accuracy: 0.7328467153284671, precision: 0.7328467153284671, recall: 0.7328467153284671, f1: 0.7328467153284671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:5100, EPOCHS : 8/10 Loss : 0.0000,0.9969\n",
      "accuracy: 0.7445255474452555, precision: 0.7445255474452555, recall: 0.7445255474452555, f1: 0.7445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:5400, EPOCHS : 8/10 Loss : 0.0000,0.1258\n",
      "accuracy: 0.7635036496350365, precision: 0.7635036496350365, recall: 0.7635036496350365, f1: 0.7635036496350364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:5700, EPOCHS : 9/10 Loss : 0.0000,0.1847\n",
      "accuracy: 0.7518248175182481, precision: 0.7518248175182481, recall: 0.7518248175182481, f1: 0.7518248175182483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:6000, EPOCHS : 9/10 Loss : 0.0000,0.0526\n",
      "accuracy: 0.743065693430657, precision: 0.743065693430657, recall: 0.743065693430657, f1: 0.743065693430657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:6300, EPOCHS : 10/10 Loss : 0.0000,0.1960\n",
      "accuracy: 0.743065693430657, precision: 0.743065693430657, recall: 0.743065693430657, f1: 0.743065693430657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:6600, EPOCHS : 10/10 Loss : 0.0000,0.0521\n",
      "accuracy: 0.743065693430657, precision: 0.743065693430657, recall: 0.743065693430657, f1: 0.743065693430657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "#             batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "#             labels = batch_isrej[\"labels\"]\n",
    "# #             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "#             #print(2)\n",
    "#             del batch_isrej[\"labels\"]\n",
    "#             feat = base_kidneyBert(**batch_isrej)\n",
    "# #             print(feat[0].shape,feat[1].shape)\n",
    "#             outputs = model_isrej(feat)\n",
    "#             #print(3)\n",
    "#             #print(4)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "#             #print(outputs,outputs.shape)\n",
    "#             #print(labels,labels.shape)\n",
    "#             loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "#             #print(6)\n",
    "#             loss_isrej.backward()\n",
    "#             #print(7)\n",
    "\n",
    "#             optimizer_isrej.step()\n",
    "#             #lr_scheduler_isrej.step()\n",
    "#             optimizer_isrej.zero_grad()\n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_isrej = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "#                 compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99073f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce97145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68a3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825b8313",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405aa2ac",
   "metadata": {},
   "source": [
    "## isRejction one task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5068630f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[641   6]\n",
      " [ 15  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       647\n",
      "           1       0.79      0.61      0.69        38\n",
      "\n",
      "    accuracy                           0.97       685\n",
      "   macro avg       0.89      0.80      0.84       685\n",
      "weighted avg       0.97      0.97      0.97       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fc4c0",
   "metadata": {},
   "source": [
    "## isRejction multi tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c0387f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[638   9]\n",
      " [ 21  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       647\n",
      "           1       0.65      0.45      0.53        38\n",
      "\n",
      "    accuracy                           0.96       685\n",
      "   macro avg       0.81      0.72      0.75       685\n",
      "weighted avg       0.95      0.96      0.95       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a131230",
   "metadata": {},
   "source": [
    "## IFTA one task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9265c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320  42   3   2]\n",
      " [ 49 144  30   1]\n",
      " [  2  29  40   1]\n",
      " [  2   2  14   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       367\n",
      "           1       0.66      0.64      0.65       224\n",
      "           2       0.46      0.56      0.50        72\n",
      "           3       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.74       685\n",
      "   macro avg       0.62      0.56      0.57       685\n",
      "weighted avg       0.74      0.74      0.74       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18010c5",
   "metadata": {},
   "source": [
    "## IFTA multi tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eba45149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324  43   0   0]\n",
      " [ 37 164  23   0]\n",
      " [  3  31  38   0]\n",
      " [  3   4  12   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       367\n",
      "           1       0.68      0.73      0.70       224\n",
      "           2       0.52      0.53      0.52        72\n",
      "           3       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.77       685\n",
      "   macro avg       0.77      0.57      0.59       685\n",
      "weighted avg       0.78      0.77      0.77       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da90be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672fdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807da831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a98067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881ca0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9740f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec280a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf76a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1d1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1405214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
