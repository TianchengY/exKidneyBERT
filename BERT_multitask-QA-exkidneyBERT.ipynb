{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee773047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,BertForSequenceClassification, AutoTokenizer, AutoModel,AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AdamW,get_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d032fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mlm_results_largeData_extended_tokenizer/checkpoint-1100 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at ./mlm_results_largeData_extended_tokenizer/checkpoint-1100 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "new_tokens = [\"interstitial\", \"fibrosis\", \"tubular\", \"atrophy\",\"antibody\",\"T-cell\"]\n",
    "tokenizer.add_tokens(new_tokens)\n",
    "base_kidneyBert = AutoModel.from_pretrained(\"./mlm_results_largeData_extended_tokenizer/checkpoint-1100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2630bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(29002, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_kidneyBert.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5f5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABMRQA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ABMRQA, self).__init__()\n",
    "        self.qa_outputs = nn.Linear(768, 2)\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "        \n",
    "        return (start_logits,end_logits)\n",
    "    \n",
    "class TCMRQA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TCMRQA, self).__init__()\n",
    "        self.qa_outputs = nn.Linear(768, 2)\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "        \n",
    "        return (start_logits,end_logits)\n",
    "    \n",
    "class IFTAQA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IFTAQA, self).__init__()\n",
    "        self.qa_outputs = nn.Linear(768, 2)\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        logits = self.qa_outputs(sequence_output)\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "        start_logits = start_logits.squeeze(-1).contiguous()\n",
    "        end_logits = end_logits.squeeze(-1).contiguous()\n",
    "        \n",
    "        return (start_logits,end_logits)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b27d0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(start_positions,end_positions,start_logits,end_logits):\n",
    "    total_loss = None\n",
    "#     print(start_positions,end_positions,start_logits.shape,end_logits.shape)\n",
    "    start_positions = start_positions.squeeze(-1)\n",
    "    end_positions = end_positions.squeeze(-1)\n",
    "    \n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "#     print(start_loss,end_loss,start_positions,end_positions)\n",
    "    total_loss = (start_loss + end_loss) / 2\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d062024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels,task_name=None):\n",
    "        self.encodings = encodings\n",
    "        self.answers = labels\n",
    "        self.task_name = task_name\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        answer = self.answers[idx]\n",
    "        offsets = inputs.pop(\"offset_mapping\")\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        cls_index = list(input_ids).index(tokenizer.cls_token_id)\n",
    "\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        \n",
    "#         print(\"Asd\",answer)\n",
    "\n",
    "        if answer[1] == 0:\n",
    "            inputs[\"start_positions\"] = cls_index\n",
    "            inputs[\"end_positions\"] = cls_index\n",
    "        else:\n",
    "            start_char = answer[0]\n",
    "            end_char = answer[1]\n",
    "\n",
    "            token_start_index = 0\n",
    "            while token_type_ids[token_start_index] != 1:\n",
    "                token_start_index += 1\n",
    "\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while offsets[token_end_index][1] == 0:\n",
    "                token_end_index -= 1\n",
    "                \n",
    "#             print(offsets[token_start_index][0] , start_char,answer)\n",
    "\n",
    "#             print(token_start_index,token_end_index)\n",
    "#             print(offsets[token_start_index], offsets[token_end_index])\n",
    "\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                inputs[\"start_positions\"] = cls_index\n",
    "                inputs[\"end_positions\"] = cls_index\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "#                     print(offsets[token_start_index],token_start_index)\n",
    "                    token_start_index += 1\n",
    "                inputs[\"start_positions\"] = token_start_index - 1\n",
    "\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                inputs[\"end_positions\"] = token_end_index + 1\n",
    "        inputs[\"start_positions\"] = torch.tensor(inputs[\"start_positions\"])\n",
    "        inputs[\"end_positions\"] = torch.tensor(inputs[\"end_positions\"])\n",
    "#         inputs[\"labels\"] = (inputs[\"start_positions\"],inputs[\"end_positions\"])\n",
    "#         print(inputs[\"start_positions\"],inputs[\"end_positions\"])\n",
    "        return inputs\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.answers)\n",
    "    \n",
    "import difflib\n",
    "\n",
    "def get_overlap_ratio(s1, s2):\n",
    "    s = difflib.SequenceMatcher(None, s1, s2)\n",
    "    pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2)) \n",
    "#     print(s1,s2,s1[pos_a:pos_a+size])\n",
    "    return size/len(s2),len(s1[pos_a:pos_a+size].split())/len(s2.split())\n",
    "\n",
    "def compute_metrics(pred,test_ans,test_ids):     \n",
    "        \n",
    "    answer_start_scores, answer_end_scores = pred\n",
    "    answer_start = np.argmax(answer_start_scores, axis=1)  # get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = np.argmax(answer_end_scores, axis=1)+1\n",
    "    \n",
    "    \n",
    "    total = 0\n",
    "    correct,correct_with_info = 0,0\n",
    "    overlap_ratio_char = []\n",
    "    overlap_ratio_word = []\n",
    "    for s,e,t,id in zip(answer_start,answer_end,test_ans,test_ids):\n",
    "        total += 1\n",
    "        pred_ans = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(id[s:e]))\n",
    "#         print(\"qweretw\",pred_ans,t,s,e)\n",
    "        if s == 0 and e == 1 and t == \"\":\n",
    "            correct += 1\n",
    "        elif not (s == 0 and e == 1) and t!=\"\":\n",
    "            if pred_ans.lower().replace('\\n', ' ')==t.lower():\n",
    "                correct_with_info += 1\n",
    "            char_ratio,word_ratio = get_overlap_ratio(pred_ans.lower().replace('\\n', ' '),t.lower())\n",
    "            overlap_ratio_char.append(char_ratio)\n",
    "            overlap_ratio_word.append(word_ratio)\n",
    "    \n",
    "    result_dict =  {\"accuracy\": (correct+correct_with_info)/total,\"accuracy_info\": correct_with_info/total,\\\n",
    "            \"overlap_ratio_char\":np.mean(overlap_ratio_char),\"overlap_ratio_word\":np.mean(overlap_ratio_word)} \n",
    "    print(result_dict)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e3f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_datasets(q,train_text,test_text,tokenizer=tokenizer):\n",
    "    train_q = [q for i in range(len(train_text))]\n",
    "    test_q = [q for i in range(len(test_text))]\n",
    "\n",
    "    train_encodings = tokenizer(train_q,train_text,padding=\"max_length\", truncation=True, \n",
    "                                return_tensors=\"pt\",max_length=512,return_offsets_mapping=True)\n",
    "    test_encodings = tokenizer(test_q,test_text,padding=\"max_length\", truncation=True, \n",
    "                                return_tensors=\"pt\",max_length=512,return_offsets_mapping=True)\n",
    "    train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "    test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "    return train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0abae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "483ea51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load abmr data\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report_qa\"].tolist()\n",
    "label1 = data[\"abmr_pos_qa\"].tolist()\n",
    "label = [eval(l) for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]\n",
    "\n",
    "label_class_help = data[\"abmr_class\"].tolist()\n",
    "label_class = [l for i,l in zip(inputs1,label_class_help) if str(i)!=\"nan\"]\n",
    "\n",
    "\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label_class,test_size=0.2)\n",
    "\n",
    "\n",
    "q_abmr = \"How is the antibody-mediated rejection?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_abmr,train_text,test_text)\n",
    "abmr_train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle=True)\n",
    "abmr_test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size)\n",
    "\n",
    "abmr_test_ans = []\n",
    "for i,l in zip(test_text,test_labels):\n",
    "    abmr_test_ans.append(i[l[0]:l[1]])\n",
    "\n",
    "abmr_test_ids = torch.tensor([])\n",
    "for i in abmr_test_loader:\n",
    "    abmr_test_ids = torch.cat((abmr_test_ids,i[\"input_ids\"]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092494d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tcmr data\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report_qa\"].tolist()\n",
    "label1 = data[\"tcmr_pos_qa\"].tolist()\n",
    "label = [eval(l) for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]\n",
    "\n",
    "label_class_help = data[\"tcmr_class\"].tolist()\n",
    "label_class = [l for i,l in zip(inputs1,label_class_help) if str(i)!=\"nan\"]\n",
    "\n",
    "\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label_class,test_size=0.2)\n",
    "\n",
    "\n",
    "q_tcmr = \"How is the t-cell-mediated rejection?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_tcmr,train_text,test_text)\n",
    "tcmr_train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle=True)\n",
    "tcmr_test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size)\n",
    "\n",
    "tcmr_test_ans = []\n",
    "for i,l in zip(test_text,test_labels):\n",
    "    tcmr_test_ans.append(i[l[0]:l[1]])\n",
    "\n",
    "tcmr_test_ids = torch.tensor([])\n",
    "for i in tcmr_test_loader:\n",
    "    tcmr_test_ids = torch.cat((tcmr_test_ids,i[\"input_ids\"]),0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c6b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ifta data\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report_qa\"].tolist()\n",
    "label1 = data[\"ifta_pos_qa\"].tolist()\n",
    "label = [eval(l) for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]\n",
    "\n",
    "label_class_help1 = data[\"IFTA\"].tolist()\n",
    "label_class_help2 = [l for i,l in zip(inputs1,label_class_help1) if str(i)!=\"nan\"]\n",
    "label_class = [0 if l in [\"nosig\",\"minimal\",\"noinfo\"] else (1 if l==\"mild\" else (2 if l==\"moderate\" else 3)) for l in label_class_help2]\n",
    "\n",
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label_class,test_size=0.2)\n",
    "\n",
    "\n",
    "q_ifta = \"What is the grade of interstitial fibrosis and tubular atrophy?\"\n",
    "train_dataset,test_dataset = gen_datasets(q_ifta,train_text,test_text)\n",
    "ifta_train_loader = torch.utils.data.DataLoader(train_dataset,batch_size = batch_size,shuffle=True)\n",
    "ifta_test_loader = torch.utils.data.DataLoader(test_dataset,batch_size = batch_size)\n",
    "\n",
    "\n",
    "\n",
    "ifta_test_ans = []\n",
    "for i,l in zip(test_text,test_labels):\n",
    "    ifta_test_ans.append(i[l[0]:l[1]])\n",
    "\n",
    "ifta_test_ids = torch.tensor([])\n",
    "for i in ifta_test_loader:\n",
    "    ifta_test_ids = torch.cat((ifta_test_ids,i[\"input_ids\"]),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38aebd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_abmr = ABMRQA()\n",
    "model_tcmr = TCMRQA()\n",
    "model_ifta = IFTAQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e32da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer_abmr = AdamW(list(base_kidneyBert.parameters())+list(model_abmr.parameters()), lr=5e-5)\n",
    "optimizer_tcmr = AdamW(list(base_kidneyBert.parameters())+list(model_tcmr.parameters()), lr=5e-5)\n",
    "optimizer_ifta = AdamW(list(base_kidneyBert.parameters())+list(model_ifta.parameters()), lr=5e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * min(len(abmr_train_loader),len(tcmr_train_loader),len(ifta_train_loader))\n",
    "lr_scheduler_abmr = get_scheduler(\"linear\", optimizer=optimizer_abmr, num_warmup_steps=30, num_training_steps=num_training_steps)\n",
    "lr_scheduler_tcmr = get_scheduler(\"linear\", optimizer=optimizer_tcmr, num_warmup_steps=30, num_training_steps=num_training_steps)\n",
    "lr_scheduler_ifta = get_scheduler(\"linear\", optimizer=optimizer_ifta, num_warmup_steps=30, num_training_steps=num_training_steps)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a6b346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IFTAQA(\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model_abmr.to(device)\n",
    "model_tcmr.to(device)\n",
    "model_ifta.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6a2f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model,dataloader):\n",
    "    start,end = [],[]\n",
    "    model.eval() \n",
    "    base_kidneyBert.eval()\n",
    "    with torch.no_grad(): \n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            del batch[\"start_positions\"]\n",
    "            del batch[\"end_positions\"]\n",
    "            start_logits,end_logits = model(base_kidneyBert(**batch))\n",
    "            start_logits = start_logits.squeeze(-1).contiguous().tolist()\n",
    "            end_logits = end_logits.squeeze(-1).contiguous().tolist()\n",
    "            start+=start_logits\n",
    "            end+=end_logits\n",
    "            \n",
    "    return (start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d85d74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b94c24b70a461e93950f9314b53c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:50, EPOCHS : 1/3 Loss : 0.0264,0.0296,0.2343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.8700729927007299, 'accuracy_info': 0.8277372262773722, 'overlap_ratio_char': 0.968720629699248, 'overlap_ratio_word': 0.9917763157894737}\n",
      "STEP:100, EPOCHS : 1/3 Loss : 0.0237,0.0166,0.3116\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.927007299270073, 'accuracy_info': 0.8671532846715329, 'overlap_ratio_char': 0.9853976073187897, 'overlap_ratio_word': 0.9967159277504105}\n",
      "STEP:150, EPOCHS : 1/3 Loss : 0.0083,0.0121,0.1903\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.9357664233576642, 'accuracy_info': 0.8671532846715329, 'overlap_ratio_char': 0.9891265912305515, 'overlap_ratio_word': 0.9966996699669967}\n",
      "STEP:200, EPOCHS : 1/3 Loss : 0.0046,0.0076,0.1037\n",
      "{'accuracy': 0.9664233576642336, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3327530834703315, 'overlap_ratio_word': 0.4474242424242424}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': nan, 'overlap_ratio_word': nan}\n",
      "{'accuracy': 0.9328467153284672, 'accuracy_info': 0.8671532846715329, 'overlap_ratio_char': 0.987517622180451, 'overlap_ratio_word': 0.9917763157894737}\n",
      "STEP:250, EPOCHS : 2/3 Loss : 0.0060,0.0054,0.0257\n",
      "{'accuracy': 0.9664233576642336, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9766423357664233, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.9416058394160584, 'accuracy_info': 0.872992700729927, 'overlap_ratio_char': 0.987538118695754, 'overlap_ratio_word': 0.9950738916256158}\n",
      "STEP:300, EPOCHS : 2/3 Loss : 0.0032,0.0055,0.0668\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.23766323024054983, 'overlap_ratio_word': 0.3}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.5869565217391305, 'overlap_ratio_word': 0.8333333333333334}\n",
      "{'accuracy': 0.9445255474452555, 'accuracy_info': 0.8773722627737226, 'overlap_ratio_char': 0.9911740558292282, 'overlap_ratio_word': 0.9950738916256158}\n",
      "STEP:350, EPOCHS : 2/3 Loss : 0.0048,0.0038,0.1899\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.9138686131386862, 'accuracy_info': 0.8335766423357664, 'overlap_ratio_char': 0.9681165540540541, 'overlap_ratio_word': 0.9712837837837838}\n",
      "STEP:400, EPOCHS : 2/3 Loss : 0.0035,0.0031,0.0142\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.92992700729927, 'accuracy_info': 0.8627737226277372, 'overlap_ratio_char': 0.9752995770676692, 'overlap_ratio_word': 0.9810855263157895}\n",
      "STEP:450, EPOCHS : 2/3 Loss : 0.0021,0.0026,0.1084\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6268115942028986, 'overlap_ratio_word': 0.7916666666666667}\n",
      "{'accuracy': 0.9430656934306569, 'accuracy_info': 0.8773722627737226, 'overlap_ratio_char': 0.9909394792399719, 'overlap_ratio_word': 0.9958949096880131}\n",
      "STEP:500, EPOCHS : 3/3 Loss : 0.0022,0.0022,0.0765\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.9138686131386862, 'accuracy_info': 0.8291970802919708, 'overlap_ratio_char': 0.9652828136330674, 'overlap_ratio_word': 0.9703891708967851}\n",
      "STEP:550, EPOCHS : 3/3 Loss : 0.0020,0.0027,0.1795\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.9124087591240876, 'accuracy_info': 0.8262773722627738, 'overlap_ratio_char': 0.9801416256157636, 'overlap_ratio_word': 0.9853448275862069}\n",
      "STEP:600, EPOCHS : 3/3 Loss : 0.0022,0.0021,0.2708\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.9182481751824818, 'accuracy_info': 0.8481751824817518, 'overlap_ratio_char': 0.9608493890977443, 'overlap_ratio_word': 0.9646381578947368}\n",
      "STEP:650, EPOCHS : 3/3 Loss : 0.0020,0.0020,0.0150\n",
      "{'accuracy': 0.9678832116788321, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.6647879763821792, 'overlap_ratio_word': 0.7777777777777778}\n",
      "{'accuracy': 0.9328467153284672, 'accuracy_info': 0.8627737226277372, 'overlap_ratio_char': 0.9773340370631011, 'overlap_ratio_word': 0.9811165845648604}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_abmr = 0\n",
    "best_f1_tcmr = 0\n",
    "best_f1_ifta = 0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_abmr,batch_tcmr,batch_ifta in zip(abmr_train_loader,tcmr_train_loader,ifta_train_loader):\n",
    "        model_abmr.train()\n",
    "        model_tcmr.train()\n",
    "        model_ifta.train()\n",
    "        base_kidneyBert.train()\n",
    "        step+=1\n",
    "        #print(step)\n",
    "        #print(1)\n",
    "\n",
    "\n",
    "        batch_abmr = {k: v.to(device) for k, v in batch_abmr.items()}\n",
    "        start_positions = batch_abmr[\"start_positions\"]\n",
    "        end_positions = batch_abmr[\"end_positions\"]\n",
    "\n",
    "        del batch_abmr[\"start_positions\"]\n",
    "        del batch_abmr[\"end_positions\"]\n",
    "        feat = base_kidneyBert(**batch_abmr)\n",
    "        start_logits,end_logits = model_abmr(feat)\n",
    "        loss_abmr = cal_loss(start_positions,end_positions,start_logits,end_logits)\n",
    "\n",
    "        loss_abmr.backward()\n",
    "        optimizer_abmr.step()\n",
    "        lr_scheduler_abmr.step()\n",
    "        optimizer_abmr.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        batch_tcmr = {k: v.to(device) for k, v in batch_tcmr.items()}\n",
    "        start_positions = batch_tcmr[\"start_positions\"]\n",
    "        end_positions = batch_tcmr[\"end_positions\"]\n",
    "\n",
    "        del batch_tcmr[\"start_positions\"]\n",
    "        del batch_tcmr[\"end_positions\"]\n",
    "        feat = base_kidneyBert(**batch_tcmr)\n",
    "        start_logits,end_logits = model_tcmr(feat)\n",
    "        loss_tcmr = cal_loss(start_positions,end_positions,start_logits,end_logits)\n",
    "\n",
    "        loss_tcmr.backward()\n",
    "        optimizer_tcmr.step()\n",
    "        lr_scheduler_tcmr.step()\n",
    "        optimizer_tcmr.zero_grad()\n",
    "\n",
    "\n",
    "        batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "        start_positions = batch_ifta[\"start_positions\"]\n",
    "        end_positions = batch_ifta[\"end_positions\"]\n",
    "\n",
    "        del batch_ifta[\"start_positions\"]\n",
    "        del batch_ifta[\"end_positions\"]\n",
    "        feat = base_kidneyBert(**batch_ifta)\n",
    "        start_logits,end_logits = model_ifta(feat)\n",
    "        loss_ifta = cal_loss(start_positions,end_positions,start_logits,end_logits)\n",
    "\n",
    "        loss_ifta.backward()\n",
    "        optimizer_ifta.step()\n",
    "        lr_scheduler_ifta.step()\n",
    "        optimizer_ifta.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            #test the accuracy\n",
    "\n",
    "            print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                  'Loss : {:.4f},{:.4f},{:.4f}'.format(loss_abmr,loss_tcmr,loss_ifta))\n",
    "\n",
    "            res_abmr = compute_metrics(get_pred(model_abmr,abmr_test_loader),abmr_test_ans,abmr_test_ids)\n",
    "            res_tcmr = compute_metrics(get_pred(model_tcmr,tcmr_test_loader),tcmr_test_ans,tcmr_test_ids)\n",
    "            res_ifta = compute_metrics(get_pred(model_ifta,ifta_test_loader),ifta_test_ans,ifta_test_ids)\n",
    "\n",
    "#             base_kidneyBert.save_pretrained(f\"./fine_both_qa/step_{step}\")\n",
    "#             torch.save(model_abmr.state_dict(),f\"./fine_both_qa/model_abmr_{step}.pth\")\n",
    "#             torch.save(model_tcmr.state_dict(),f\"./fine_both_qa/model_tcmr_{step}.pth\")\n",
    "#             torch.save(model_ifta.state_dict(),f\"./fine_both_qa/model_ifta_{step}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eee85814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9664233576642336, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3540271774444162, 'overlap_ratio_word': 0.4444444444444445}\n",
      "{'accuracy': 0.9445255474452555, 'accuracy_info': 0.8759124087591241, 'overlap_ratio_char': 0.987538118695754, 'overlap_ratio_word': 0.9917898193760263}\n"
     ]
    }
   ],
   "source": [
    "res_abmr = compute_metrics(get_pred(model_abmr,abmr_test_loader),abmr_test_ans,abmr_test_ids)\n",
    "res_tcmr = compute_metrics(get_pred(model_tcmr,tcmr_test_loader),tcmr_test_ans,tcmr_test_ids)\n",
    "res_ifta = compute_metrics(get_pred(model_ifta,ifta_test_loader),ifta_test_ans,ifta_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42705250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4580 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 2/20 Loss : 0.0131,0.0026,0.1571\n",
      "{'accuracy': 0.9664233576642336, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.49437805463739865, 'overlap_ratio_word': 0.6527777777777778}\n",
      "{'accuracy': 0.927007299270073, 'accuracy_info': 0.8627737226277372, 'overlap_ratio_char': 0.9830254177453518, 'overlap_ratio_word': 0.9925864909390445}\n",
      "STEP:600, EPOCHS : 3/20 Loss : 0.0005,0.0007,0.0185\n",
      "{'accuracy': 0.9664233576642336, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3634197501369981, 'overlap_ratio_word': 0.46075757575757575}\n",
      "{'accuracy': 0.9781021897810219, 'accuracy_info': 0.0, 'overlap_ratio_char': 0.3524027459954233, 'overlap_ratio_word': 0.5277777777777778}\n",
      "{'accuracy': 0.945985401459854, 'accuracy_info': 0.8788321167883212, 'overlap_ratio_char': 0.9909394792399719, 'overlap_ratio_word': 0.9958949096880131}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4923ee1bd555>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mloss_tcmr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_positions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_positions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend_logits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mloss_tcmr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0moptimizer_tcmr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mlr_scheduler_tcmr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_abmr = 0\n",
    "best_f1_tcmr = 0\n",
    "best_f1_ifta = 0\n",
    "step = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_abmr,batch_tcmr,batch_ifta in zip(abmr_train_loader,tcmr_train_loader,ifta_train_loader):\n",
    "        model_abmr.train()\n",
    "        model_tcmr.train()\n",
    "        model_ifta.train()\n",
    "        base_kidneyBert.train()\n",
    "        step+=1\n",
    "        #print(step)\n",
    "        #print(1)\n",
    "\n",
    "\n",
    "        batch_abmr = {k: v.to(device) for k, v in batch_abmr.items()}\n",
    "        start_positions = batch_abmr[\"start_positions\"]\n",
    "        end_positions = batch_abmr[\"end_positions\"]\n",
    "\n",
    "        del batch_abmr[\"start_positions\"]\n",
    "        del batch_abmr[\"end_positions\"]\n",
    "        feat = base_kidneyBert(**batch_abmr)\n",
    "        start_logits,end_logits = model_abmr(feat)\n",
    "        loss_abmr = cal_loss(start_positions,end_positions,start_logits,end_logits)\n",
    "\n",
    "        loss_abmr.backward()\n",
    "        optimizer_abmr.step()\n",
    "        lr_scheduler_abmr.step()\n",
    "        optimizer_abmr.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        batch_tcmr = {k: v.to(device) for k, v in batch_tcmr.items()}\n",
    "        start_positions = batch_tcmr[\"start_positions\"]\n",
    "        end_positions = batch_tcmr[\"end_positions\"]\n",
    "\n",
    "        del batch_tcmr[\"start_positions\"]\n",
    "        del batch_tcmr[\"end_positions\"]\n",
    "        feat = base_kidneyBert(**batch_tcmr)\n",
    "        start_logits,end_logits = model_tcmr(feat)\n",
    "        loss_tcmr = cal_loss(start_positions,end_positions,start_logits,end_logits)\n",
    "\n",
    "        loss_tcmr.backward()\n",
    "        optimizer_tcmr.step()\n",
    "        lr_scheduler_tcmr.step()\n",
    "        optimizer_tcmr.zero_grad()\n",
    "\n",
    "\n",
    "        batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "        start_positions = batch_ifta[\"start_positions\"]\n",
    "        end_positions = batch_ifta[\"end_positions\"]\n",
    "\n",
    "        del batch_ifta[\"start_positions\"]\n",
    "        del batch_ifta[\"end_positions\"]\n",
    "        feat = base_kidneyBert(**batch_ifta)\n",
    "        start_logits,end_logits = model_ifta(feat)\n",
    "        loss_ifta = cal_loss(start_positions,end_positions,start_logits,end_logits)\n",
    "\n",
    "        loss_ifta.backward()\n",
    "        optimizer_ifta.step()\n",
    "        lr_scheduler_ifta.step()\n",
    "        optimizer_ifta.zero_grad()\n",
    "\n",
    "\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            #test the accuracy\n",
    "\n",
    "            print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                  'Loss : {:.4f},{:.4f},{:.4f}'.format(loss_abmr,loss_tcmr,loss_ifta))\n",
    "\n",
    "            res_abmr = compute_metrics(get_pred(model_abmr,abmr_test_loader),abmr_test_ans,abmr_test_ids)\n",
    "            res_tcmr = compute_metrics(get_pred(model_tcmr,tcmr_test_loader),tcmr_test_ans,tcmr_test_ids)\n",
    "            res_ifta = compute_metrics(get_pred(model_ifta,ifta_test_loader),ifta_test_ans,ifta_test_ids)\n",
    "\n",
    "            base_kidneyBert.save_pretrained(f\"./fine_both_qa/step_{step}\")\n",
    "            torch.save(model_abmr.state_dict(),f\"./fine_both_qa/model_abmr_{step}.pth\")\n",
    "            torch.save(model_tcmr.state_dict(),f\"./fine_both_qa/model_tcmr_{step}.pth\")\n",
    "            torch.save(model_ifta.state_dict(),f\"./fine_both_qa/model_ifta_{step}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4994284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kidneyBert.save_pretrained(f\"./fine_both/final\")\n",
    "torch.save(model_isrej.state_dict(),f\"./fine_both/model_isrej_final.pth\")\n",
    "torch.save(model_ifta.state_dict(),f\"./fine_both/model_ifta_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6675ac98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_isrej.load_state_dict(torch.load(\"./fine_both/model_isrej_final.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b26ff0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[638   9]\n",
      " [ 21  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       647\n",
      "           1       0.65      0.45      0.53        38\n",
      "\n",
      "    accuracy                           0.96       685\n",
      "   macro avg       0.81      0.72      0.75       685\n",
      "weighted avg       0.95      0.96      0.95       685\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324  43   0   0]\n",
      " [ 37 164  23   0]\n",
      " [  3  31  38   0]\n",
      " [  3   4  12   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       367\n",
      "           1       0.68      0.73      0.70       224\n",
      "           2       0.52      0.53      0.52        72\n",
      "           3       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.77       685\n",
      "   macro avg       0.77      0.57      0.59       685\n",
      "weighted avg       0.78      0.77      0.77       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))\n",
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac83b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0d3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d4151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "975d05f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1471b661b1a24328bc702210a5ceed2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 2/20 Loss : 0.2560,0.0000\n",
      "accuracy: 0.9445255474452555, precision: 0.9445255474452555, recall: 0.9445255474452555, f1: 0.9445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 4/20 Loss : 0.2050,0.0000\n",
      "accuracy: 0.9562043795620438, precision: 0.9562043795620438, recall: 0.9562043795620438, f1: 0.9562043795620438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 6/20 Loss : 0.0197,0.0000\n",
      "accuracy: 0.9503649635036496, precision: 0.9503649635036496, recall: 0.9503649635036496, f1: 0.9503649635036496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 7/20 Loss : 0.0123,0.0000\n",
      "accuracy: 0.9635036496350365, precision: 0.9635036496350365, recall: 0.9635036496350365, f1: 0.9635036496350365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 9/20 Loss : 0.0687,0.0000\n",
      "accuracy: 0.9547445255474453, precision: 0.9547445255474453, recall: 0.9547445255474453, f1: 0.9547445255474453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 11/20 Loss : 0.0141,0.0000\n",
      "accuracy: 0.9635036496350365, precision: 0.9635036496350365, recall: 0.9635036496350365, f1: 0.9635036496350365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 13/20 Loss : 0.0038,0.0000\n",
      "accuracy: 0.964963503649635, precision: 0.964963503649635, recall: 0.964963503649635, f1: 0.964963503649635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 14/20 Loss : 0.0004,0.0000\n",
      "accuracy: 0.9664233576642336, precision: 0.9664233576642336, recall: 0.9664233576642336, f1: 0.9664233576642337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 16/20 Loss : 0.0024,0.0000\n",
      "accuracy: 0.9664233576642336, precision: 0.9664233576642336, recall: 0.9664233576642336, f1: 0.9664233576642337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 18/20 Loss : 0.0005,0.0000\n",
      "accuracy: 0.9693430656934306, precision: 0.9693430656934306, recall: 0.9693430656934306, f1: 0.9693430656934306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 20/20 Loss : 0.0001,0.0000\n",
      "accuracy: 0.9693430656934306, precision: 0.9693430656934306, recall: 0.9693430656934306, f1: 0.9693430656934306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1 = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "\n",
    "#             batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "#             labels = batch_ifta[\"labels\"]\n",
    "#             del batch_ifta[\"labels\"]\n",
    "#             feat = base_kidneyBert(**batch_ifta)\n",
    "#             outputs = model_ifta(feat)\n",
    "# #             outputs = model_ifta(batch_ifta)\n",
    "#             #print(10)\n",
    "            \n",
    "#             #print(11)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "#             #print(12)\n",
    "#             #print(\"q\",outputs,outputs.shape)\n",
    "#             #print(\"z\",labels,labels.shape)\n",
    "#             loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "#             loss_ifta.backward()\n",
    "\n",
    "#             optimizer_ifta.step()\n",
    "#             lr_scheduler_ifta.step()\n",
    "#             optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_ifta = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "                res = compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                if res[\"f1\"] > best_f1:\n",
    "                    best_f1 = res[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_rej/f1{best_f1}\")\n",
    "                    torch.save(model_isrej.state_dict(),f\"./fine_rej/model_isrej_{best_f1}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1124e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kidneyBert.save_pretrained(f\"./fine_rej/final\")\n",
    "torch.save(model_isrej.state_dict(),f\"./fine_rej/model_isrej_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb0464eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[641   6]\n",
      " [ 15  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       647\n",
      "           1       0.79      0.61      0.69        38\n",
      "\n",
      "    accuracy                           0.97       685\n",
      "   macro avg       0.89      0.80      0.84       685\n",
      "weighted avg       0.97      0.97      0.97       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1e7a5a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8196cdbf2f46509ec9b4ea1dcdd7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 2/20 Loss : 0.0000,0.3606\n",
      "accuracy: 0.7051094890510949, precision: 0.7051094890510949, recall: 0.7051094890510949, f1: 0.7051094890510949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 4/20 Loss : 0.0000,0.4748\n",
      "accuracy: 0.7284671532846715, precision: 0.7284671532846715, recall: 0.7284671532846715, f1: 0.7284671532846715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 6/20 Loss : 0.0000,0.3987\n",
      "accuracy: 0.7138686131386861, precision: 0.7138686131386861, recall: 0.7138686131386861, f1: 0.7138686131386861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 7/20 Loss : 0.0000,0.4292\n",
      "accuracy: 0.7386861313868613, precision: 0.7386861313868613, recall: 0.7386861313868613, f1: 0.7386861313868613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 9/20 Loss : 0.0000,0.1700\n",
      "accuracy: 0.7343065693430657, precision: 0.7343065693430657, recall: 0.7343065693430657, f1: 0.7343065693430656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 11/20 Loss : 0.0000,0.0980\n",
      "accuracy: 0.7138686131386861, precision: 0.7138686131386861, recall: 0.7138686131386861, f1: 0.7138686131386861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 13/20 Loss : 0.0000,0.0224\n",
      "accuracy: 0.7343065693430657, precision: 0.7343065693430657, recall: 0.7343065693430657, f1: 0.7343065693430656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 14/20 Loss : 0.0000,0.0817\n",
      "accuracy: 0.7386861313868613, precision: 0.7386861313868613, recall: 0.7386861313868613, f1: 0.7386861313868613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 16/20 Loss : 0.0000,0.0653\n",
      "accuracy: 0.7401459854014598, precision: 0.7401459854014598, recall: 0.7401459854014598, f1: 0.7401459854014598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 18/20 Loss : 0.0000,0.0056\n",
      "accuracy: 0.7416058394160584, precision: 0.7416058394160584, recall: 0.7416058394160584, f1: 0.7416058394160584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 20/20 Loss : 0.0000,0.0151\n",
      "accuracy: 0.7386861313868613, precision: 0.7386861313868613, recall: 0.7386861313868613, f1: 0.7386861313868613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1 = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "#             batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "#             labels = batch_isrej[\"labels\"]\n",
    "# #             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "#             #print(2)\n",
    "#             del batch_isrej[\"labels\"]\n",
    "#             feat = base_kidneyBert(**batch_isrej)\n",
    "# #             print(feat[0].shape,feat[1].shape)\n",
    "#             outputs = model_isrej(feat)\n",
    "#             #print(3)\n",
    "#             #print(4)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "#             #print(outputs,outputs.shape)\n",
    "#             #print(labels,labels.shape)\n",
    "#             loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "#             #print(6)\n",
    "#             loss_isrej.backward()\n",
    "#             #print(7)\n",
    "\n",
    "#             optimizer_isrej.step()\n",
    "#             lr_scheduler_isrej.step()\n",
    "#             optimizer_isrej.zero_grad()\n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_isrej = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "                res = compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "                if res[\"f1\"] > best_f1:\n",
    "                    best_f1 = res[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_ifta/f1{best_f1}\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_ifta/model_isrej_{best_f1}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87ac4c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kidneyBert.save_pretrained(f\"./fine_ifta/final\")\n",
    "torch.save(model_ifta.state_dict(),f\"./fine_ifta/model_ifta_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65dfd34d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320  42   3   2]\n",
      " [ 49 144  30   1]\n",
      " [  2  29  40   1]\n",
      " [  2   2  14   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       367\n",
      "           1       0.66      0.64      0.65       224\n",
      "           2       0.46      0.56      0.50        72\n",
      "           3       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.74       685\n",
      "   macro avg       0.62      0.56      0.57       685\n",
      "weighted avg       0.74      0.74      0.74       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb52a44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 16.00 GiB total capacity; 14.15 GiB already allocated; 0 bytes free; 14.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_isrej = 0\n",
    "best_f1_ifta = 0\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "            for k, v in batch_isrej.items():\n",
    "                del v\n",
    "                \n",
    "            batch_isrej = 0\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            \n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "                \n",
    "                res_isrej = compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                res_ifta = compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "                if res_isrej[\"f1\"] > best_f1_isrej and res_ifta[\"f1\"] > best_f1_ifta:\n",
    "                    best_f1_isrej = res_isrej[\"f1\"]\n",
    "                    best_f1_ifta = res_ifta[\"f1\"]\n",
    "                    base_kidneyBert.save_pretrained(f\"./fine_both/f1_{best_f1_isrej}_{best_f1_ifta}\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_both/model_isrej_{best_f1_isrej}.pth\")\n",
    "                    torch.save(model_ifta.state_dict(),f\"./fine_both/model_ifta_{best_f1_ifta}.pth\")\n",
    "#                 compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da9650c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e791b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2fe58caabf84b87818e6fc8d4e28d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "            batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "            labels = batch_isrej[\"labels\"]\n",
    "#             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "            #print(2)\n",
    "            del batch_isrej[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_isrej)\n",
    "#             print(feat[0].shape,feat[1].shape)\n",
    "            outputs = model_isrej(feat)\n",
    "            #print(3)\n",
    "            #print(4)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(outputs,outputs.shape)\n",
    "            #print(labels,labels.shape)\n",
    "            loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "            #print(6)\n",
    "            loss_isrej.backward()\n",
    "            #print(7)\n",
    "\n",
    "            optimizer_isrej.step()\n",
    "            #lr_scheduler_isrej.step()\n",
    "            optimizer_isrej.zero_grad()\n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_isrej = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "#                 compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ccf874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:300, EPOCHS : 1/10 Loss : 0.0000,0.5015\n",
      "accuracy: 0.7167883211678832, precision: 0.7167883211678832, recall: 0.7167883211678832, f1: 0.7167883211678832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:600, EPOCHS : 1/10 Loss : 0.0000,0.6111\n",
      "accuracy: 0.6875912408759124, precision: 0.6875912408759124, recall: 0.6875912408759124, f1: 0.6875912408759124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:900, EPOCHS : 2/10 Loss : 0.0000,1.2040\n",
      "accuracy: 0.7299270072992701, precision: 0.7299270072992701, recall: 0.7299270072992701, f1: 0.72992700729927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1200, EPOCHS : 2/10 Loss : 0.0000,0.4732\n",
      "accuracy: 0.7094890510948905, precision: 0.7094890510948905, recall: 0.7094890510948905, f1: 0.7094890510948906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1500, EPOCHS : 3/10 Loss : 0.0000,0.6230\n",
      "accuracy: 0.7124087591240876, precision: 0.7124087591240876, recall: 0.7124087591240876, f1: 0.7124087591240876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:1800, EPOCHS : 3/10 Loss : 0.0000,0.6581\n",
      "accuracy: 0.7299270072992701, precision: 0.7299270072992701, recall: 0.7299270072992701, f1: 0.72992700729927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2100, EPOCHS : 4/10 Loss : 0.0000,0.9544\n",
      "accuracy: 0.7197080291970803, precision: 0.7197080291970803, recall: 0.7197080291970803, f1: 0.7197080291970803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2400, EPOCHS : 4/10 Loss : 0.0000,0.6450\n",
      "accuracy: 0.6963503649635037, precision: 0.6963503649635037, recall: 0.6963503649635037, f1: 0.6963503649635037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:2700, EPOCHS : 4/10 Loss : 0.0000,0.0922\n",
      "accuracy: 0.7401459854014598, precision: 0.7401459854014598, recall: 0.7401459854014598, f1: 0.7401459854014598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3000, EPOCHS : 5/10 Loss : 0.0000,0.6349\n",
      "accuracy: 0.7445255474452555, precision: 0.7445255474452555, recall: 0.7445255474452555, f1: 0.7445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3300, EPOCHS : 5/10 Loss : 0.0000,0.6144\n",
      "accuracy: 0.7401459854014598, precision: 0.7401459854014598, recall: 0.7401459854014598, f1: 0.7401459854014598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3600, EPOCHS : 6/10 Loss : 0.0000,0.2996\n",
      "accuracy: 0.7065693430656934, precision: 0.7065693430656934, recall: 0.7065693430656934, f1: 0.7065693430656934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:3900, EPOCHS : 6/10 Loss : 0.0000,0.2006\n",
      "accuracy: 0.7357664233576642, precision: 0.7357664233576642, recall: 0.7357664233576642, f1: 0.7357664233576642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:4200, EPOCHS : 7/10 Loss : 0.0000,0.4186\n",
      "accuracy: 0.7313868613138687, precision: 0.7313868613138687, recall: 0.7313868613138687, f1: 0.7313868613138687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:4500, EPOCHS : 7/10 Loss : 0.0000,0.7996\n",
      "accuracy: 0.7474452554744525, precision: 0.7474452554744525, recall: 0.7474452554744525, f1: 0.7474452554744525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:4800, EPOCHS : 8/10 Loss : 0.0000,0.3397\n",
      "accuracy: 0.7328467153284671, precision: 0.7328467153284671, recall: 0.7328467153284671, f1: 0.7328467153284671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:5100, EPOCHS : 8/10 Loss : 0.0000,0.9969\n",
      "accuracy: 0.7445255474452555, precision: 0.7445255474452555, recall: 0.7445255474452555, f1: 0.7445255474452555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:5400, EPOCHS : 8/10 Loss : 0.0000,0.1258\n",
      "accuracy: 0.7635036496350365, precision: 0.7635036496350365, recall: 0.7635036496350365, f1: 0.7635036496350364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:5700, EPOCHS : 9/10 Loss : 0.0000,0.1847\n",
      "accuracy: 0.7518248175182481, precision: 0.7518248175182481, recall: 0.7518248175182481, f1: 0.7518248175182483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:6000, EPOCHS : 9/10 Loss : 0.0000,0.0526\n",
      "accuracy: 0.743065693430657, precision: 0.743065693430657, recall: 0.743065693430657, f1: 0.743065693430657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:6300, EPOCHS : 10/10 Loss : 0.0000,0.1960\n",
      "accuracy: 0.743065693430657, precision: 0.743065693430657, recall: 0.743065693430657, f1: 0.743065693430657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP:6600, EPOCHS : 10/10 Loss : 0.0000,0.0521\n",
      "accuracy: 0.743065693430657, precision: 0.743065693430657, recall: 0.743065693430657, f1: 0.743065693430657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6049037/ytc1997/renal_nlp/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "\n",
    "step = 0\n",
    "try:\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_isrej,batch_ifta in zip(isrej_train_loader,ifta_train_loader):\n",
    "            model_isrej.train()\n",
    "            model_ifta.train()\n",
    "            base_kidneyBert.train()\n",
    "            step+=1\n",
    "            #print(step)\n",
    "            #print(1)\n",
    "            \n",
    "            \n",
    "#             batch_isrej = {k: v.to(device) for k, v in batch_isrej.items()}\n",
    "#             labels = batch_isrej[\"labels\"]\n",
    "# #             labels = copy.deepcopy(batch_isrej[\"labels\"]).to(device)\n",
    "#             #print(2)\n",
    "#             del batch_isrej[\"labels\"]\n",
    "#             feat = base_kidneyBert(**batch_isrej)\n",
    "# #             print(feat[0].shape,feat[1].shape)\n",
    "#             outputs = model_isrej(feat)\n",
    "#             #print(3)\n",
    "#             #print(4)\n",
    "#             loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "#             #print(outputs,outputs.shape)\n",
    "#             #print(labels,labels.shape)\n",
    "#             loss_isrej = loss_fct(outputs.view(-1, 2), labels.view(-1))\n",
    "#             #print(6)\n",
    "#             loss_isrej.backward()\n",
    "#             #print(7)\n",
    "\n",
    "#             optimizer_isrej.step()\n",
    "#             #lr_scheduler_isrej.step()\n",
    "#             optimizer_isrej.zero_grad()\n",
    "\n",
    "            batch_ifta = {k: v.to(device) for k, v in batch_ifta.items()}\n",
    "            labels = batch_ifta[\"labels\"]\n",
    "            del batch_ifta[\"labels\"]\n",
    "            feat = base_kidneyBert(**batch_ifta)\n",
    "            outputs = model_ifta(feat)\n",
    "#             outputs = model_ifta(batch_ifta)\n",
    "            #print(10)\n",
    "            \n",
    "            #print(11)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss().to(device)\n",
    "            #print(12)\n",
    "            #print(\"q\",outputs,outputs.shape)\n",
    "            #print(\"z\",labels,labels.shape)\n",
    "            loss_ifta = loss_fct(outputs.view(-1, 4), labels.view(-1))\n",
    "            loss_ifta.backward()\n",
    "\n",
    "            optimizer_ifta.step()\n",
    "            lr_scheduler_ifta.step()\n",
    "            optimizer_ifta.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "    \n",
    "            loss_isrej = 0\n",
    "            if step % 300 == 0:\n",
    "                #test the accuracy\n",
    "\n",
    "                print('STEP:{}, EPOCHS : {}/{}'.format(step,epoch+1,num_epochs),\n",
    "                      'Loss : {:.4f},{:.4f}'.format(loss_isrej,loss_ifta))\n",
    "\n",
    "#                 compute_metrics(get_pred(model_isrej,isrej_test_loader))\n",
    "                compute_metrics(get_pred(model_ifta,ifta_test_loader))\n",
    "except Exception as e:\n",
    "    print(\"Exception\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca99073f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce97145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68a3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "825b8313",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "405aa2ac",
   "metadata": {},
   "source": [
    "## isRejction one task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5068630f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[641   6]\n",
      " [ 15  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       647\n",
      "           1       0.79      0.61      0.69        38\n",
      "\n",
      "    accuracy                           0.97       685\n",
      "   macro avg       0.89      0.80      0.84       685\n",
      "weighted avg       0.97      0.97      0.97       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fc4c0",
   "metadata": {},
   "source": [
    "## isRejction multi tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c0387f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[638   9]\n",
      " [ 21  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       647\n",
      "           1       0.65      0.45      0.53        38\n",
      "\n",
      "    accuracy                           0.96       685\n",
      "   macro avg       0.81      0.72      0.75       685\n",
      "weighted avg       0.95      0.96      0.95       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_isrej,isrej_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a131230",
   "metadata": {},
   "source": [
    "## IFTA one task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9265c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[320  42   3   2]\n",
      " [ 49 144  30   1]\n",
      " [  2  29  40   1]\n",
      " [  2   2  14   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       367\n",
      "           1       0.66      0.64      0.65       224\n",
      "           2       0.46      0.56      0.50        72\n",
      "           3       0.50      0.18      0.27        22\n",
      "\n",
      "    accuracy                           0.74       685\n",
      "   macro avg       0.62      0.56      0.57       685\n",
      "weighted avg       0.74      0.74      0.74       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18010c5",
   "metadata": {},
   "source": [
    "## IFTA multi tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eba45149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-290a08d6a040>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[324  43   0   0]\n",
      " [ 37 164  23   0]\n",
      " [  3  31  38   0]\n",
      " [  3   4  12   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88       367\n",
      "           1       0.68      0.73      0.70       224\n",
      "           2       0.52      0.53      0.52        72\n",
      "           3       1.00      0.14      0.24        22\n",
      "\n",
      "    accuracy                           0.77       685\n",
      "   macro avg       0.77      0.57      0.59       685\n",
      "weighted avg       0.78      0.77      0.77       685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_labels,test_labels = get_pred(model_ifta,ifta_test_loader)\n",
    "print(confusion_matrix(test_labels,pred_labels))\n",
    "print(classification_report(test_labels,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da90be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5672fdcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807da831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a98067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881ca0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9740f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec280a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf76a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1d1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1405214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
