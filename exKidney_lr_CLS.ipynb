{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914f06e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,BertForSequenceClassification, AutoTokenizer, AutoModel,AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42a62bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec63f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43363a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(28996, 768, padding_idx=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b2d1f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 28996 tensor([[-0.0333, -0.0794, -0.0196,  ..., -0.0365, -0.0359,  0.0013],\n",
      "        [ 0.0125, -0.0182, -0.0349,  ..., -0.0387, -0.0596, -0.0106],\n",
      "        [-0.0384, -0.0131,  0.0037,  ..., -0.0394, -0.0423, -0.0357],\n",
      "        ...,\n",
      "        [-0.0045, -0.0044, -0.0520,  ..., -0.0384, -0.0762, -0.0117],\n",
      "        [-0.0235,  0.0125, -0.0237,  ..., -0.0818,  0.0034, -0.0393],\n",
      "        [ 0.0488, -0.0234, -0.0319,  ..., -0.0522, -0.0444, -0.0116]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.embeddings.word_embeddings.named_parameters():\n",
    "    #print(dir(param))\n",
    "    if param.requires_grad:\n",
    "        print(name, len(param.data),param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e930ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 29002 tensor([[-0.0333, -0.0794, -0.0196,  ..., -0.0365, -0.0359,  0.0013],\n",
      "        [ 0.0125, -0.0182, -0.0349,  ..., -0.0387, -0.0596, -0.0106],\n",
      "        [-0.0384, -0.0131,  0.0037,  ..., -0.0394, -0.0423, -0.0357],\n",
      "        ...,\n",
      "        [-0.0015,  0.0085, -0.0136,  ..., -0.0067,  0.0218, -0.0072],\n",
      "        [-0.0160,  0.0052,  0.0189,  ..., -0.0064, -0.0283,  0.0127],\n",
      "        [-0.0282,  0.0033,  0.0212,  ..., -0.0097, -0.0260, -0.0052]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.embeddings.word_embeddings.named_parameters():\n",
    "    #print(dir(param))\n",
    "    if param.requires_grad:\n",
    "        print(name, len(param.data),param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43007b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 29002 tensor([[-0.0333, -0.0794, -0.0196,  ..., -0.0365, -0.0359,  0.0013],\n",
      "        [ 0.0125, -0.0182, -0.0349,  ..., -0.0387, -0.0596, -0.0106],\n",
      "        [-0.0384, -0.0131,  0.0037,  ..., -0.0394, -0.0423, -0.0357],\n",
      "        ...,\n",
      "        [-0.0147, -0.0325, -0.0084,  ..., -0.0460,  0.0382,  0.0045],\n",
      "        [ 0.0046,  0.0099, -0.0027,  ...,  0.0149,  0.0103, -0.0042],\n",
      "        [ 0.0223,  0.0003,  0.0170,  ...,  0.0172, -0.0408, -0.0061]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.embeddings.word_embeddings.named_parameters():\n",
    "    #print(dir(param))\n",
    "    if param.requires_grad:\n",
    "        print(name, len(param.data),param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f1aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 29002 tensor([[-0.0333, -0.0794, -0.0196,  ..., -0.0365, -0.0359,  0.0013],\n",
      "        [ 0.0125, -0.0182, -0.0349,  ..., -0.0387, -0.0596, -0.0106],\n",
      "        [-0.0384, -0.0131,  0.0037,  ..., -0.0394, -0.0423, -0.0357],\n",
      "        ...,\n",
      "        [-0.0376,  0.0200, -0.0143,  ...,  0.0254,  0.0201, -0.0004],\n",
      "        [-0.0055, -0.0355,  0.0392,  ..., -0.0206,  0.0027, -0.0159],\n",
      "        [-0.0111,  0.0308,  0.0389,  ...,  0.0054, -0.0082, -0.0020]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.bert.embeddings.word_embeddings.named_parameters():\n",
    "    #print(dir(param))\n",
    "    if param.requires_grad:\n",
    "        print(name, len(param.data),param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e817fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(29002, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(29002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca311b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.tie_word_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aeff2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.tie_word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2a315e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ccd993fd61e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#weight[-6:]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model.bert.embeddings.word_embeddings.parameters()[-6:] #weight[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28f72a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x0000028B98AEF7B0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb0275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "new_tokens = [\"interstitial\", \"fibrosis\", \"tubular\", \"atrophy\",\"antibody\",\"T-cell\"]\n",
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc60cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8141501",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a28271",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f959a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "# inputs1 = data[\"train_report\"].tolist()\n",
    "inputs1 = data[\"train_report_qa\"].tolist()\n",
    "label1 = data[\"IFTA\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac429a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2 = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "#label = [0 if l in [\"nosig\",\"minimal\",\"noinfo\"] else (1 if l==\"mild\" else (2 if l==\"moderate\" else 3)) for l in label2]\n",
    "label = []\n",
    "for l in label2:\n",
    "    if l == \"noinfo\":\n",
    "        label.append(0)\n",
    "    elif l == \"nosig\":\n",
    "        label.append(1)\n",
    "    elif l == \"minimal\":\n",
    "        label.append(2)\n",
    "    elif l == \"mild\":\n",
    "        label.append(3)\n",
    "    elif l == \"moderate\":\n",
    "        label.append(4)\n",
    "    else:\n",
    "        label.append(5)\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b7fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f547a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    precision = precision_score(y_true=labels, y_pred=pred,average=\"micro\")\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred,average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c865f6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./mlm_results_largeData_extended_tokenizer_lr/checkpoint-1400 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./mlm_results_largeData_extended_tokenizer_lr/checkpoint-1400 and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\",num_labels=6)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\",num_labels=6)\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData_extended_tokenizer_lr/checkpoint-1400\",num_labels=6)\n",
    "#model_renal = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\",num_labels=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fe337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='928' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 928/2580 10:39 < 19:00, 1.45 it/s, Epoch 5.39/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.557700</td>\n",
       "      <td>1.388861</td>\n",
       "      <td>0.512409</td>\n",
       "      <td>0.512409</td>\n",
       "      <td>0.512409</td>\n",
       "      <td>0.424480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.231300</td>\n",
       "      <td>1.162278</td>\n",
       "      <td>0.597080</td>\n",
       "      <td>0.597080</td>\n",
       "      <td>0.597080</td>\n",
       "      <td>0.492329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.212000</td>\n",
       "      <td>1.105211</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.502948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.053624</td>\n",
       "      <td>0.618978</td>\n",
       "      <td>0.618978</td>\n",
       "      <td>0.618978</td>\n",
       "      <td>0.550526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.072400</td>\n",
       "      <td>0.930673</td>\n",
       "      <td>0.651095</td>\n",
       "      <td>0.651095</td>\n",
       "      <td>0.651095</td>\n",
       "      <td>0.576806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.960700</td>\n",
       "      <td>0.959221</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.594036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.925783</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.590649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.964335</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.652555</td>\n",
       "      <td>0.631400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.879100</td>\n",
       "      <td>0.998828</td>\n",
       "      <td>0.637956</td>\n",
       "      <td>0.637956</td>\n",
       "      <td>0.637956</td>\n",
       "      <td>0.564034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.956500</td>\n",
       "      <td>0.960702</td>\n",
       "      <td>0.626277</td>\n",
       "      <td>0.626277</td>\n",
       "      <td>0.626277</td>\n",
       "      <td>0.543292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.897400</td>\n",
       "      <td>0.900393</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.651787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.799600</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.624733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.791900</td>\n",
       "      <td>0.902600</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.674817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.820900</td>\n",
       "      <td>0.923911</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.667745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0.937547</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.678342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>0.877352</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.680647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.756600</td>\n",
       "      <td>0.914191</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.657560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.702200</td>\n",
       "      <td>0.962043</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.657759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# BERT - ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2055' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2055/2580 24:10 < 06:10, 1.42 it/s, Epoch 11.94/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.462600</td>\n",
       "      <td>1.183166</td>\n",
       "      <td>0.581022</td>\n",
       "      <td>0.581022</td>\n",
       "      <td>0.581022</td>\n",
       "      <td>0.477052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.101800</td>\n",
       "      <td>0.980255</td>\n",
       "      <td>0.633577</td>\n",
       "      <td>0.633577</td>\n",
       "      <td>0.633577</td>\n",
       "      <td>0.562757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.085300</td>\n",
       "      <td>0.928196</td>\n",
       "      <td>0.658394</td>\n",
       "      <td>0.658394</td>\n",
       "      <td>0.658394</td>\n",
       "      <td>0.576777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.965800</td>\n",
       "      <td>0.902720</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.628368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.866512</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.648810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.915600</td>\n",
       "      <td>0.905765</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>0.626471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>0.855402</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.658419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.803300</td>\n",
       "      <td>0.824018</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.696512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.780700</td>\n",
       "      <td>0.822974</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.673226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.805589</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.651244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.776200</td>\n",
       "      <td>0.814279</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.685920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>0.798045</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.706128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.676000</td>\n",
       "      <td>0.787001</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.719386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.685900</td>\n",
       "      <td>0.790187</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.714213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.821723</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.706207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.588400</td>\n",
       "      <td>0.800565</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.708680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>0.903201</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.665163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.807365</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.711812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.455500</td>\n",
       "      <td>0.839640</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.706885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.484300</td>\n",
       "      <td>0.863786</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.697163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.819988</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.741606</td>\n",
       "      <td>0.731570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.887762</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.704912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.959270</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.696656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.966265</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.686979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.945188</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.706930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>0.952454</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.712899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.940056</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.728167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.968583</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.712404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>1.067602</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.714613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>1.069287</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.727007</td>\n",
       "      <td>0.717233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>1.162723</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.688315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>1.149429</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.701722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>1.143990</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.718412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>1.110595</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>1.202370</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.701241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.141000</td>\n",
       "      <td>1.199023</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.715976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>1.250864</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.724491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.144200</td>\n",
       "      <td>1.316680</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.719683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>1.297016</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.740146</td>\n",
       "      <td>0.735013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>1.316818</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>1.347557</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.707457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# KidneyBERT - ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a5cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 30:16, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.456200</td>\n",
       "      <td>1.151662</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.491674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.795100</td>\n",
       "      <td>0.438924</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.823548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.408765</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.878131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.340700</td>\n",
       "      <td>0.387071</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.873957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.331900</td>\n",
       "      <td>0.365728</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.903574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.397677</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.868524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.352807</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.890348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.419329</td>\n",
       "      <td>0.874453</td>\n",
       "      <td>0.874453</td>\n",
       "      <td>0.874453</td>\n",
       "      <td>0.876963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.387285</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.891748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.388091</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.431910</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.877223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.211500</td>\n",
       "      <td>0.376059</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.899586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.202800</td>\n",
       "      <td>0.397013</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.903118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.399934</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.416235</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.905924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0.456342</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.895949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.205600</td>\n",
       "      <td>0.438797</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.896496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.388170</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.908341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>0.371842</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.908279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.090900</td>\n",
       "      <td>0.446107</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.907557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.396007</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.479062</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.909790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.469331</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>0.459747</td>\n",
       "      <td>0.918248</td>\n",
       "      <td>0.918248</td>\n",
       "      <td>0.918248</td>\n",
       "      <td>0.915359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.494355</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.894471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.459524</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.485615</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.907387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.519547</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.905373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.499014</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.903401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.486521</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.900571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.487368</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.519407</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.913037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.573968</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.892179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.518712</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.897889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.475670</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.907551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.471452</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.911114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.483330</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.911911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.497756</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.904236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.502894</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.905582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.506372</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.912194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.521909</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.911794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.504907</td>\n",
       "      <td>0.918248</td>\n",
       "      <td>0.918248</td>\n",
       "      <td>0.918248</td>\n",
       "      <td>0.916971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>0.515401</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.909480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.517471</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.910210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.021200</td>\n",
       "      <td>0.519722</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.512720</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.525800</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.909994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.523817</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.913073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.527049</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.910009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.527725</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.911199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.529512</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.911199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350 (score: 0.3528066575527191).\n"
     ]
    }
   ],
   "source": [
    "# KidneyBERT - qa ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacc7d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 30:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.462900</td>\n",
       "      <td>1.143271</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.493175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.083766</td>\n",
       "      <td>0.616058</td>\n",
       "      <td>0.616058</td>\n",
       "      <td>0.616058</td>\n",
       "      <td>0.541205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.075200</td>\n",
       "      <td>0.950542</td>\n",
       "      <td>0.659854</td>\n",
       "      <td>0.659854</td>\n",
       "      <td>0.659854</td>\n",
       "      <td>0.595676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.952100</td>\n",
       "      <td>0.937897</td>\n",
       "      <td>0.630657</td>\n",
       "      <td>0.630657</td>\n",
       "      <td>0.630657</td>\n",
       "      <td>0.579477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.954400</td>\n",
       "      <td>0.900083</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>0.667153</td>\n",
       "      <td>0.637690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.915300</td>\n",
       "      <td>0.862881</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.669477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.818500</td>\n",
       "      <td>0.843714</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.635012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.792400</td>\n",
       "      <td>0.832210</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.675337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>0.835042</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.666819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.816369</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.632238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.778700</td>\n",
       "      <td>0.868986</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.656244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.649300</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.680937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.662100</td>\n",
       "      <td>0.864794</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.703277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.687100</td>\n",
       "      <td>0.805791</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.698604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.806257</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.712409</td>\n",
       "      <td>0.706537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.865095</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.692174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.671508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.890737</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>0.670073</td>\n",
       "      <td>0.659929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.939224</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.686072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.491400</td>\n",
       "      <td>0.936527</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.681124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.909082</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.690342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.369500</td>\n",
       "      <td>1.007236</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.670329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.365800</td>\n",
       "      <td>0.956974</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.688653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.995672</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.682116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>1.070074</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.689121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.312800</td>\n",
       "      <td>1.013628</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.690377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.279100</td>\n",
       "      <td>1.017693</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.704851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>1.075537</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.683765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>1.125861</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.694490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.232800</td>\n",
       "      <td>1.203528</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.693431</td>\n",
       "      <td>0.682788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.201400</td>\n",
       "      <td>1.272301</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.673647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>1.200092</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.690216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>1.227688</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.693964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.144900</td>\n",
       "      <td>1.286478</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.689807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>1.317992</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.703479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>1.264870</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.701086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>1.345215</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.698613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.126500</td>\n",
       "      <td>1.403882</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.694998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>1.435757</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.705503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>1.425594</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.699212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.080500</td>\n",
       "      <td>1.495768</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.703557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>1.502190</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.698525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>1.531617</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.699109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>1.558958</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.694025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>1.537218</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.701104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>1.546296</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.700203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>1.593310</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.705109</td>\n",
       "      <td>0.698530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.044800</td>\n",
       "      <td>1.583525</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.706499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>1.606003</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.706186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.602924</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.708092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>1.592252</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.706819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700 (score: 0.8057909607887268).\n"
     ]
    }
   ],
   "source": [
    "# exKidneyBERT - ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac56308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2580' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2580/2580 29:47, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.451600</td>\n",
       "      <td>1.075703</td>\n",
       "      <td>0.626277</td>\n",
       "      <td>0.626277</td>\n",
       "      <td>0.626277</td>\n",
       "      <td>0.512141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.647800</td>\n",
       "      <td>0.414251</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.880026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.460300</td>\n",
       "      <td>0.437068</td>\n",
       "      <td>0.872993</td>\n",
       "      <td>0.872993</td>\n",
       "      <td>0.872993</td>\n",
       "      <td>0.851261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.424771</td>\n",
       "      <td>0.887591</td>\n",
       "      <td>0.887591</td>\n",
       "      <td>0.887591</td>\n",
       "      <td>0.861179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.402230</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.876411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.361697</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.886696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.407881</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.891341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.424414</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.886123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.259900</td>\n",
       "      <td>0.417459</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.881994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.236100</td>\n",
       "      <td>0.390827</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.437128</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.887067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>0.438553</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.899203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.409790</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.897130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.191900</td>\n",
       "      <td>0.403348</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.901054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.389705</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.898539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.437566</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.418073</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.899968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.413029</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.899094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.129600</td>\n",
       "      <td>0.404817</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.904598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.439338</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.902823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.457635</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.895860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.073500</td>\n",
       "      <td>0.497043</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.895701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.500306</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.900328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.467408</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.901544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.092900</td>\n",
       "      <td>0.532733</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.885112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.477614</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.120200</td>\n",
       "      <td>0.492847</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.903005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.494926</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.905193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.536288</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.085400</td>\n",
       "      <td>0.470583</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.907085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.062100</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.904291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.519878</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.899584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.568740</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.896527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.552914</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.901021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.511897</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.547969</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.904644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.535356</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.909976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.518306</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.907410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.027200</td>\n",
       "      <td>0.540082</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.901553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.548513</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.548791</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.898351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.561544</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.899678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.538602</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.905382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.546423</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.901683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.564512</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.903280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.570104</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.902643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>0.569711</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.904640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.573160</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.902643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.574569</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.903409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.580296</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.904905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.580977</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.904905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\n",
      "Configuration saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_mlm_results_ifta_4labels_largeData_batch16_extoken\\checkpoint-300 (score: 0.3616968095302582).\n"
     ]
    }
   ],
   "source": [
    "# exKidneyBERT_lr - qa ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_mlm_results_ifta_4labels_largeData_batch16_extoken',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bee0c9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2651' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2651/3440 30:50 < 09:11, 1.43 it/s, Epoch 15.41/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.489700</td>\n",
       "      <td>1.287165</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.518248</td>\n",
       "      <td>0.422044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.158700</td>\n",
       "      <td>1.048901</td>\n",
       "      <td>0.610219</td>\n",
       "      <td>0.610219</td>\n",
       "      <td>0.610219</td>\n",
       "      <td>0.500856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.078100</td>\n",
       "      <td>0.960798</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.591547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.978900</td>\n",
       "      <td>0.916042</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.623582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.965100</td>\n",
       "      <td>0.888289</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.649876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.893400</td>\n",
       "      <td>0.889392</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.691971</td>\n",
       "      <td>0.643470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.823500</td>\n",
       "      <td>0.842183</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.651656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>0.846844</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.679359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.802100</td>\n",
       "      <td>0.880122</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0.629390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.832600</td>\n",
       "      <td>0.841846</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.636635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.806600</td>\n",
       "      <td>0.856462</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.664598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.679500</td>\n",
       "      <td>0.812379</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.693929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.740700</td>\n",
       "      <td>0.791868</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.694622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.717700</td>\n",
       "      <td>0.865430</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.671533</td>\n",
       "      <td>0.656638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.783763</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.727999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.628800</td>\n",
       "      <td>0.828078</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.696208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.670100</td>\n",
       "      <td>0.825267</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.690792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.598200</td>\n",
       "      <td>0.817623</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.707895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.509200</td>\n",
       "      <td>0.849805</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.720001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.879078</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.704398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.539200</td>\n",
       "      <td>0.878554</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.710235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.422900</td>\n",
       "      <td>0.934870</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.692802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.870797</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.714585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.851115</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.716931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>0.945792</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.700105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.967294</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.716497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.979541</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.708845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.298100</td>\n",
       "      <td>1.015499</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.267400</td>\n",
       "      <td>0.978319</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.717098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>1.091705</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.713169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.292100</td>\n",
       "      <td>1.049754</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.691066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.215900</td>\n",
       "      <td>1.096912</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.708047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>1.173169</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.722628</td>\n",
       "      <td>0.712032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>1.146533</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.693916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>1.237270</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.708103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.213800</td>\n",
       "      <td>1.268015</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.703226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.155300</td>\n",
       "      <td>1.343373</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.714126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>1.392333</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.684672</td>\n",
       "      <td>0.681512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>1.490923</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.686131</td>\n",
       "      <td>0.691928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.147700</td>\n",
       "      <td>1.469238</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.698616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.165500</td>\n",
       "      <td>1.427136</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.691957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.128900</td>\n",
       "      <td>1.358557</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.726098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>1.441901</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.711347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.111400</td>\n",
       "      <td>1.499934</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.712743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>1.580442</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.700730</td>\n",
       "      <td>0.701701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.094000</td>\n",
       "      <td>1.589005</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.697922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>1.664106</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.698987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>1.660519</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.706569</td>\n",
       "      <td>0.697459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>1.643861</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.697989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.671941</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.692385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>1.733601</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.693874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>1.776549</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.689051</td>\n",
       "      <td>0.688211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7/11 00:04 < 00:02, 1.45 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d5b5eb72a75e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1438\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1440\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1441\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1442\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1563\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m             \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2208\u001b[1;33m         output = eval_loop(\n\u001b[0m\u001b[0;32m   2209\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2210\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Evaluation\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   2390\u001b[0m                 \u001b[0mlosses_host\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlosses_host\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2392\u001b[1;33m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2393\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m                 \u001b[0mpreds_host\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreds_host\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[1;34m(self, tensor, pad_index)\u001b[0m\n\u001b[0;32m   2504\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2505\u001b[0m         \u001b[1;31m# Gather all sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2506\u001b[1;33m         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2507\u001b[0m         \u001b[0msizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# BioBERT - ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_bioBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530d18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2708' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2708/3440 31:45 < 08:35, 1.42 it/s, Epoch 15.74/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.501500</td>\n",
       "      <td>1.382176</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.357851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.051000</td>\n",
       "      <td>0.842015</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.636124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.853300</td>\n",
       "      <td>0.736691</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.665873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>0.679440</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>0.729630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.552100</td>\n",
       "      <td>0.484167</td>\n",
       "      <td>0.871533</td>\n",
       "      <td>0.871533</td>\n",
       "      <td>0.871533</td>\n",
       "      <td>0.854789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.466900</td>\n",
       "      <td>0.446796</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.846423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>0.521461</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.843272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.546551</td>\n",
       "      <td>0.826277</td>\n",
       "      <td>0.826277</td>\n",
       "      <td>0.826277</td>\n",
       "      <td>0.837394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.467222</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>0.392983</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.891971</td>\n",
       "      <td>0.877525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.324300</td>\n",
       "      <td>0.477253</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.874266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.265700</td>\n",
       "      <td>0.447378</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.880600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.424018</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.877909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.267000</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.889051</td>\n",
       "      <td>0.879448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.426076</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.894158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.264200</td>\n",
       "      <td>0.424229</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.885803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.430796</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.891284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.376748</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.891399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.394552</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.899459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.193200</td>\n",
       "      <td>0.394838</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.404247</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.896554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.510584</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.892874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.169500</td>\n",
       "      <td>0.469543</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.905330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.439838</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.905387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.427337</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.904412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.418826</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.908381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.433871</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.905523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.464505</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.907831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.478818</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.909127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.430707</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.907110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.472141</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.899572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.415344</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.911389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.449110</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.911897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.115500</td>\n",
       "      <td>0.460211</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.515937</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.905251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.520120</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.902786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.542722</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.532887</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.903035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.514645</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.910378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.604245</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.898943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.040700</td>\n",
       "      <td>0.556873</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.907686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.538994</td>\n",
       "      <td>0.916788</td>\n",
       "      <td>0.916788</td>\n",
       "      <td>0.916788</td>\n",
       "      <td>0.913029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.075500</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.909818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.511567</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.533393</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.912726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.577115</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.910508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.558086</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.919708</td>\n",
       "      <td>0.918503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.060300</td>\n",
       "      <td>0.525237</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.580091</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.911612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.573976</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>0.610280</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.915352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.605717</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.914170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.611778</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.913967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.608546</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.913869</td>\n",
       "      <td>0.915553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700\n",
      "Configuration saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_bioBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# BioBERT - qa ifta cls \n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_bioBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d6cc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2358' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2358/2580 27:30 < 02:35, 1.43 it/s, Epoch 13.70/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.554000</td>\n",
       "      <td>1.242224</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>0.471908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.124300</td>\n",
       "      <td>1.165618</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.501815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.152900</td>\n",
       "      <td>0.963942</td>\n",
       "      <td>0.643796</td>\n",
       "      <td>0.643796</td>\n",
       "      <td>0.643796</td>\n",
       "      <td>0.553779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.032000</td>\n",
       "      <td>0.929965</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.662774</td>\n",
       "      <td>0.593074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.994200</td>\n",
       "      <td>0.885117</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.596577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.914700</td>\n",
       "      <td>0.883437</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.665693</td>\n",
       "      <td>0.591820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.858240</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.624408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.826329</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.694891</td>\n",
       "      <td>0.685623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.792800</td>\n",
       "      <td>0.875262</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.687591</td>\n",
       "      <td>0.650343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>0.802420</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.669661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.785900</td>\n",
       "      <td>0.797607</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.693338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.828011</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.691048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>0.803753</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.696475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.751000</td>\n",
       "      <td>0.870880</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.683212</td>\n",
       "      <td>0.666696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.634400</td>\n",
       "      <td>0.862304</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.699270</td>\n",
       "      <td>0.691173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.675100</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.724088</td>\n",
       "      <td>0.718563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.709000</td>\n",
       "      <td>0.828718</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.681547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.660400</td>\n",
       "      <td>0.770778</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.734307</td>\n",
       "      <td>0.720243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.835780</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.713232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.597200</td>\n",
       "      <td>0.814706</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.705055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.541500</td>\n",
       "      <td>0.762933</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.748905</td>\n",
       "      <td>0.741125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.507700</td>\n",
       "      <td>0.916388</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.696350</td>\n",
       "      <td>0.681638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.906030</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.719210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.492200</td>\n",
       "      <td>0.833288</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.716659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>0.862193</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.717097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.971752</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.699108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.423100</td>\n",
       "      <td>0.859620</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.707745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.385800</td>\n",
       "      <td>0.935264</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.710949</td>\n",
       "      <td>0.701922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.947350</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.705791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.355600</td>\n",
       "      <td>0.953126</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.721168</td>\n",
       "      <td>0.709724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.296600</td>\n",
       "      <td>0.955412</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.697810</td>\n",
       "      <td>0.690875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.942499</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.727149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.992918</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.712651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.997563</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.719193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>1.031797</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.725547</td>\n",
       "      <td>0.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>1.072917</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.708029</td>\n",
       "      <td>0.700883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>1.105643</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.716788</td>\n",
       "      <td>0.706204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.221300</td>\n",
       "      <td>1.153420</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.710183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.143100</td>\n",
       "      <td>1.187932</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.710149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.144000</td>\n",
       "      <td>1.181399</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.715997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>1.205722</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.709489</td>\n",
       "      <td>0.703678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>1.214140</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.732847</td>\n",
       "      <td>0.728614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>1.260206</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.718248</td>\n",
       "      <td>0.716339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>1.306476</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.719708</td>\n",
       "      <td>0.718562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>1.353462</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.713869</td>\n",
       "      <td>0.710552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>1.374028</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.715328</td>\n",
       "      <td>0.710817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>1.439176</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.702190</td>\n",
       "      <td>0.696340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# ClinicalBERT - ifta cls\n",
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=6)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8544bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2580\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2425' max='2580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2425/2580 28:24 < 01:49, 1.42 it/s, Epoch 14.09/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.492300</td>\n",
       "      <td>1.285793</td>\n",
       "      <td>0.534307</td>\n",
       "      <td>0.534307</td>\n",
       "      <td>0.534307</td>\n",
       "      <td>0.429406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.099200</td>\n",
       "      <td>0.953476</td>\n",
       "      <td>0.668613</td>\n",
       "      <td>0.668613</td>\n",
       "      <td>0.668613</td>\n",
       "      <td>0.594669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>0.826294</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.738686</td>\n",
       "      <td>0.657862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.496641</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.846715</td>\n",
       "      <td>0.805063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.426770</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.865124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>0.423094</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.881752</td>\n",
       "      <td>0.861376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.373200</td>\n",
       "      <td>0.447873</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.878666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.384700</td>\n",
       "      <td>0.447438</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.865693</td>\n",
       "      <td>0.867447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.309600</td>\n",
       "      <td>0.414070</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.886131</td>\n",
       "      <td>0.873508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.352900</td>\n",
       "      <td>0.355984</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.899270</td>\n",
       "      <td>0.898160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.412763</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.880313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.229900</td>\n",
       "      <td>0.440152</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.884672</td>\n",
       "      <td>0.874101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.299500</td>\n",
       "      <td>0.402839</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.878783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.375754</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.894734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>0.376643</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.901066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.253800</td>\n",
       "      <td>0.372458</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.884632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.249100</td>\n",
       "      <td>0.436130</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.893733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.376174</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.896847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.197000</td>\n",
       "      <td>0.397187</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.902426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.401979</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.904541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.409196</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.897956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.494923</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.885638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.135800</td>\n",
       "      <td>0.475650</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>0.885993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.449390</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.898192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.485467</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.891169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.439488</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.903459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.146300</td>\n",
       "      <td>0.442924</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.894891</td>\n",
       "      <td>0.890008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.083300</td>\n",
       "      <td>0.467591</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.894591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>0.482883</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>0.900738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.909489</td>\n",
       "      <td>0.904558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.086400</td>\n",
       "      <td>0.410643</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.906943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.460092</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.900947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.053600</td>\n",
       "      <td>0.534060</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.899861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>0.457825</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.907638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.461105</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.910949</td>\n",
       "      <td>0.907661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.493082</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.902944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.513883</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.897214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.514596</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.896350</td>\n",
       "      <td>0.897150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.906569</td>\n",
       "      <td>0.903744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.534187</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900730</td>\n",
       "      <td>0.900870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.536435</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.903130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.536454</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.905537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.543745</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893431</td>\n",
       "      <td>0.893401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.547782</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.900769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.561744</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.901224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.560620</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.903650</td>\n",
       "      <td>0.902369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.554065</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>0.903816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>0.543609</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.902175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\n",
      "Configuration saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_cliBERT_results_ifta_4labels_largeData_batch16\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-6-42ad60b603ba>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# ClinicalBERT - qa ifta cls\n",
    "batch_size = 16\n",
    "model_cli = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\",num_labels=6)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_cliBERT_results_ifta_4labels_largeData_batch16',          \n",
    "    num_train_epochs=15,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*4,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=0.01,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_cli,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ecf970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5db2e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f263179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a33765f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,BertForSequenceClassification, AutoTokenizer, AutoModel,AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a259d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "new_tokens = [\"interstitial\", \"fibrosis\", \"tubular\", \"atrophy\",\"antibody\",\"T-cell\"]\n",
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b36e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c875cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdae117",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "inputs1 = data[\"train_report_qa\"].tolist()\n",
    "label1 = data[\"isRejection\"].tolist()\n",
    "\n",
    "label = [l for i,l in zip(inputs1,label1) if str(i)!=\"nan\"]\n",
    "inputs = [i for i in inputs1 if str(i)!=\"nan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee44b62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(\n",
    "    inputs, label,random_state = 1,stratify=label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acd8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RenalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e4e4cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_encodings = tokenizer(train_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "test_encodings = tokenizer(test_text,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)\n",
    "train_dataset = RenalDataset(train_encodings, train_labels)\n",
    "test_dataset = RenalDataset(test_encodings, test_labels)\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData/checkpoint-1100\")\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "# model_renal = AutoModelForSequenceClassification.from_pretrained(\"./mlm_results_largeData_extended_tokenizer/checkpoint-1100\")\n",
    "model_renal = AutoModelForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316f8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1615' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1615/3440 18:39 < 21:06, 1.44 it/s, Epoch 9.38/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>0.224976</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>0.243678</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.226800</td>\n",
       "      <td>0.210406</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.189300</td>\n",
       "      <td>0.139218</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.123087</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.245881</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.174738</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.448980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.144836</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.127100</td>\n",
       "      <td>0.129198</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.162830</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.184400</td>\n",
       "      <td>0.198171</td>\n",
       "      <td>0.940146</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.438356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.114002</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.115600</td>\n",
       "      <td>0.112736</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.110678</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.131383</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.144843</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.220846</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>0.131350</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.166565</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.674157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.124197</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>0.147531</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.129348</td>\n",
       "      <td>0.975182</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.064800</td>\n",
       "      <td>0.187165</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.578313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.175273</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.158703</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.152722</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.210694</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.181773</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.193747</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.177121</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.716418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# BioBERT - qa cls\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_exkidBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ce4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1627' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1627/3440 19:03 < 21:15, 1.42 it/s, Epoch 9.45/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.317800</td>\n",
       "      <td>0.229680</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.214161</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.191500</td>\n",
       "      <td>0.150284</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.217008</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.150063</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.452830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.132223</td>\n",
       "      <td>0.947445</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.491803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.152015</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.145495</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.431373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.183383</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.452830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.137300</td>\n",
       "      <td>0.192427</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.629213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.154726</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.152324</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.118900</td>\n",
       "      <td>0.163388</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.159202</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.148351</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.187894</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.100500</td>\n",
       "      <td>0.167416</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>0.160447</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.174275</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.184726</td>\n",
       "      <td>0.950365</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.585366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.141047</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.098200</td>\n",
       "      <td>0.164046</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.183249</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.202923</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.220392</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.208218</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.189606</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.186221</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.509091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.193125</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.431373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# Clinical BERT - qa cls\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_exkidBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b1c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3404' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3404/3440 40:04 < 00:25, 1.42 it/s, Epoch 19.78/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.219373</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>0.265068</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>0.220932</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.203422</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>0.166120</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.187900</td>\n",
       "      <td>0.301379</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.190871</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.169900</td>\n",
       "      <td>0.134971</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.224407</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.168174</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.153367</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.232558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.109000</td>\n",
       "      <td>0.188875</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.149800</td>\n",
       "      <td>0.138545</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.160300</td>\n",
       "      <td>0.126619</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.169564</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.164983</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.183454</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.134800</td>\n",
       "      <td>0.144437</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.072900</td>\n",
       "      <td>0.142171</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.676056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.133081</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.192484</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.078300</td>\n",
       "      <td>0.126724</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.123896</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.157218</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.617021</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.166181</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.138041</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.160551</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.164016</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.707692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.153386</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.165510</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.029100</td>\n",
       "      <td>0.183024</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.644068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.203264</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.162253</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.134204</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.170117</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.238007</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.177797</td>\n",
       "      <td>0.972263</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.186018</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.201138</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.238694</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.242269</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.232862</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.218999</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.258628</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.217832</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.232881</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.237986</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.252469</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.232779</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.220123</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.235149</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.242541</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.259211</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.253923</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.231933</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.234573</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.712329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.266069</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.270943</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.270351</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.270615</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.258706</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.266498</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.267663</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.262012</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.267920</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.268914</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.270326</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "# Kidney BERT - qa cls\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_exkidBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f77100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3440\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3440' max='3440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3440/3440 40:26, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.224674</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.278130</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.184699</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.201900</td>\n",
       "      <td>0.163006</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.127365</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.168400</td>\n",
       "      <td>0.247684</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>0.193167</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.116394</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.115300</td>\n",
       "      <td>0.167927</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.127723</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.136376</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.542373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.165003</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.142965</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.121210</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.637681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.163984</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>0.171464</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.230091</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.472727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.081500</td>\n",
       "      <td>0.149363</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.180466</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.657534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>0.194978</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.704225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.177177</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.025600</td>\n",
       "      <td>0.217258</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.203154</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.275439</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.472727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.241193</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.224902</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.263204</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.223972</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.233193</td>\n",
       "      <td>0.969343</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.240946</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.240881</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.278421</td>\n",
       "      <td>0.951825</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.602410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>0.250578</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.230333</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.261507</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.263793</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.291024</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.276981</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.263623</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.306551</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.276765</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.597015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.333894</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.264444</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.305463</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.294177</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.284935</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.302366</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.299559</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.586207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.284017</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.286936</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.263485</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.276680</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.281505</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.283745</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.287766</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.282497</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.299067</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300203</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301422</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301766</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302561</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.303310</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.306508</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306725</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307034</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307278</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307420</td>\n",
       "      <td>0.967883</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-50] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2450] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2550] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2650] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2750] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2850] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2950] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3050] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3150] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3250] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3350] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400 (score: 0.11639368534088135).\n"
     ]
    }
   ],
   "source": [
    "# exKidney BERT - qa cls\n",
    "\n",
    "batch_size = 16\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_exkidBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ff5f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2738\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 6860\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6860' max='6860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6860/6860 43:38, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.270800</td>\n",
       "      <td>0.276292</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.293186</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.230500</td>\n",
       "      <td>0.232601</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.205782</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.243196</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.255087</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>0.281646</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.168213</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.174800</td>\n",
       "      <td>0.177754</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.164829</td>\n",
       "      <td>0.944526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.194900</td>\n",
       "      <td>0.232532</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.132567</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>0.152056</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.208900</td>\n",
       "      <td>0.174235</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.147187</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.168400</td>\n",
       "      <td>0.206138</td>\n",
       "      <td>0.953285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.149168</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.137029</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.528302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.108900</td>\n",
       "      <td>0.134814</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.183389</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.127000</td>\n",
       "      <td>0.219599</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.508475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.656716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.126200</td>\n",
       "      <td>0.182336</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.201987</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.181523</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>0.229472</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.102700</td>\n",
       "      <td>0.174133</td>\n",
       "      <td>0.966423</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.272245</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.207269</td>\n",
       "      <td>0.964964</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.183927</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.231029</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.491228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.065300</td>\n",
       "      <td>0.245634</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.248230</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.508475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>0.258728</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.574468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.182264</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.279233</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.575342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.064200</td>\n",
       "      <td>0.289404</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>0.309504</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.276384</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.244878</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.254896</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.285763</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.286735</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.268625</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.277562</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.591549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.336614</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.360227</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.271658</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.323224</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.524590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.299939</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.284736</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.304305</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.320452</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.343562</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.350880</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.567164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.361014</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.026100</td>\n",
       "      <td>0.354937</td>\n",
       "      <td>0.957664</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.524590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.361993</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.344037</td>\n",
       "      <td>0.962044</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.346447</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.584615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.354929</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.360291</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.367348</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.355915</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.355266</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.362939</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.361685</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.367764</td>\n",
       "      <td>0.960584</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-1200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-3900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-4900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5800] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-5900] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6000] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6100] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6200] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6300] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6400] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6500] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6600] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 685\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\n",
      "Configuration saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\\config.json\n",
      "Model weights saved in ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6800\\pytorch_model.bin\n",
      "Deleting older checkpoint [fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-6700] due to args.save_total_limit\n",
      "<ipython-input-5-f26e59613042>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./fine_exkidBERTcased_results_largeData_batch16_wd1e-5\\checkpoint-2200 (score: 0.12533804774284363).\n"
     ]
    }
   ],
   "source": [
    "# exKidney BERT - qa cls\n",
    "\n",
    "batch_size = 8\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./fine_exkidBERTcased_results_largeData_batch16_wd1e-5',          \n",
    "    num_train_epochs=20,              \n",
    "    per_device_train_batch_size=batch_size,  \n",
    "    per_device_eval_batch_size=batch_size*2,   \n",
    "    warmup_steps=50,                \n",
    "    weight_decay=1e-5,                          \n",
    "    logging_steps=50*16/batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50*16/batch_size,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps = 50*16/batch_size,\n",
    "    save_total_limit = 1,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_renal,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "try:\n",
    "    \n",
    "    trainer.train()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfe577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05cf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867771a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
