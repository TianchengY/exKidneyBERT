{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2955652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead,BertForSequenceClassification, AutoTokenizer, AutoModel,AutoModelForMaskedLM,AutoModelForSequenceClassification\n",
    "import torch\n",
    "from torch import nn\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score,roc_curve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7870c15",
   "metadata": {},
   "source": [
    "# Fine-tune Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334ed089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "new_tokens = [\"interstitial\", \"fibrosis\", \"tubular\", \"atrophy\",\"antibody\",\"T-cell\"]\n",
    "tokenizer.add_tokens(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91fe4cc4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interstitial',\n",
       " 'fibrosis',\n",
       " 'and',\n",
       " 'tubular',\n",
       " 'atrophy',\n",
       " '.',\n",
       " 't-cell',\n",
       " 'mediated',\n",
       " 'rejection',\n",
       " '.',\n",
       " 'antibody']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"interstitial fibrosis and tubular atrophy. T-cell mediated rejection. antibody \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1299c1bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inter',\n",
       " '##st',\n",
       " '##iti',\n",
       " '##al',\n",
       " 'fi',\n",
       " '##bro',\n",
       " '##sis',\n",
       " 'and',\n",
       " 'tub',\n",
       " '##ular',\n",
       " 'at',\n",
       " '##rop',\n",
       " '##hy',\n",
       " '.',\n",
       " 't',\n",
       " '-',\n",
       " 'cell',\n",
       " 'mediated',\n",
       " 'rejection',\n",
       " '.',\n",
       " 'anti',\n",
       " '##body']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"interstitial fibrosis and tubular atrophy. T-cell mediated rejection. antibody \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8b81620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(29002, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238b9999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(29002, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=29002, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03601a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35d5ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = data[\"Raw Case Text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe02954",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoding = tokenizer(inputs,padding=\"max_length\", truncation=True, \n",
    "                            return_tensors=\"pt\",max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a3f2b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoding['labels'] = input_encoding.input_ids.detach().clone()\n",
    "input_encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3649a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False,  True, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ...,  True, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = torch.rand(input_encoding.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (input_encoding.input_ids != 101) * \\\n",
    "           (input_encoding.input_ids != 102) * (input_encoding.input_ids != 0)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c449f55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mask_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "175eadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos = [torch.flatten(mask_arr[i].nonzero()).tolist() for i in range(input_encoding.input_ids.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9fbd94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_encoding.input_ids.shape[0]):\n",
    "    input_encoding.input_ids[i, mask_pos[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe3496f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encoding):\n",
    "        self.encoding = encoding\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encoding.input_ids)\n",
    "\n",
    "masked_dataset = MaskedDataset(input_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "544a7bdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ytc19\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3429\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2145\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2091' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2091/2145 12:27 < 00:19, 2.79 it/s, Epoch 4.87/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.029800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.029100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-100\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-100\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-100\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-200\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-200\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-200\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-300\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-300\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-300\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-400\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-400\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-400\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-500\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-500\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-500\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-600\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-600\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-600\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-700\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-700\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-700\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-800\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-800\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-800\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-900\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-900\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-900\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1000\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1000\\pytorch_model.bin\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1100\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1100\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-100] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1200\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1200\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-200] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1300\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1300\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-300] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1400\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1400\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-400] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1500\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1500\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-500] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1600\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1600\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-600] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1700\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1700\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-700] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1800\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1800\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-800] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-1900\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-1900\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-900] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n",
      "Saving model checkpoint to ./mlm_results_largeData_extended_tokenizer\\checkpoint-2000\n",
      "Configuration saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./mlm_results_largeData_extended_tokenizer\\checkpoint-2000\\pytorch_model.bin\n",
      "Deleting older checkpoint [mlm_results_largeData_extended_tokenizer\\checkpoint-1000] due to args.save_total_limit\n",
      "<ipython-input-14-9ee0b0f0abb5>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encoding.items()}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7d5c28e5f3f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1363\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1956\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1957\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1958\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./mlm_results_largeData_extended_tokenizer',          \n",
    "    num_train_epochs=5,              \n",
    "    per_device_train_batch_size=8,  \n",
    "    #per_device_eval_batch_size=64,   \n",
    "    #warmup_steps=50,                \n",
    "    #weight_decay=0.01,                          \n",
    "    logging_steps=100,\n",
    "    #evaluation_strateg=\"steps\",\n",
    "    #eval_steps=100,\n",
    "    #load_best_model_at_end=True,\n",
    "    save_steps = 100,\n",
    "    save_total_limit = 10,\n",
    "    seed = 0\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                 \n",
    "    train_dataset=masked_dataset,         \n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97e1731",
   "metadata": {},
   "source": [
    "# Test Trained MLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdf3965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_renal = AutoModelForMaskedLM.from_pretrained(\"./mlm_results_largeData_extended_tokenizer/checkpoint-1100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3dde310",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sent = f\"Comment: The biopsy shows severe interstitial inflammation and tubulitis (i3/t3), \\\n",
    "which are diagnostic for acute T-cell-mediated rejection, type IB.\"\n",
    "\n",
    "masked_sent = f\"Comment: The {tokenizer.mask_token} shows {tokenizer.mask_token} interstitial {tokenizer.mask_token} and tubulitis (i3/t3), \\\n",
    "which are {tokenizer.mask_token} for {tokenizer.mask_token} T-cell-mediated {tokenizer.mask_token}, {tokenizer.mask_token} IB.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd802525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4,  6,  8, 23, 25, 29, 31])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent = tokenizer.encode(masked_sent, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(tokenized_sent == tokenizer.mask_token_id)[1]\n",
    "\n",
    "mask_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17091236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: \n",
      " Comment: The biopsy shows severe interstitial inflammation and tubulitis (i3/t3), which are diagnostic for acute T-cell-mediated rejection, type IB. \n",
      "\n",
      "Comment: The 0*patient* shows 1*moderate* interstitial 2*inflammation* and tubulitis (i3/t3), which are 3*typical* for 4*acute* T-cell-mediated 5*rejection*, 6*and* IB. \n",
      "\n",
      "Comment: The 0*specimen* shows 1*mild* interstitial 2*fibrosis* and tubulitis (i3/t3), which are 3*diagnostic* for 4*a* T-cell-mediated 5*diabetes*, 6*including* IB. \n",
      "\n",
      "Comment: The 0*abdomen* shows 1*severe* interstitial 2*congestion* and tubulitis (i3/t3), which are 3*suspicious* for 4*chronic* T-cell-mediated 5*injury*, 6*but* IB. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clinical model\n",
    "token_logits = model_renal(tokenized_sent).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices.tolist()\n",
    "print(\"Original Sentence: \\n\", original_sent, \"\\n\")\n",
    "for words in zip(*top_3_tokens):\n",
    "    new_sent = masked_sent\n",
    "    for i,token in enumerate(words):\n",
    "        new_sent = new_sent.replace(tokenizer.mask_token,f'{i}*{tokenizer.decode([token])}*',1)\n",
    "    print(new_sent,\"\\n\")\n",
    "    \n",
    "# token_logits = model(tokenized_sent).logits\n",
    "# mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "# top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "# for token in top_5_tokens:\n",
    "#     print(masked_sent.replace(tokenizer.mask_token,tokenizer.decode([token])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65bb5888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: \n",
      " Comment: The biopsy shows severe interstitial inflammation and tubulitis (i3/t3), which are diagnostic for acute T-cell-mediated rejection, type IB. \n",
      "\n",
      "Comment: The 0*patient* shows 1*moderate* interstitial 2*inflammation* and tubulitis (i3/t3), which are 3*typical* for 4*acute* T-cell-mediated 5*rejection*, 6*and* IB. \n",
      "\n",
      "Comment: The 0*specimen* shows 1*mild* interstitial 2*fibrosis* and tubulitis (i3/t3), which are 3*diagnostic* for 4*a* T-cell-mediated 5*diabetes*, 6*including* IB. \n",
      "\n",
      "Comment: The 0*abdomen* shows 1*severe* interstitial 2*congestion* and tubulitis (i3/t3), which are 3*suspicious* for 4*chronic* T-cell-mediated 5*injury*, 6*but* IB. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model_renal\n",
    "token_logits = model_renal(tokenized_sent).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_3_tokens = torch.topk(mask_token_logits, 3, dim=1).indices.tolist()\n",
    "print(\"Original Sentence: \\n\", original_sent, \"\\n\")\n",
    "for words in zip(*top_3_tokens):\n",
    "    new_sent = masked_sent\n",
    "    for i,token in enumerate(words):\n",
    "        new_sent = new_sent.replace(tokenizer.mask_token,f'{i}*{tokenizer.decode([token])}*',1)\n",
    "    print(new_sent,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ba707",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
